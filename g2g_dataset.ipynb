{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d1fd6-7025-401e-9c60-dc4af0e885b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from gene_mat import gen_dataset_wt\n",
    "from dcj_comp import dcj_dist\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f498092f-fb00-4bd7-968e-27cba9a4172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dcj(x):\n",
    "    a,b,c = dcj_dist(x[0], x[1])[-1], dcj_dist(x[-1], x[1])[-1], dcj_dist(x[0], x[-1])[-1]\n",
    "    if a != b or (a+b) != c:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9327e409-6956-42cd-94c8-fafe45dadc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_g2g_data(gene_len, graph_num, step, op_type):\n",
    "    l = 0\n",
    "    res = np.zeros((graph_num, 3, gene_len), dtype = np.int32)\n",
    "    while True:\n",
    "        s,o,t = gen_dataset_wt(gene_len, graph_num * 2, 2*step + 1, op_type)\n",
    "        s = s[:, (0, step, -1)]\n",
    "\n",
    "        with Pool(22) as p:\n",
    "            tags = p.map(check_dcj, list(s))\n",
    "        s =  s[tags]\n",
    "        size = min(s.shape[0], graph_num - l)\n",
    "\n",
    "        res[l: (l + size)] = s[:size]\n",
    "        l += size\n",
    "        if l>=graph_num:\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102d73ec-6f1a-4248-b149-35c9ab843d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_g2g_dataset(gene_len, step, graph_num = None, fname = None):\n",
    "    if graph_num == None:\n",
    "        graph_num = 1000\n",
    "        \n",
    "    if fname == None:\n",
    "        fname = 'g2g_' + str(gene_len) + '_' + str(step) + '.pt'\n",
    "    \n",
    "    source = np.zeros((graph_num * step, 2, gene_len), dtype = np.int32) #[]\n",
    "    target = np.zeros((graph_num * step, gene_len), dtype = np.int32) #[]\n",
    "    \n",
    "    for dist in range(0, step):\n",
    "        s = gen_g2g_data(gene_len, graph_num, dist, op_type = 2)\n",
    "        \n",
    "        source[dist * graph_num : (dist + 1) * graph_num] = s[:, (0, -1)]\n",
    "        target[dist * graph_num : (dist + 1) * graph_num] = s[:, 1]\n",
    "    torch.save((source, target), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21272f76-7bbd-4891-aa1b-45b2a56810ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.cuda.device(1):\n",
    "    save_g2g_dataset(gene_len = 100, step = 5, graph_num = None, fname = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf596bb-713c-4140-8c80-7e74037e935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb68c55-fdff-49ef-a1db-a092f4e374ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, gene_len, step_range, graph_num = 10000):\n",
    "#                  transform=None, pre_transform=None, pre_filter = None):\n",
    "        self.gene_len = gene_len\n",
    "        self.step_range = step_range\n",
    "        self.graph_num = graph_num\n",
    "        super().__init__(root + '_' + str(self.gene_len) + '_' \n",
    "                         + str(self.step_range) + '_' + str(self.graph_num), \n",
    "                         transform = None, \n",
    "                         pre_transform = None, \n",
    "                         pre_filter = None)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['g2raw_' + str(self.gene_len) +\n",
    "                '_' + str(self.step_range) + '.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['g2dat_' + str(self.gene_len) +\n",
    "                '_' + str(self.step_range) + '.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        print('Generating...', file=sys.stderr)\n",
    "        save_dataset(self.gene_len, self.step_range, \n",
    "                     graph_num = self.graph_num, \n",
    "                     fname = self.raw_dir + '/' + self.raw_file_names[0])\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        filename = self.raw_dir + '/' + self.raw_file_names[0]\n",
    "        source, target = torch.load(filename, map_location=torch.device('cuda'))        \n",
    "        \n",
    "        # todo: change gen_graph function\n",
    "        data_list = [gen_graph(x, label = inv_num) for x, inv_num in zip(gene_list, label)]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7286432-e332-483a-848d-569d030cc017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep AI",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
