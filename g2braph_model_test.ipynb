{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8832435c-cc48-40da-b226-548b3281c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from phylognn_model import G2Braph\n",
    "from gene_graph_dataset import G2BraphDataset\n",
    "\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11a6854-b123-4f21-876b-75717250c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p, test_p = 0.7, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9e9f86-5660-485c-921d-40e6eeaa2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = G2BraphDataset('dataset_g2b', 1000, 10).shuffle()\n",
    "data_size = len(dataset)\n",
    "train_size, test_size = (int)(data_size * train_p), (int)(data_size * test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b428c27-6f37-480e-ae50-d86dfc839c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:(train_size + test_size)]\n",
    "val_dataset = dataset[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394976a2-812c-4add-9041-48d897d7caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad402c1-6d41-412b-8a9d-fe71da146b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = torch.zeros(5, dtype=torch.long)\n",
    "for data in train_dataset:\n",
    "    d = degree(data.edge_index[1].type(torch.int64), \n",
    "               num_nodes=data.num_nodes, dtype=torch.long)\n",
    "    deg += torch.bincount(d, minlength=deg.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce5584-e4e5-4963-8d64-f7822cf8757d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb03c710-bda4-492e-86e8-3696cd51de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = G2Braph(deg).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c2a368-5a64-4f2f-8c7b-a812984f0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for data in train_dataset:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        res = model(data.x, data.edge_index, None, None)\n",
    "        loss = F.binary_cross_entropy(res.squeeze(), data.node_label.to(torch.float))\n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58ad428-cdd3-4997-a50a-8a911215f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(test_dataset):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, auc, ap = 0, 0, 0\n",
    "    for data in test_dataset:\n",
    "        data = data.to(device)\n",
    "        res = model(data.x, data.edge_index, None, None)\n",
    "        \n",
    "        y, pred = data.node_label.cpu().numpy(), res.squeeze().cpu().numpy()\n",
    "        \n",
    "        total_loss += F.binary_cross_entropy(res.squeeze(), data.node_label.to(torch.float))\n",
    "        auc += roc_auc_score(y, pred)\n",
    "        ap += average_precision_score(y, pred)\n",
    "        \n",
    "    return total_loss / len(test_dataset), auc / len(test_dataset), ap / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d1caae-4b52-4a14-a920-4fec3e93596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs/g2braph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc7b73-2132-4f35-97b1-b05117d34b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 21 21:06:48 2021\tEpoch: 001, Train Loss: 0.0489, Val Loss: 0.0320, Val AUC: 0.8876, Val AP: 0.7000\n",
      "Tue Dec 21 21:07:49 2021\tEpoch: 002, Train Loss: 0.0264, Val Loss: 0.0268, Val AUC: 0.9099, Val AP: 0.7237\n",
      "Tue Dec 21 21:08:50 2021\tEpoch: 003, Train Loss: 0.0218, Val Loss: 0.0243, Val AUC: 0.9125, Val AP: 0.7327\n",
      "Tue Dec 21 21:09:51 2021\tEpoch: 004, Train Loss: 0.0200, Val Loss: 0.0235, Val AUC: 0.9185, Val AP: 0.7421\n",
      "Tue Dec 21 21:10:51 2021\tEpoch: 005, Train Loss: 0.0190, Val Loss: 0.0230, Val AUC: 0.9200, Val AP: 0.7472\n",
      "Tue Dec 21 21:11:51 2021\tEpoch: 006, Train Loss: 0.0184, Val Loss: 0.0226, Val AUC: 0.9214, Val AP: 0.7460\n",
      "Tue Dec 21 21:12:51 2021\tEpoch: 007, Train Loss: 0.0180, Val Loss: 0.0235, Val AUC: 0.9149, Val AP: 0.7379\n",
      "Tue Dec 21 21:13:51 2021\tEpoch: 008, Train Loss: 0.0178, Val Loss: 0.0240, Val AUC: 0.9130, Val AP: 0.7325\n",
      "Tue Dec 21 21:14:52 2021\tEpoch: 009, Train Loss: 0.0176, Val Loss: 0.0243, Val AUC: 0.9168, Val AP: 0.7372\n",
      "Tue Dec 21 21:15:51 2021\tEpoch: 010, Train Loss: 0.0176, Val Loss: 0.0228, Val AUC: 0.9172, Val AP: 0.7467\n",
      "Tue Dec 21 21:16:46 2021\tEpoch: 011, Train Loss: 0.0174, Val Loss: 0.0238, Val AUC: 0.9168, Val AP: 0.7377\n",
      "Tue Dec 21 21:17:46 2021\tEpoch: 012, Train Loss: 0.0174, Val Loss: 0.0244, Val AUC: 0.9128, Val AP: 0.7365\n",
      "Tue Dec 21 21:18:46 2021\tEpoch: 013, Train Loss: 0.0172, Val Loss: 0.0237, Val AUC: 0.9162, Val AP: 0.7376\n",
      "Tue Dec 21 21:19:46 2021\tEpoch: 014, Train Loss: 0.0172, Val Loss: 0.0245, Val AUC: 0.9156, Val AP: 0.7372\n",
      "Tue Dec 21 21:20:45 2021\tEpoch: 015, Train Loss: 0.0171, Val Loss: 0.0242, Val AUC: 0.9164, Val AP: 0.7336\n",
      "Tue Dec 21 21:21:45 2021\tEpoch: 016, Train Loss: 0.0168, Val Loss: 0.0233, Val AUC: 0.9212, Val AP: 0.7453\n",
      "Tue Dec 21 21:22:47 2021\tEpoch: 017, Train Loss: 0.0167, Val Loss: 0.0232, Val AUC: 0.9249, Val AP: 0.7468\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    train_loss = train(train_dataset.shuffle())\n",
    "    val_loss, val_auc, val_ap = test(val_dataset.shuffle())\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/validate', val_loss, epoch)\n",
    "    writer.add_scalar('AUC/validate', val_auc, epoch)\n",
    "    writer.add_scalar('AP/validate', val_ap, epoch)\n",
    "    \n",
    "    print(f'{time.ctime()}  '\n",
    "              f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, '\n",
    "              f'Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b56a7-e2be-4976-a391-3001fdb66c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_auc, test_ap = test(test_dataset.shuffle())\n",
    "print(f'Test Loss: {train_loss:.4f}, Test AUC: {test_auc:.4f}, '\n",
    "          f'Test AP: {test_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d2d07-e5c8-4d76-8813-ec4d8b463f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep AI",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
