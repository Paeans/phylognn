{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aa328c-fbde-4c86-837d-b109eac25828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, Embedding\n",
    "from torch.nn import Sequential, ReLU, Linear, MSELoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, PNAConv, BatchNorm, global_add_pool\n",
    "\n",
    "from phylognn_model import G2Dist_GCNConv\n",
    "\n",
    "from gene_graph_dataset import GeneGraphDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1afe07e-f45d-4435-9efd-f7be458f83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p, test_p = 0.7, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8f1633-bee2-464b-93e2-6fea1a471948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeneGraphDataset('dataset', 100, 20, graph_num = 50)\n",
    "data_size = len(dataset)\n",
    "train_size, test_size = (int)(data_size * train_p), (int)(data_size * test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2f694a-7ae1-455e-9582-8b7eb9ed67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95dcce3-4aaf-4d68-b153-a9581899a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:(train_size + test_size)]\n",
    "val_dataset = dataset[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47b7e88-9969-44f9-84f7-5153ff78f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6fab12-de4d-4967-85da-114dcd36e87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[200], edge_index=[2, 398], edge_attr=[398, 2], dtype=torch.int64, y=[1], num_nodes=200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30f5652-6017-4f4c-a304-842abf6ddfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f6283c-d51a-4747-8f1b-f437ca523abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddbf1dce-6f12-4fdd-be53-37271e03d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c85b3a-1bdf-49db-8494-d04d29ba39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader), len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6c79a8d-bb5d-4875-80ff-6c22ece243e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = G2Dist_GCNConv().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e364bfa2-7153-493c-9d74-ba7b1ae117ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = MSELoss()\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #loss = (out.squeeze() - data.y).abs().sum()\n",
    "        loss = mse_loss(out.squeeze(), data.y.to(torch.float))\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce1b9829-772b-4e9b-a75e-1e9904d80afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_error = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        total_error += (out.squeeze() - data.y).abs().sum().item()\n",
    "    return total_error / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fba2c20-6dee-4b91-acdb-8ee1fa2319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs_g2d_10/g2distance_0100_0020_01000-gcn-run4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e23bb307-e484-493c-a60e-69911d93d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 29 23:31:13 2021\tEpoch: 001, Loss: 131.6797, Val: 10.6940, Test: 9.1010\n",
      "Wed Dec 29 23:31:15 2021\tEpoch: 002, Loss: 101.3037, Val: 9.9220, Test: 8.3069\n",
      "Wed Dec 29 23:31:17 2021\tEpoch: 003, Loss: 70.7683, Val: 9.2629, Test: 7.6386\n",
      "Wed Dec 29 23:31:19 2021\tEpoch: 004, Loss: 45.9278, Val: 9.0215, Test: 7.3829\n",
      "Wed Dec 29 23:31:21 2021\tEpoch: 005, Loss: 32.2752, Val: 9.3279, Test: 7.6283\n",
      "Wed Dec 29 23:31:23 2021\tEpoch: 006, Loss: 29.0565, Val: 8.3758, Test: 6.6687\n",
      "Wed Dec 29 23:31:25 2021\tEpoch: 007, Loss: 27.2096, Val: 7.2313, Test: 5.6692\n",
      "Wed Dec 29 23:31:27 2021\tEpoch: 008, Loss: 25.7433, Val: 6.3189, Test: 5.0125\n",
      "Wed Dec 29 23:31:29 2021\tEpoch: 009, Loss: 24.6015, Val: 5.7001, Test: 4.5915\n",
      "Wed Dec 29 23:31:31 2021\tEpoch: 010, Loss: 23.4974, Val: 5.0510, Test: 4.3246\n",
      "Wed Dec 29 23:31:33 2021\tEpoch: 011, Loss: 22.4077, Val: 4.8185, Test: 4.2774\n",
      "Wed Dec 29 23:31:35 2021\tEpoch: 012, Loss: 21.7950, Val: 4.6875, Test: 4.2714\n",
      "Wed Dec 29 23:31:37 2021\tEpoch: 013, Loss: 21.1261, Val: 4.7015, Test: 4.2613\n",
      "Wed Dec 29 23:31:38 2021\tEpoch: 014, Loss: 20.3979, Val: 4.6208, Test: 4.2906\n",
      "Wed Dec 29 23:31:41 2021\tEpoch: 015, Loss: 19.6564, Val: 4.7069, Test: 4.2738\n",
      "Wed Dec 29 23:31:42 2021\tEpoch: 016, Loss: 19.1168, Val: 4.6419, Test: 4.2656\n",
      "Wed Dec 29 23:31:44 2021\tEpoch: 017, Loss: 18.3571, Val: 4.5780, Test: 4.3260\n",
      "Wed Dec 29 23:31:46 2021\tEpoch: 018, Loss: 17.9476, Val: 4.7453, Test: 4.2876\n",
      "Wed Dec 29 23:31:48 2021\tEpoch: 019, Loss: 17.2988, Val: 4.5969, Test: 4.3461\n",
      "Wed Dec 29 23:31:50 2021\tEpoch: 020, Loss: 16.5148, Val: 4.6333, Test: 4.2963\n",
      "Wed Dec 29 23:31:52 2021\tEpoch: 021, Loss: 15.8266, Val: 4.9269, Test: 4.2517\n",
      "Wed Dec 29 23:31:54 2021\tEpoch: 022, Loss: 15.4228, Val: 5.4527, Test: 4.4393\n",
      "Wed Dec 29 23:31:56 2021\tEpoch: 023, Loss: 14.8154, Val: 5.3294, Test: 4.4039\n",
      "Wed Dec 29 23:31:58 2021\tEpoch: 024, Loss: 14.4041, Val: 4.6975, Test: 4.3178\n",
      "Wed Dec 29 23:32:00 2021\tEpoch: 025, Loss: 13.5283, Val: 4.8003, Test: 4.3455\n",
      "Wed Dec 29 23:32:02 2021\tEpoch: 026, Loss: 13.1608, Val: 5.2746, Test: 4.3995\n",
      "Wed Dec 29 23:32:04 2021\tEpoch: 027, Loss: 12.2988, Val: 4.7805, Test: 4.3672\n",
      "Wed Dec 29 23:32:06 2021\tEpoch: 028, Loss: 11.8861, Val: 4.7568, Test: 4.3958\n",
      "Wed Dec 29 23:32:08 2021\tEpoch: 029, Loss: 11.9211, Val: 4.9033, Test: 4.3553\n",
      "Wed Dec 29 23:32:09 2021\tEpoch: 030, Loss: 10.6415, Val: 5.6779, Test: 4.6029\n",
      "Wed Dec 29 23:32:11 2021\tEpoch: 031, Loss: 10.5653, Val: 4.5396, Test: 4.5996\n",
      "Wed Dec 29 23:32:13 2021\tEpoch: 032, Loss: 10.1400, Val: 4.5602, Test: 4.6179\n",
      "Wed Dec 29 23:32:15 2021\tEpoch: 033, Loss: 9.4376, Val: 4.7329, Test: 4.4291\n",
      "Wed Dec 29 23:32:17 2021\tEpoch: 034, Loss: 9.0835, Val: 5.0138, Test: 4.4236\n",
      "Wed Dec 29 23:32:19 2021\tEpoch: 035, Loss: 8.6912, Val: 5.2137, Test: 4.4500\n",
      "Wed Dec 29 23:32:21 2021\tEpoch: 036, Loss: 8.5275, Val: 5.0447, Test: 4.4239\n",
      "Wed Dec 29 23:32:22 2021\tEpoch: 037, Loss: 7.9523, Val: 5.7829, Test: 4.6353\n",
      "Wed Dec 29 23:32:24 2021\tEpoch: 038, Loss: 7.5722, Val: 4.9193, Test: 4.4374\n",
      "Wed Dec 29 23:32:26 2021\tEpoch: 039, Loss: 7.4768, Val: 5.4197, Test: 4.5241\n",
      "Wed Dec 29 23:32:28 2021\tEpoch: 040, Loss: 6.8908, Val: 5.8654, Test: 4.7489\n",
      "Wed Dec 29 23:32:30 2021\tEpoch: 041, Loss: 6.2216, Val: 4.6597, Test: 4.4811\n",
      "Wed Dec 29 23:32:32 2021\tEpoch: 042, Loss: 6.0811, Val: 4.6507, Test: 4.4872\n",
      "Wed Dec 29 23:32:34 2021\tEpoch: 043, Loss: 5.8818, Val: 5.4521, Test: 4.5140\n",
      "Wed Dec 29 23:32:36 2021\tEpoch: 044, Loss: 5.9692, Val: 4.9384, Test: 4.4124\n",
      "Wed Dec 29 23:32:37 2021\tEpoch: 045, Loss: 5.9014, Val: 4.6341, Test: 4.4795\n",
      "Wed Dec 29 23:32:39 2021\tEpoch: 046, Loss: 5.7132, Val: 4.7237, Test: 4.4085\n",
      "Wed Dec 29 23:32:41 2021\tEpoch: 047, Loss: 4.9768, Val: 4.4584, Test: 4.5930\n",
      "Wed Dec 29 23:32:43 2021\tEpoch: 048, Loss: 4.9224, Val: 4.6045, Test: 4.5205\n",
      "Wed Dec 29 23:32:45 2021\tEpoch: 049, Loss: 4.5647, Val: 4.8328, Test: 4.3793\n",
      "Wed Dec 29 23:32:47 2021\tEpoch: 050, Loss: 4.4262, Val: 5.0885, Test: 4.4051\n",
      "Wed Dec 29 23:32:49 2021\tEpoch: 051, Loss: 4.5046, Val: 5.9483, Test: 4.7576\n",
      "Wed Dec 29 23:32:51 2021\tEpoch: 052, Loss: 4.3251, Val: 5.4283, Test: 4.5025\n",
      "Wed Dec 29 23:32:53 2021\tEpoch: 053, Loss: 3.7038, Val: 5.0908, Test: 4.4437\n",
      "Wed Dec 29 23:32:54 2021\tEpoch: 054, Loss: 3.4659, Val: 4.5792, Test: 4.4915\n",
      "Wed Dec 29 23:32:56 2021\tEpoch: 055, Loss: 4.1210, Val: 4.7034, Test: 4.4764\n",
      "Wed Dec 29 23:32:58 2021\tEpoch: 056, Loss: 3.3103, Val: 4.5070, Test: 4.6402\n",
      "Wed Dec 29 23:33:00 2021\tEpoch: 057, Loss: 3.7509, Val: 4.5862, Test: 4.5163\n",
      "Wed Dec 29 23:33:02 2021\tEpoch: 058, Loss: 4.0478, Val: 5.2433, Test: 4.4381\n",
      "Wed Dec 29 23:33:04 2021\tEpoch: 059, Loss: 3.7260, Val: 4.5509, Test: 4.4969\n",
      "Wed Dec 29 23:33:06 2021\tEpoch: 060, Loss: 2.9176, Val: 4.5800, Test: 4.4754\n",
      "Wed Dec 29 23:33:08 2021\tEpoch: 061, Loss: 3.1681, Val: 4.9800, Test: 4.3921\n",
      "Wed Dec 29 23:33:10 2021\tEpoch: 062, Loss: 2.6772, Val: 4.9278, Test: 4.3626\n",
      "Wed Dec 29 23:33:12 2021\tEpoch: 063, Loss: 3.0663, Val: 5.2661, Test: 4.4216\n",
      "Wed Dec 29 23:33:14 2021\tEpoch: 064, Loss: 2.4652, Val: 4.9747, Test: 4.3924\n",
      "Wed Dec 29 23:33:16 2021\tEpoch: 065, Loss: 2.2939, Val: 4.6125, Test: 4.4559\n",
      "Wed Dec 29 23:33:18 2021\tEpoch: 066, Loss: 2.5422, Val: 4.4552, Test: 4.6218\n",
      "Wed Dec 29 23:33:20 2021\tEpoch: 067, Loss: 2.3052, Val: 4.8110, Test: 4.4299\n",
      "Wed Dec 29 23:33:22 2021\tEpoch: 068, Loss: 2.4249, Val: 4.9936, Test: 4.4096\n",
      "Wed Dec 29 23:33:24 2021\tEpoch: 069, Loss: 1.7909, Val: 4.5755, Test: 4.5470\n",
      "Wed Dec 29 23:33:26 2021\tEpoch: 070, Loss: 1.7502, Val: 4.6320, Test: 4.4735\n",
      "Wed Dec 29 23:33:28 2021\tEpoch: 071, Loss: 1.8305, Val: 5.1742, Test: 4.3973\n",
      "Wed Dec 29 23:33:29 2021\tEpoch: 072, Loss: 1.8613, Val: 4.8082, Test: 4.4132\n",
      "Wed Dec 29 23:33:31 2021\tEpoch: 073, Loss: 1.8797, Val: 5.0607, Test: 4.3881\n",
      "Wed Dec 29 23:33:33 2021\tEpoch: 074, Loss: 1.8420, Val: 4.8742, Test: 4.4145\n",
      "Wed Dec 29 23:33:35 2021\tEpoch: 075, Loss: 1.6181, Val: 4.7390, Test: 4.4790\n",
      "Wed Dec 29 23:33:37 2021\tEpoch: 076, Loss: 1.4457, Val: 4.5836, Test: 4.5250\n",
      "Wed Dec 29 23:33:39 2021\tEpoch: 077, Loss: 1.5000, Val: 4.7085, Test: 4.4710\n",
      "Wed Dec 29 23:33:41 2021\tEpoch: 078, Loss: 1.1798, Val: 4.9941, Test: 4.4073\n",
      "Wed Dec 29 23:33:42 2021\tEpoch: 079, Loss: 1.6237, Val: 4.4465, Test: 4.9072\n",
      "Wed Dec 29 23:33:44 2021\tEpoch: 080, Loss: 1.4402, Val: 4.5759, Test: 4.5855\n",
      "Wed Dec 29 23:33:46 2021\tEpoch: 081, Loss: 1.2005, Val: 4.9789, Test: 4.3979\n",
      "Wed Dec 29 23:33:48 2021\tEpoch: 082, Loss: 1.5068, Val: 4.4308, Test: 4.7887\n",
      "Wed Dec 29 23:33:50 2021\tEpoch: 083, Loss: 1.1438, Val: 5.2495, Test: 6.5555\n",
      "Wed Dec 29 23:33:52 2021\tEpoch: 084, Loss: 1.0158, Val: 4.5517, Test: 4.5311\n",
      "Wed Dec 29 23:33:53 2021\tEpoch: 085, Loss: 1.3243, Val: 5.3038, Test: 4.4189\n",
      "Wed Dec 29 23:33:55 2021\tEpoch: 086, Loss: 1.1838, Val: 4.5234, Test: 4.6885\n",
      "Wed Dec 29 23:33:57 2021\tEpoch: 087, Loss: 1.3057, Val: 4.6008, Test: 5.2095\n",
      "Wed Dec 29 23:33:59 2021\tEpoch: 088, Loss: 1.2616, Val: 4.4484, Test: 4.6104\n",
      "Wed Dec 29 23:34:01 2021\tEpoch: 089, Loss: 0.9886, Val: 4.4693, Test: 4.8365\n",
      "Wed Dec 29 23:34:03 2021\tEpoch: 090, Loss: 0.9589, Val: 4.5958, Test: 4.4653\n",
      "Wed Dec 29 23:34:05 2021\tEpoch: 091, Loss: 1.1368, Val: 4.8995, Test: 4.4217\n",
      "Wed Dec 29 23:34:06 2021\tEpoch: 092, Loss: 1.5585, Val: 4.6592, Test: 4.4687\n",
      "Wed Dec 29 23:34:08 2021\tEpoch: 093, Loss: 1.2019, Val: 4.6179, Test: 4.5462\n",
      "Wed Dec 29 23:34:10 2021\tEpoch: 094, Loss: 1.0649, Val: 4.6321, Test: 4.5091\n",
      "Wed Dec 29 23:34:12 2021\tEpoch: 095, Loss: 1.2692, Val: 4.9638, Test: 4.4044\n",
      "Wed Dec 29 23:34:14 2021\tEpoch: 096, Loss: 2.3061, Val: 4.5250, Test: 4.6924\n",
      "Wed Dec 29 23:34:16 2021\tEpoch: 097, Loss: 1.3093, Val: 4.5871, Test: 5.0256\n",
      "Wed Dec 29 23:34:18 2021\tEpoch: 098, Loss: 0.9196, Val: 4.9849, Test: 4.4849\n",
      "Wed Dec 29 23:34:20 2021\tEpoch: 099, Loss: 1.2545, Val: 4.5530, Test: 4.5867\n",
      "Wed Dec 29 23:34:22 2021\tEpoch: 100, Loss: 0.9971, Val: 4.4846, Test: 4.7259\n"
     ]
    }
   ],
   "source": [
    "result = torch.zeros(1000, 3)\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader)\n",
    "    test_mae = test(test_loader)\n",
    "    val_mae = test(val_loader)\n",
    "    \n",
    "    # scheduler.step(val_mae)\n",
    "    result[epoch - 1] = torch.tensor([loss, val_mae, test_mae])\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "    writer.add_scalar('Loss/test', test_mae, epoch)\n",
    "    writer.add_scalar('Loss/val', val_mae, epoch)\n",
    "    \n",
    "    print(f'{time.ctime()}\\t'\n",
    "          f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n",
    "          f'Test: {test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da7ec806-9523-4302-9042-9444644e43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1571b24e-8499-4ea6-9d44-65ad67bddf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3adca663-8162-47b7-80d1-5088c7ee6c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8690, 6.00\n",
      "9.8693, 13.00\n",
      "9.5195, 16.00\n",
      "12.6847, 10.00\n",
      "11.0214, 8.00\n",
      "12.1926, 1.00\n",
      "12.4089, 14.00\n",
      "12.6962, 6.00\n",
      "8.4674, 5.00\n",
      "13.1534, 3.00\n",
      "10.9987, 15.00\n",
      "9.1817, 10.00\n",
      "10.4410, 10.00\n",
      "13.2640, 9.00\n",
      "16.0047, 17.00\n",
      "13.3262, 15.00\n",
      "12.9492, 5.00\n",
      "9.8725, 9.00\n",
      "17.0109, 1.00\n",
      "4.4897, 1.00\n",
      "11.6419, 14.00\n",
      "10.8838, 10.00\n",
      "17.4414, 3.00\n",
      "14.9151, 18.00\n",
      "20.1962, 16.00\n",
      "13.2005, 3.00\n",
      "8.4702, 6.00\n",
      "9.7967, 14.00\n",
      "10.4376, 2.00\n",
      "16.4852, 12.00\n",
      "15.2414, 17.00\n",
      "13.8360, 12.00\n",
      "8.5370, 19.00\n",
      "15.0889, 18.00\n",
      "19.0239, 14.00\n",
      "14.0629, 2.00\n",
      "16.2450, 18.00\n",
      "5.5416, 7.00\n",
      "13.0683, 14.00\n",
      "8.7653, 4.00\n",
      "14.0036, 17.00\n",
      "7.9410, 7.00\n",
      "9.5773, 9.00\n",
      "7.5399, 5.00\n",
      "8.7327, 4.00\n",
      "14.5951, 11.00\n",
      "15.1789, 2.00\n",
      "18.2782, 12.00\n",
      "15.0488, 12.00\n",
      "9.6260, 8.00\n",
      "9.9108, 3.00\n",
      "7.6402, 1.00\n",
      "12.1432, 18.00\n",
      "9.5015, 13.00\n",
      "10.7635, 18.00\n",
      "12.0166, 12.00\n",
      "14.7583, 3.00\n",
      "9.7486, 11.00\n",
      "14.2026, 15.00\n",
      "7.7697, 9.00\n",
      "7.8131, 5.00\n",
      "8.3330, 2.00\n",
      "12.8150, 8.00\n",
      "10.9716, 20.00\n",
      "11.9946, 14.00\n",
      "15.3974, 5.00\n",
      "12.2330, 20.00\n",
      "11.7888, 5.00\n",
      "15.6698, 7.00\n",
      "13.7966, 9.00\n",
      "10.4494, 13.00\n",
      "11.4563, 7.00\n",
      "11.3732, 8.00\n",
      "7.1542, 6.00\n",
      "9.5913, 9.00\n",
      "9.6126, 2.00\n",
      "12.0541, 12.00\n",
      "11.5517, 11.00\n",
      "7.8422, 3.00\n",
      "9.1464, 12.00\n",
      "8.4367, 3.00\n",
      "12.2605, 11.00\n",
      "8.6319, 12.00\n",
      "17.7875, 19.00\n",
      "10.5888, 10.00\n",
      "12.6415, 10.00\n",
      "7.6279, 8.00\n",
      "10.6242, 17.00\n",
      "17.3143, 2.00\n",
      "7.1839, 11.00\n",
      "14.8288, 10.00\n",
      "7.2944, 10.00\n",
      "15.8709, 2.00\n",
      "18.7917, 8.00\n",
      "10.3587, 6.00\n",
      "14.1915, 6.00\n",
      "11.0048, 13.00\n",
      "16.3406, 19.00\n",
      "13.7347, 13.00\n",
      "18.9893, 7.00\n",
      "15.2870, 9.00\n",
      "9.8311, 16.00\n",
      "9.4097, 4.00\n",
      "14.5941, 14.00\n",
      "15.1804, 13.00\n",
      "9.8154, 1.00\n",
      "9.8765, 18.00\n",
      "9.9470, 12.00\n",
      "9.7315, 9.00\n",
      "13.2566, 11.00\n",
      "9.7011, 7.00\n",
      "16.7940, 6.00\n",
      "12.6133, 18.00\n",
      "13.9461, 16.00\n",
      "12.0591, 14.00\n",
      "12.4832, 8.00\n",
      "11.4634, 5.00\n",
      "20.4208, 7.00\n",
      "13.1025, 16.00\n",
      "10.6947, 11.00\n",
      "10.8688, 2.00\n",
      "16.0933, 6.00\n",
      "10.6916, 5.00\n",
      "16.2617, 16.00\n",
      "13.5034, 14.00\n",
      "11.5725, 9.00\n",
      "8.3273, 7.00\n",
      "13.1358, 17.00\n",
      "13.2790, 11.00\n",
      "16.9286, 20.00\n",
      "15.0620, 10.00\n",
      "6.1716, 3.00\n",
      "17.2320, 4.00\n",
      "19.6543, 20.00\n",
      "10.3194, 9.00\n",
      "14.4634, 15.00\n",
      "8.0119, 11.00\n",
      "11.4034, 19.00\n",
      "10.7514, 10.00\n",
      "14.3081, 2.00\n",
      "14.6366, 3.00\n",
      "13.3670, 17.00\n",
      "12.4184, 18.00\n",
      "12.9347, 13.00\n",
      "12.5109, 6.00\n",
      "12.7274, 15.00\n",
      "13.6949, 16.00\n",
      "10.0534, 2.00\n",
      "10.9328, 7.00\n",
      "14.1491, 12.00\n",
      "10.8203, 17.00\n",
      "16.5518, 6.00\n",
      "8.8422, 1.00\n",
      "13.1525, 17.00\n",
      "18.1406, 7.00\n",
      "15.1958, 8.00\n",
      "12.6072, 15.00\n",
      "10.5741, 7.00\n",
      "14.3514, 10.00\n",
      "9.5559, 6.00\n",
      "14.2689, 11.00\n",
      "9.7723, 11.00\n",
      "11.3470, 14.00\n",
      "12.6060, 9.00\n",
      "13.2622, 8.00\n",
      "12.9310, 12.00\n",
      "7.4752, 1.00\n",
      "7.2834, 2.00\n",
      "7.1139, 1.00\n",
      "12.8239, 15.00\n",
      "12.4825, 12.00\n",
      "14.0259, 9.00\n",
      "10.7863, 8.00\n",
      "11.8203, 7.00\n",
      "13.7390, 4.00\n",
      "12.8382, 13.00\n",
      "13.1012, 20.00\n",
      "14.0997, 12.00\n",
      "12.2000, 14.00\n",
      "14.7436, 11.00\n",
      "11.6315, 5.00\n",
      "18.9680, 3.00\n",
      "6.4671, 7.00\n",
      "12.0343, 3.00\n",
      "13.8548, 10.00\n",
      "12.1809, 10.00\n",
      "12.5538, 3.00\n",
      "9.6324, 2.00\n",
      "9.4024, 12.00\n",
      "12.2780, 7.00\n",
      "8.8917, 8.00\n",
      "8.8497, 19.00\n",
      "18.6693, 15.00\n",
      "13.9381, 14.00\n",
      "6.8196, 14.00\n",
      "11.0560, 17.00\n",
      "12.2993, 6.00\n",
      "11.7526, 14.00\n",
      "16.6284, 8.00\n",
      "10.5891, 12.00\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for td in test_loader:\n",
    "    td = td.to(device)\n",
    "    \n",
    "    out = model(td.x, td.edge_index, td.batch)\n",
    "    print(f'{out.squeeze().item():.4f}, {td.y.item():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8540995-e201-4072-a300-c0c77ad8047f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dataset'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_579893/478233052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             raise AttributeError(\n\u001b[0;32m---> 51\u001b[0;31m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "len(td.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "187df19e-9c61-4dc3-8280-f186badf6107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneGraphDataset(200)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae63b9a-9488-4a47-9b4e-05545886fc63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep AI",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
