{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aa328c-fbde-4c86-837d-b109eac25828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, Embedding\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, L1Loss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, PNAConv, BatchNorm, global_add_pool\n",
    "\n",
    "from phylognn_model import G2Dist_GCNConv\n",
    "\n",
    "from gene_graph_dataset import GeneGraphDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1afe07e-f45d-4435-9efd-f7be458f83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p, test_p = 0.7, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8f1633-bee2-464b-93e2-6fea1a471948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeneGraphDataset('dataset', 20, 20, graph_num = 100)\n",
    "data_size = len(dataset)\n",
    "train_size, test_size = (int)(data_size * train_p), (int)(data_size * test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2f694a-7ae1-455e-9582-8b7eb9ed67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95dcce3-4aaf-4d68-b153-a9581899a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:(train_size + test_size)]\n",
    "val_dataset = dataset[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f6283c-d51a-4747-8f1b-f437ca523abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbf1dce-6f12-4fdd-be53-37271e03d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c85b3a-1bdf-49db-8494-d04d29ba39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader), len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c79a8d-bb5d-4875-80ff-6c22ece243e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = G2Dist_GCNConv().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e364bfa2-7153-493c-9d74-ba7b1ae117ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = MSELoss()\n",
    "# l1_fn = L1Loss()\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss, counter = 0, 0\n",
    "    size = len(train_loader)\n",
    "    for batch, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #loss = (out.squeeze() - data.y).abs().sum()\n",
    "        pred, y = out.softmax(axis = 1).argmax(axis = 1), data.y\n",
    "        counter += (pred == y).sum().item()\n",
    "        \n",
    "        loss = loss_fn(out, data.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / len(train_loader), counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce1b9829-772b-4e9b-a75e-1e9904d80afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_error, counter = 0, 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        pred, y = out.softmax(axis = 1).argmax(axis = 1), data.y\n",
    "        counter += (pred == y).sum().item()\n",
    "        \n",
    "        # total_error += (out.squeeze() - data.y).abs().sum().item()\n",
    "        \n",
    "        total_error += loss_fn(out, data.y).item()\n",
    "        \n",
    "    return total_error / len(loader), counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fba2c20-6dee-4b91-acdb-8ee1fa2319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs_g2d_10/g2dist_0020_0020_02000-gcn-run10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23bb307-e484-493c-a60e-69911d93d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan  1 22:38:29 2022\tEpoch: 001, Loss: 3.0023, Val: 3.3581, Test: 3.2833\n",
      "\t\t -- train_counter: 65, test_counter:21\n",
      "Sat Jan  1 22:38:32 2022\tEpoch: 002, Loss: 2.8931, Val: 4.4271, Test: 4.4344\n",
      "\t\t -- train_counter: 83, test_counter:22\n",
      "Sat Jan  1 22:38:35 2022\tEpoch: 003, Loss: 2.8606, Val: 5.4239, Test: 5.1078\n",
      "\t\t -- train_counter: 112, test_counter:24\n",
      "Sat Jan  1 22:38:38 2022\tEpoch: 004, Loss: 2.8327, Val: 10.0936, Test: 9.6779\n",
      "\t\t -- train_counter: 117, test_counter:15\n",
      "Sat Jan  1 22:38:41 2022\tEpoch: 005, Loss: 2.8114, Val: 11.5798, Test: 10.8108\n",
      "\t\t -- train_counter: 134, test_counter:23\n",
      "Sat Jan  1 22:38:44 2022\tEpoch: 006, Loss: 2.7775, Val: 8.9466, Test: 8.2702\n",
      "\t\t -- train_counter: 159, test_counter:24\n",
      "Sat Jan  1 22:38:47 2022\tEpoch: 007, Loss: 2.7291, Val: 7.1029, Test: 6.8132\n",
      "\t\t -- train_counter: 190, test_counter:9\n",
      "Sat Jan  1 22:38:50 2022\tEpoch: 008, Loss: 2.6951, Val: 4.7179, Test: 4.6327\n",
      "\t\t -- train_counter: 177, test_counter:20\n",
      "Sat Jan  1 22:38:53 2022\tEpoch: 009, Loss: 2.6590, Val: 3.9246, Test: 3.9229\n",
      "\t\t -- train_counter: 189, test_counter:24\n",
      "Sat Jan  1 22:38:56 2022\tEpoch: 010, Loss: 2.6345, Val: 3.3807, Test: 3.4677\n",
      "\t\t -- train_counter: 192, test_counter:24\n",
      "Sat Jan  1 22:38:58 2022\tEpoch: 011, Loss: 2.6173, Val: 3.1828, Test: 3.3370\n",
      "\t\t -- train_counter: 188, test_counter:27\n",
      "Sat Jan  1 22:39:01 2022\tEpoch: 012, Loss: 2.6294, Val: 2.9635, Test: 3.0853\n",
      "\t\t -- train_counter: 195, test_counter:30\n",
      "Sat Jan  1 22:39:04 2022\tEpoch: 013, Loss: 2.5928, Val: 3.0225, Test: 3.0932\n",
      "\t\t -- train_counter: 192, test_counter:30\n",
      "Sat Jan  1 22:39:07 2022\tEpoch: 014, Loss: 2.6004, Val: 2.8526, Test: 3.0384\n",
      "\t\t -- train_counter: 216, test_counter:35\n",
      "Sat Jan  1 22:39:10 2022\tEpoch: 015, Loss: 2.5638, Val: 2.7659, Test: 2.9128\n",
      "\t\t -- train_counter: 210, test_counter:46\n",
      "Sat Jan  1 22:39:13 2022\tEpoch: 016, Loss: 2.5550, Val: 2.7309, Test: 2.9534\n",
      "\t\t -- train_counter: 223, test_counter:39\n",
      "Sat Jan  1 22:39:16 2022\tEpoch: 017, Loss: 2.5195, Val: 2.8920, Test: 3.1362\n",
      "\t\t -- train_counter: 253, test_counter:26\n",
      "Sat Jan  1 22:39:19 2022\tEpoch: 018, Loss: 2.5164, Val: 3.0160, Test: 3.1928\n",
      "\t\t -- train_counter: 222, test_counter:30\n",
      "Sat Jan  1 22:39:22 2022\tEpoch: 019, Loss: 2.5085, Val: 2.9630, Test: 3.2645\n",
      "\t\t -- train_counter: 243, test_counter:31\n",
      "Sat Jan  1 22:39:25 2022\tEpoch: 020, Loss: 2.4912, Val: 3.1425, Test: 3.3176\n",
      "\t\t -- train_counter: 237, test_counter:36\n",
      "Sat Jan  1 22:39:27 2022\tEpoch: 021, Loss: 2.4343, Val: 3.0307, Test: 3.2542\n",
      "\t\t -- train_counter: 275, test_counter:24\n",
      "Sat Jan  1 22:39:30 2022\tEpoch: 022, Loss: 2.3657, Val: 3.2443, Test: 3.3581\n",
      "\t\t -- train_counter: 291, test_counter:39\n",
      "Sat Jan  1 22:39:33 2022\tEpoch: 023, Loss: 2.3977, Val: 3.1582, Test: 3.3505\n",
      "\t\t -- train_counter: 298, test_counter:40\n",
      "Sat Jan  1 22:39:36 2022\tEpoch: 024, Loss: 2.3911, Val: 3.0260, Test: 3.3380\n",
      "\t\t -- train_counter: 273, test_counter:34\n",
      "Sat Jan  1 22:39:39 2022\tEpoch: 025, Loss: 2.3261, Val: 3.1778, Test: 3.3794\n",
      "\t\t -- train_counter: 291, test_counter:32\n",
      "Sat Jan  1 22:39:42 2022\tEpoch: 026, Loss: 2.3391, Val: 3.0175, Test: 3.2265\n",
      "\t\t -- train_counter: 274, test_counter:52\n",
      "Sat Jan  1 22:39:44 2022\tEpoch: 027, Loss: 2.2996, Val: 3.0457, Test: 3.5006\n",
      "\t\t -- train_counter: 307, test_counter:20\n",
      "Sat Jan  1 22:39:47 2022\tEpoch: 028, Loss: 2.2806, Val: 3.2812, Test: 3.4288\n",
      "\t\t -- train_counter: 325, test_counter:25\n",
      "Sat Jan  1 22:39:50 2022\tEpoch: 029, Loss: 2.2364, Val: 3.5218, Test: 3.7313\n",
      "\t\t -- train_counter: 339, test_counter:31\n",
      "Sat Jan  1 22:39:53 2022\tEpoch: 030, Loss: 2.2257, Val: 4.2313, Test: 4.4286\n",
      "\t\t -- train_counter: 338, test_counter:25\n",
      "Sat Jan  1 22:39:56 2022\tEpoch: 031, Loss: 2.2016, Val: 4.2642, Test: 4.3692\n",
      "\t\t -- train_counter: 353, test_counter:23\n",
      "Sat Jan  1 22:39:59 2022\tEpoch: 032, Loss: 2.1819, Val: 3.8360, Test: 4.0334\n",
      "\t\t -- train_counter: 344, test_counter:25\n",
      "Sat Jan  1 22:40:01 2022\tEpoch: 033, Loss: 2.1492, Val: 3.1367, Test: 3.2081\n",
      "\t\t -- train_counter: 358, test_counter:34\n",
      "Sat Jan  1 22:40:04 2022\tEpoch: 034, Loss: 2.1015, Val: 4.0827, Test: 4.3834\n",
      "\t\t -- train_counter: 378, test_counter:36\n",
      "Sat Jan  1 22:40:07 2022\tEpoch: 035, Loss: 2.0393, Val: 4.4914, Test: 4.5057\n",
      "\t\t -- train_counter: 396, test_counter:26\n",
      "Sat Jan  1 22:40:10 2022\tEpoch: 036, Loss: 2.1013, Val: 3.1618, Test: 3.3439\n",
      "\t\t -- train_counter: 381, test_counter:35\n",
      "Sat Jan  1 22:40:13 2022\tEpoch: 037, Loss: 2.0873, Val: 3.1200, Test: 3.2528\n",
      "\t\t -- train_counter: 400, test_counter:34\n",
      "Sat Jan  1 22:40:16 2022\tEpoch: 038, Loss: 2.0362, Val: 3.2997, Test: 3.4017\n",
      "\t\t -- train_counter: 407, test_counter:36\n",
      "Sat Jan  1 22:40:19 2022\tEpoch: 039, Loss: 2.0330, Val: 3.1346, Test: 3.2340\n",
      "\t\t -- train_counter: 415, test_counter:34\n",
      "Sat Jan  1 22:40:22 2022\tEpoch: 040, Loss: 1.9513, Val: 4.4087, Test: 5.1577\n",
      "\t\t -- train_counter: 439, test_counter:28\n",
      "Sat Jan  1 22:40:24 2022\tEpoch: 041, Loss: 1.9807, Val: 3.4380, Test: 3.6396\n",
      "\t\t -- train_counter: 455, test_counter:34\n",
      "Sat Jan  1 22:40:27 2022\tEpoch: 042, Loss: 1.9940, Val: 3.2471, Test: 3.4584\n",
      "\t\t -- train_counter: 420, test_counter:45\n",
      "Sat Jan  1 22:40:30 2022\tEpoch: 043, Loss: 1.9453, Val: 4.7838, Test: 4.7559\n",
      "\t\t -- train_counter: 446, test_counter:31\n",
      "Sat Jan  1 22:40:33 2022\tEpoch: 044, Loss: 1.9094, Val: 2.7117, Test: 2.8785\n",
      "\t\t -- train_counter: 466, test_counter:57\n",
      "Sat Jan  1 22:40:36 2022\tEpoch: 045, Loss: 1.9092, Val: 3.1294, Test: 3.2210\n",
      "\t\t -- train_counter: 470, test_counter:51\n",
      "Sat Jan  1 22:40:39 2022\tEpoch: 046, Loss: 1.9017, Val: 3.7694, Test: 4.0293\n",
      "\t\t -- train_counter: 465, test_counter:46\n",
      "Sat Jan  1 22:40:42 2022\tEpoch: 047, Loss: 1.9072, Val: 3.3864, Test: 3.4568\n",
      "\t\t -- train_counter: 450, test_counter:43\n",
      "Sat Jan  1 22:40:44 2022\tEpoch: 048, Loss: 1.9324, Val: 3.1545, Test: 3.2010\n",
      "\t\t -- train_counter: 453, test_counter:53\n",
      "Sat Jan  1 22:40:47 2022\tEpoch: 049, Loss: 1.9015, Val: 3.4263, Test: 3.5895\n",
      "\t\t -- train_counter: 450, test_counter:48\n",
      "Sat Jan  1 22:40:50 2022\tEpoch: 050, Loss: 1.8692, Val: 6.3994, Test: 6.5791\n",
      "\t\t -- train_counter: 467, test_counter:26\n",
      "Sat Jan  1 22:40:53 2022\tEpoch: 051, Loss: 1.8124, Val: 3.9564, Test: 3.9335\n",
      "\t\t -- train_counter: 504, test_counter:26\n",
      "Sat Jan  1 22:40:56 2022\tEpoch: 052, Loss: 1.8626, Val: 2.5438, Test: 2.8037\n",
      "\t\t -- train_counter: 507, test_counter:54\n",
      "Sat Jan  1 22:40:59 2022\tEpoch: 053, Loss: 1.8062, Val: 2.4986, Test: 2.7117\n",
      "\t\t -- train_counter: 485, test_counter:63\n",
      "Sat Jan  1 22:41:02 2022\tEpoch: 054, Loss: 1.8258, Val: 2.6641, Test: 2.9442\n",
      "\t\t -- train_counter: 497, test_counter:62\n",
      "Sat Jan  1 22:41:05 2022\tEpoch: 055, Loss: 1.8118, Val: 3.2565, Test: 3.5730\n",
      "\t\t -- train_counter: 519, test_counter:49\n",
      "Sat Jan  1 22:41:08 2022\tEpoch: 056, Loss: 1.7958, Val: 2.6792, Test: 2.8120\n",
      "\t\t -- train_counter: 519, test_counter:62\n",
      "Sat Jan  1 22:41:11 2022\tEpoch: 057, Loss: 1.7941, Val: 2.7493, Test: 3.1349\n",
      "\t\t -- train_counter: 501, test_counter:42\n",
      "Sat Jan  1 22:41:14 2022\tEpoch: 058, Loss: 1.7391, Val: 2.6419, Test: 2.9099\n",
      "\t\t -- train_counter: 537, test_counter:61\n",
      "Sat Jan  1 22:41:17 2022\tEpoch: 059, Loss: 1.7671, Val: 2.4361, Test: 2.6785\n",
      "\t\t -- train_counter: 521, test_counter:67\n",
      "Sat Jan  1 22:41:19 2022\tEpoch: 060, Loss: 1.7496, Val: 2.6625, Test: 2.9735\n",
      "\t\t -- train_counter: 522, test_counter:57\n",
      "Sat Jan  1 22:41:22 2022\tEpoch: 061, Loss: 1.7290, Val: 3.7042, Test: 4.1170\n",
      "\t\t -- train_counter: 567, test_counter:48\n",
      "Sat Jan  1 22:41:25 2022\tEpoch: 062, Loss: 1.6706, Val: 2.6870, Test: 2.9466\n",
      "\t\t -- train_counter: 566, test_counter:80\n",
      "Sat Jan  1 22:41:28 2022\tEpoch: 063, Loss: 1.6698, Val: 3.1540, Test: 3.0925\n",
      "\t\t -- train_counter: 574, test_counter:42\n",
      "Sat Jan  1 22:41:31 2022\tEpoch: 064, Loss: 1.6516, Val: 4.7793, Test: 4.7991\n",
      "\t\t -- train_counter: 568, test_counter:43\n",
      "Sat Jan  1 22:41:34 2022\tEpoch: 065, Loss: 1.7521, Val: 2.6375, Test: 2.8727\n",
      "\t\t -- train_counter: 552, test_counter:69\n",
      "Sat Jan  1 22:41:36 2022\tEpoch: 066, Loss: 1.7615, Val: 2.5240, Test: 2.8313\n",
      "\t\t -- train_counter: 552, test_counter:63\n",
      "Sat Jan  1 22:41:39 2022\tEpoch: 067, Loss: 1.6994, Val: 2.7042, Test: 2.6398\n",
      "\t\t -- train_counter: 577, test_counter:74\n",
      "Sat Jan  1 22:41:42 2022\tEpoch: 068, Loss: 1.6354, Val: 3.7015, Test: 4.0147\n",
      "\t\t -- train_counter: 587, test_counter:50\n",
      "Sat Jan  1 22:41:45 2022\tEpoch: 069, Loss: 1.6458, Val: 3.3561, Test: 3.6133\n",
      "\t\t -- train_counter: 607, test_counter:55\n",
      "Sat Jan  1 22:41:48 2022\tEpoch: 070, Loss: 1.6417, Val: 2.8585, Test: 3.1161\n",
      "\t\t -- train_counter: 601, test_counter:64\n",
      "Sat Jan  1 22:41:51 2022\tEpoch: 071, Loss: 1.6291, Val: 3.2294, Test: 3.5159\n",
      "\t\t -- train_counter: 600, test_counter:57\n",
      "Sat Jan  1 22:41:53 2022\tEpoch: 072, Loss: 1.5883, Val: 2.8066, Test: 2.7788\n",
      "\t\t -- train_counter: 592, test_counter:62\n",
      "Sat Jan  1 22:41:56 2022\tEpoch: 073, Loss: 1.6224, Val: 2.9178, Test: 3.2459\n",
      "\t\t -- train_counter: 596, test_counter:59\n",
      "Sat Jan  1 22:41:59 2022\tEpoch: 074, Loss: 1.6578, Val: 4.4308, Test: 4.9839\n",
      "\t\t -- train_counter: 598, test_counter:38\n",
      "Sat Jan  1 22:42:02 2022\tEpoch: 075, Loss: 1.7083, Val: 3.4163, Test: 3.2642\n",
      "\t\t -- train_counter: 568, test_counter:57\n",
      "Sat Jan  1 22:42:05 2022\tEpoch: 076, Loss: 1.6237, Val: 2.5435, Test: 2.7759\n",
      "\t\t -- train_counter: 597, test_counter:71\n",
      "Sat Jan  1 22:42:08 2022\tEpoch: 077, Loss: 1.5748, Val: 3.3496, Test: 3.7043\n",
      "\t\t -- train_counter: 635, test_counter:49\n",
      "Sat Jan  1 22:42:10 2022\tEpoch: 078, Loss: 1.6320, Val: 4.3137, Test: 4.7220\n",
      "\t\t -- train_counter: 603, test_counter:35\n",
      "Sat Jan  1 22:42:13 2022\tEpoch: 079, Loss: 1.6125, Val: 2.9023, Test: 3.0057\n",
      "\t\t -- train_counter: 610, test_counter:61\n",
      "Sat Jan  1 22:42:16 2022\tEpoch: 080, Loss: 1.6240, Val: 4.0225, Test: 4.3524\n",
      "\t\t -- train_counter: 598, test_counter:38\n",
      "Sat Jan  1 22:42:19 2022\tEpoch: 081, Loss: 1.5762, Val: 3.2253, Test: 3.3639\n",
      "\t\t -- train_counter: 641, test_counter:65\n",
      "Sat Jan  1 22:42:22 2022\tEpoch: 082, Loss: 1.6137, Val: 4.9950, Test: 5.1396\n",
      "\t\t -- train_counter: 642, test_counter:33\n",
      "Sat Jan  1 22:42:25 2022\tEpoch: 083, Loss: 1.5769, Val: 2.9522, Test: 3.2648\n",
      "\t\t -- train_counter: 623, test_counter:60\n",
      "Sat Jan  1 22:42:28 2022\tEpoch: 084, Loss: 1.5436, Val: 4.2666, Test: 4.8901\n",
      "\t\t -- train_counter: 637, test_counter:42\n",
      "Sat Jan  1 22:42:31 2022\tEpoch: 085, Loss: 1.5414, Val: 3.7205, Test: 4.3785\n",
      "\t\t -- train_counter: 652, test_counter:49\n",
      "Sat Jan  1 22:42:34 2022\tEpoch: 086, Loss: 1.5841, Val: 2.8214, Test: 2.9970\n",
      "\t\t -- train_counter: 673, test_counter:62\n",
      "Sat Jan  1 22:42:37 2022\tEpoch: 087, Loss: 1.4667, Val: 2.6307, Test: 2.5904\n",
      "\t\t -- train_counter: 686, test_counter:69\n",
      "Sat Jan  1 22:42:40 2022\tEpoch: 088, Loss: 1.5142, Val: 2.6799, Test: 2.7591\n",
      "\t\t -- train_counter: 660, test_counter:70\n",
      "Sat Jan  1 22:42:43 2022\tEpoch: 089, Loss: 1.4670, Val: 2.6737, Test: 2.7986\n",
      "\t\t -- train_counter: 695, test_counter:65\n",
      "Sat Jan  1 22:42:46 2022\tEpoch: 090, Loss: 1.4895, Val: 2.5903, Test: 2.7752\n",
      "\t\t -- train_counter: 659, test_counter:74\n",
      "Sat Jan  1 22:42:49 2022\tEpoch: 091, Loss: 1.4623, Val: 2.6074, Test: 2.6621\n",
      "\t\t -- train_counter: 704, test_counter:71\n",
      "Sat Jan  1 22:42:51 2022\tEpoch: 092, Loss: 1.4549, Val: 6.6393, Test: 6.9680\n",
      "\t\t -- train_counter: 681, test_counter:27\n",
      "Sat Jan  1 22:42:54 2022\tEpoch: 093, Loss: 1.4336, Val: 6.1879, Test: 6.3285\n",
      "\t\t -- train_counter: 697, test_counter:34\n",
      "Sat Jan  1 22:42:57 2022\tEpoch: 094, Loss: 1.4116, Val: 4.0878, Test: 4.5466\n",
      "\t\t -- train_counter: 738, test_counter:46\n",
      "Sat Jan  1 22:43:00 2022\tEpoch: 095, Loss: 1.4464, Val: 2.7980, Test: 2.9424\n",
      "\t\t -- train_counter: 705, test_counter:65\n",
      "Sat Jan  1 22:43:03 2022\tEpoch: 096, Loss: 1.3829, Val: 2.6682, Test: 2.9701\n",
      "\t\t -- train_counter: 723, test_counter:68\n",
      "Sat Jan  1 22:43:06 2022\tEpoch: 097, Loss: 1.3543, Val: 2.5387, Test: 3.0555\n",
      "\t\t -- train_counter: 732, test_counter:71\n",
      "Sat Jan  1 22:43:09 2022\tEpoch: 098, Loss: 1.3822, Val: 2.8388, Test: 3.1293\n",
      "\t\t -- train_counter: 732, test_counter:67\n",
      "Sat Jan  1 22:43:12 2022\tEpoch: 099, Loss: 1.3294, Val: 2.7661, Test: 3.5594\n",
      "\t\t -- train_counter: 756, test_counter:56\n",
      "Sat Jan  1 22:43:15 2022\tEpoch: 100, Loss: 1.3736, Val: 3.0896, Test: 3.4514\n",
      "\t\t -- train_counter: 747, test_counter:53\n",
      "Sat Jan  1 22:43:18 2022\tEpoch: 101, Loss: 1.3698, Val: 2.7463, Test: 3.0898\n",
      "\t\t -- train_counter: 741, test_counter:65\n",
      "Sat Jan  1 22:43:21 2022\tEpoch: 102, Loss: 1.3527, Val: 2.7507, Test: 3.0010\n",
      "\t\t -- train_counter: 753, test_counter:71\n",
      "Sat Jan  1 22:43:24 2022\tEpoch: 103, Loss: 1.3438, Val: 3.0692, Test: 3.2787\n",
      "\t\t -- train_counter: 760, test_counter:79\n",
      "Sat Jan  1 22:43:26 2022\tEpoch: 104, Loss: 1.3158, Val: 3.4179, Test: 4.1242\n",
      "\t\t -- train_counter: 768, test_counter:53\n",
      "Sat Jan  1 22:43:29 2022\tEpoch: 105, Loss: 1.3771, Val: 3.8621, Test: 4.3610\n",
      "\t\t -- train_counter: 741, test_counter:53\n",
      "Sat Jan  1 22:43:32 2022\tEpoch: 106, Loss: 1.3763, Val: 2.8336, Test: 3.3244\n",
      "\t\t -- train_counter: 732, test_counter:74\n",
      "Sat Jan  1 22:43:35 2022\tEpoch: 107, Loss: 1.2979, Val: 2.8392, Test: 3.1531\n",
      "\t\t -- train_counter: 786, test_counter:60\n",
      "Sat Jan  1 22:43:38 2022\tEpoch: 108, Loss: 1.3168, Val: 3.1351, Test: 3.6266\n",
      "\t\t -- train_counter: 758, test_counter:56\n",
      "Sat Jan  1 22:43:41 2022\tEpoch: 109, Loss: 1.3092, Val: 2.8337, Test: 2.9040\n",
      "\t\t -- train_counter: 756, test_counter:87\n",
      "Sat Jan  1 22:43:44 2022\tEpoch: 110, Loss: 1.3208, Val: 3.3560, Test: 3.7243\n",
      "\t\t -- train_counter: 794, test_counter:64\n",
      "Sat Jan  1 22:43:47 2022\tEpoch: 111, Loss: 1.2985, Val: 2.7581, Test: 3.1672\n",
      "\t\t -- train_counter: 770, test_counter:70\n",
      "Sat Jan  1 22:43:50 2022\tEpoch: 112, Loss: 1.2905, Val: 3.2930, Test: 3.3994\n",
      "\t\t -- train_counter: 772, test_counter:58\n",
      "Sat Jan  1 22:43:53 2022\tEpoch: 113, Loss: 1.2736, Val: 3.9309, Test: 4.1986\n",
      "\t\t -- train_counter: 777, test_counter:53\n",
      "Sat Jan  1 22:43:56 2022\tEpoch: 114, Loss: 1.2747, Val: 2.8405, Test: 3.3099\n",
      "\t\t -- train_counter: 793, test_counter:73\n",
      "Sat Jan  1 22:43:58 2022\tEpoch: 115, Loss: 1.3222, Val: 3.4994, Test: 3.8864\n",
      "\t\t -- train_counter: 767, test_counter:59\n",
      "Sat Jan  1 22:44:01 2022\tEpoch: 116, Loss: 1.3071, Val: 2.6970, Test: 3.2019\n",
      "\t\t -- train_counter: 769, test_counter:71\n",
      "Sat Jan  1 22:44:04 2022\tEpoch: 117, Loss: 1.2988, Val: 2.7920, Test: 3.1525\n",
      "\t\t -- train_counter: 795, test_counter:64\n",
      "Sat Jan  1 22:44:07 2022\tEpoch: 118, Loss: 1.2231, Val: 2.9255, Test: 2.9195\n",
      "\t\t -- train_counter: 815, test_counter:69\n",
      "Sat Jan  1 22:44:10 2022\tEpoch: 119, Loss: 1.1912, Val: 3.0071, Test: 3.2577\n",
      "\t\t -- train_counter: 819, test_counter:65\n",
      "Sat Jan  1 22:44:13 2022\tEpoch: 120, Loss: 1.2084, Val: 3.5049, Test: 3.7520\n",
      "\t\t -- train_counter: 814, test_counter:42\n",
      "Sat Jan  1 22:44:16 2022\tEpoch: 121, Loss: 1.1578, Val: 3.1912, Test: 3.4351\n",
      "\t\t -- train_counter: 844, test_counter:65\n",
      "Sat Jan  1 22:44:18 2022\tEpoch: 122, Loss: 1.1824, Val: 3.6267, Test: 3.8274\n",
      "\t\t -- train_counter: 837, test_counter:67\n",
      "Sat Jan  1 22:44:21 2022\tEpoch: 123, Loss: 1.2486, Val: 2.7277, Test: 3.2655\n",
      "\t\t -- train_counter: 821, test_counter:63\n",
      "Sat Jan  1 22:44:24 2022\tEpoch: 124, Loss: 1.2271, Val: 2.8614, Test: 3.3392\n",
      "\t\t -- train_counter: 817, test_counter:72\n",
      "Sat Jan  1 22:44:26 2022\tEpoch: 125, Loss: 1.1590, Val: 2.7597, Test: 3.0025\n",
      "\t\t -- train_counter: 833, test_counter:72\n",
      "Sat Jan  1 22:44:29 2022\tEpoch: 126, Loss: 1.1884, Val: 3.0692, Test: 3.3097\n",
      "\t\t -- train_counter: 844, test_counter:75\n",
      "Sat Jan  1 22:44:31 2022\tEpoch: 127, Loss: 1.1550, Val: 5.0352, Test: 5.6860\n",
      "\t\t -- train_counter: 867, test_counter:43\n",
      "Sat Jan  1 22:44:34 2022\tEpoch: 128, Loss: 1.1833, Val: 3.8701, Test: 4.2638\n",
      "\t\t -- train_counter: 853, test_counter:55\n",
      "Sat Jan  1 22:44:37 2022\tEpoch: 129, Loss: 1.2236, Val: 3.9882, Test: 4.6789\n",
      "\t\t -- train_counter: 785, test_counter:58\n",
      "Sat Jan  1 22:44:39 2022\tEpoch: 130, Loss: 1.2166, Val: 3.4379, Test: 3.7823\n",
      "\t\t -- train_counter: 825, test_counter:65\n",
      "Sat Jan  1 22:44:42 2022\tEpoch: 131, Loss: 1.2238, Val: 3.2189, Test: 3.8404\n",
      "\t\t -- train_counter: 816, test_counter:55\n",
      "Sat Jan  1 22:44:44 2022\tEpoch: 132, Loss: 1.2117, Val: 3.0061, Test: 3.1879\n",
      "\t\t -- train_counter: 839, test_counter:65\n",
      "Sat Jan  1 22:44:47 2022\tEpoch: 133, Loss: 1.1931, Val: 4.4328, Test: 5.3189\n",
      "\t\t -- train_counter: 849, test_counter:40\n",
      "Sat Jan  1 22:44:50 2022\tEpoch: 134, Loss: 1.1854, Val: 5.5013, Test: 6.1279\n",
      "\t\t -- train_counter: 822, test_counter:29\n",
      "Sat Jan  1 22:44:52 2022\tEpoch: 135, Loss: 1.1931, Val: 5.0900, Test: 5.9450\n",
      "\t\t -- train_counter: 852, test_counter:41\n",
      "Sat Jan  1 22:44:55 2022\tEpoch: 136, Loss: 1.1542, Val: 4.7502, Test: 5.1969\n",
      "\t\t -- train_counter: 853, test_counter:52\n",
      "Sat Jan  1 22:44:58 2022\tEpoch: 137, Loss: 1.1252, Val: 3.9338, Test: 4.3229\n",
      "\t\t -- train_counter: 867, test_counter:56\n",
      "Sat Jan  1 22:45:01 2022\tEpoch: 138, Loss: 1.1059, Val: 3.1225, Test: 3.5278\n",
      "\t\t -- train_counter: 864, test_counter:68\n",
      "Sat Jan  1 22:45:04 2022\tEpoch: 139, Loss: 1.1352, Val: 3.0629, Test: 3.5668\n",
      "\t\t -- train_counter: 867, test_counter:76\n",
      "Sat Jan  1 22:45:07 2022\tEpoch: 140, Loss: 1.0941, Val: 4.1564, Test: 4.7082\n",
      "\t\t -- train_counter: 878, test_counter:51\n",
      "Sat Jan  1 22:45:10 2022\tEpoch: 141, Loss: 1.1930, Val: 5.3310, Test: 5.5292\n",
      "\t\t -- train_counter: 857, test_counter:49\n",
      "Sat Jan  1 22:45:13 2022\tEpoch: 142, Loss: 1.1617, Val: 3.7504, Test: 4.3675\n",
      "\t\t -- train_counter: 842, test_counter:67\n",
      "Sat Jan  1 22:45:16 2022\tEpoch: 143, Loss: 1.0919, Val: 4.5568, Test: 4.9645\n",
      "\t\t -- train_counter: 873, test_counter:49\n",
      "Sat Jan  1 22:45:18 2022\tEpoch: 144, Loss: 1.1057, Val: 3.5931, Test: 4.0488\n",
      "\t\t -- train_counter: 878, test_counter:43\n",
      "Sat Jan  1 22:45:21 2022\tEpoch: 145, Loss: 1.1402, Val: 2.9377, Test: 3.0863\n",
      "\t\t -- train_counter: 845, test_counter:71\n",
      "Sat Jan  1 22:45:24 2022\tEpoch: 146, Loss: 1.1160, Val: 3.5617, Test: 4.2778\n",
      "\t\t -- train_counter: 867, test_counter:54\n",
      "Sat Jan  1 22:45:27 2022\tEpoch: 147, Loss: 1.0740, Val: 3.1660, Test: 3.6003\n",
      "\t\t -- train_counter: 901, test_counter:62\n",
      "Sat Jan  1 22:45:30 2022\tEpoch: 148, Loss: 1.1361, Val: 2.7260, Test: 3.3429\n",
      "\t\t -- train_counter: 876, test_counter:65\n",
      "Sat Jan  1 22:45:33 2022\tEpoch: 149, Loss: 1.0788, Val: 2.9274, Test: 3.3415\n",
      "\t\t -- train_counter: 882, test_counter:68\n",
      "Sat Jan  1 22:45:36 2022\tEpoch: 150, Loss: 1.0486, Val: 4.9904, Test: 5.2539\n",
      "\t\t -- train_counter: 904, test_counter:47\n",
      "Sat Jan  1 22:45:38 2022\tEpoch: 151, Loss: 1.0374, Val: 6.2462, Test: 6.5816\n",
      "\t\t -- train_counter: 915, test_counter:41\n",
      "Sat Jan  1 22:45:41 2022\tEpoch: 152, Loss: 1.0925, Val: 4.4762, Test: 5.2786\n",
      "\t\t -- train_counter: 881, test_counter:55\n",
      "Sat Jan  1 22:45:44 2022\tEpoch: 153, Loss: 1.1113, Val: 3.4447, Test: 4.0519\n",
      "\t\t -- train_counter: 895, test_counter:65\n",
      "Sat Jan  1 22:45:47 2022\tEpoch: 154, Loss: 1.0499, Val: 3.1926, Test: 3.5038\n",
      "\t\t -- train_counter: 908, test_counter:61\n",
      "Sat Jan  1 22:45:49 2022\tEpoch: 155, Loss: 1.0416, Val: 3.0268, Test: 3.3569\n",
      "\t\t -- train_counter: 893, test_counter:71\n",
      "Sat Jan  1 22:45:52 2022\tEpoch: 156, Loss: 1.1399, Val: 3.1146, Test: 3.3372\n",
      "\t\t -- train_counter: 889, test_counter:62\n",
      "Sat Jan  1 22:45:55 2022\tEpoch: 157, Loss: 1.0305, Val: 3.3115, Test: 3.6943\n",
      "\t\t -- train_counter: 920, test_counter:62\n",
      "Sat Jan  1 22:45:58 2022\tEpoch: 158, Loss: 1.0459, Val: 3.1539, Test: 3.4070\n",
      "\t\t -- train_counter: 911, test_counter:62\n",
      "Sat Jan  1 22:46:01 2022\tEpoch: 159, Loss: 1.0437, Val: 3.0096, Test: 3.3677\n",
      "\t\t -- train_counter: 936, test_counter:72\n",
      "Sat Jan  1 22:46:04 2022\tEpoch: 160, Loss: 1.0196, Val: 2.9732, Test: 3.2571\n",
      "\t\t -- train_counter: 911, test_counter:76\n",
      "Sat Jan  1 22:46:06 2022\tEpoch: 161, Loss: 0.9687, Val: 4.1545, Test: 4.4670\n",
      "\t\t -- train_counter: 946, test_counter:46\n",
      "Sat Jan  1 22:46:09 2022\tEpoch: 162, Loss: 1.0306, Val: 2.8561, Test: 3.0826\n",
      "\t\t -- train_counter: 930, test_counter:71\n",
      "Sat Jan  1 22:46:12 2022\tEpoch: 163, Loss: 1.0021, Val: 2.9726, Test: 3.5106\n",
      "\t\t -- train_counter: 948, test_counter:58\n",
      "Sat Jan  1 22:46:14 2022\tEpoch: 164, Loss: 1.0356, Val: 3.2382, Test: 3.3696\n",
      "\t\t -- train_counter: 915, test_counter:85\n",
      "Sat Jan  1 22:46:17 2022\tEpoch: 165, Loss: 1.0268, Val: 3.1881, Test: 3.4569\n",
      "\t\t -- train_counter: 926, test_counter:69\n",
      "Sat Jan  1 22:46:20 2022\tEpoch: 166, Loss: 1.0204, Val: 2.8792, Test: 3.2992\n",
      "\t\t -- train_counter: 915, test_counter:65\n",
      "Sat Jan  1 22:46:22 2022\tEpoch: 167, Loss: 0.9585, Val: 3.0571, Test: 3.1381\n",
      "\t\t -- train_counter: 945, test_counter:72\n",
      "Sat Jan  1 22:46:26 2022\tEpoch: 168, Loss: 1.0033, Val: 3.0521, Test: 3.1765\n",
      "\t\t -- train_counter: 947, test_counter:67\n",
      "Sat Jan  1 22:46:29 2022\tEpoch: 169, Loss: 1.0191, Val: 3.2353, Test: 3.7751\n",
      "\t\t -- train_counter: 920, test_counter:72\n",
      "Sat Jan  1 22:46:32 2022\tEpoch: 170, Loss: 1.0253, Val: 3.0159, Test: 3.5995\n",
      "\t\t -- train_counter: 920, test_counter:64\n",
      "Sat Jan  1 22:46:34 2022\tEpoch: 171, Loss: 0.9769, Val: 2.9157, Test: 3.2318\n",
      "\t\t -- train_counter: 967, test_counter:71\n",
      "Sat Jan  1 22:46:37 2022\tEpoch: 172, Loss: 0.9626, Val: 3.5491, Test: 3.8627\n",
      "\t\t -- train_counter: 943, test_counter:62\n",
      "Sat Jan  1 22:46:40 2022\tEpoch: 173, Loss: 0.9341, Val: 3.6467, Test: 4.1417\n",
      "\t\t -- train_counter: 958, test_counter:60\n",
      "Sat Jan  1 22:46:42 2022\tEpoch: 174, Loss: 1.0125, Val: 3.7360, Test: 4.1129\n",
      "\t\t -- train_counter: 945, test_counter:61\n",
      "Sat Jan  1 22:46:45 2022\tEpoch: 175, Loss: 0.9457, Val: 3.5030, Test: 4.4983\n",
      "\t\t -- train_counter: 940, test_counter:62\n",
      "Sat Jan  1 22:46:48 2022\tEpoch: 176, Loss: 0.9503, Val: 3.4089, Test: 3.4470\n",
      "\t\t -- train_counter: 976, test_counter:67\n",
      "Sat Jan  1 22:46:50 2022\tEpoch: 177, Loss: 0.9505, Val: 4.2019, Test: 4.9326\n",
      "\t\t -- train_counter: 960, test_counter:24\n",
      "Sat Jan  1 22:46:54 2022\tEpoch: 178, Loss: 0.9635, Val: 3.1232, Test: 3.5706\n",
      "\t\t -- train_counter: 940, test_counter:46\n",
      "Sat Jan  1 22:46:57 2022\tEpoch: 179, Loss: 0.9790, Val: 3.7180, Test: 4.1117\n",
      "\t\t -- train_counter: 925, test_counter:64\n",
      "Sat Jan  1 22:47:00 2022\tEpoch: 180, Loss: 1.0060, Val: 4.8057, Test: 5.1959\n",
      "\t\t -- train_counter: 935, test_counter:51\n",
      "Sat Jan  1 22:47:02 2022\tEpoch: 181, Loss: 0.9202, Val: 2.8983, Test: 3.0077\n",
      "\t\t -- train_counter: 964, test_counter:80\n",
      "Sat Jan  1 22:47:05 2022\tEpoch: 182, Loss: 0.9568, Val: 3.1452, Test: 3.4357\n",
      "\t\t -- train_counter: 966, test_counter:60\n",
      "Sat Jan  1 22:47:08 2022\tEpoch: 183, Loss: 0.9573, Val: 3.2842, Test: 3.3099\n",
      "\t\t -- train_counter: 975, test_counter:75\n",
      "Sat Jan  1 22:47:10 2022\tEpoch: 184, Loss: 0.9020, Val: 3.3179, Test: 3.3828\n",
      "\t\t -- train_counter: 1002, test_counter:78\n",
      "Sat Jan  1 22:47:13 2022\tEpoch: 185, Loss: 0.9793, Val: 3.2754, Test: 3.2955\n",
      "\t\t -- train_counter: 949, test_counter:66\n",
      "Sat Jan  1 22:47:15 2022\tEpoch: 186, Loss: 0.9183, Val: 3.1112, Test: 3.3496\n",
      "\t\t -- train_counter: 985, test_counter:71\n",
      "Sat Jan  1 22:47:18 2022\tEpoch: 187, Loss: 0.9125, Val: 3.3078, Test: 3.3276\n",
      "\t\t -- train_counter: 954, test_counter:65\n",
      "Sat Jan  1 22:47:21 2022\tEpoch: 188, Loss: 0.9309, Val: 3.5530, Test: 3.8173\n",
      "\t\t -- train_counter: 957, test_counter:51\n",
      "Sat Jan  1 22:47:24 2022\tEpoch: 189, Loss: 0.9272, Val: 3.2539, Test: 3.3826\n",
      "\t\t -- train_counter: 952, test_counter:65\n",
      "Sat Jan  1 22:47:27 2022\tEpoch: 190, Loss: 0.8962, Val: 3.4983, Test: 3.7005\n",
      "\t\t -- train_counter: 981, test_counter:69\n",
      "Sat Jan  1 22:47:30 2022\tEpoch: 191, Loss: 0.9243, Val: 3.4839, Test: 3.7481\n",
      "\t\t -- train_counter: 973, test_counter:60\n",
      "Sat Jan  1 22:47:32 2022\tEpoch: 192, Loss: 0.8903, Val: 3.3359, Test: 3.3724\n",
      "\t\t -- train_counter: 1011, test_counter:79\n",
      "Sat Jan  1 22:47:35 2022\tEpoch: 193, Loss: 0.8969, Val: 3.8703, Test: 4.1378\n",
      "\t\t -- train_counter: 997, test_counter:66\n",
      "Sat Jan  1 22:47:38 2022\tEpoch: 194, Loss: 0.8050, Val: 4.7117, Test: 4.8187\n",
      "\t\t -- train_counter: 1012, test_counter:45\n",
      "Sat Jan  1 22:47:41 2022\tEpoch: 195, Loss: 0.9508, Val: 4.2902, Test: 4.7315\n",
      "\t\t -- train_counter: 976, test_counter:54\n",
      "Sat Jan  1 22:47:43 2022\tEpoch: 196, Loss: 0.8892, Val: 6.5107, Test: 7.5563\n",
      "\t\t -- train_counter: 1000, test_counter:40\n",
      "Sat Jan  1 22:47:46 2022\tEpoch: 197, Loss: 0.9041, Val: 4.1884, Test: 4.7595\n",
      "\t\t -- train_counter: 996, test_counter:63\n",
      "Sat Jan  1 22:47:49 2022\tEpoch: 198, Loss: 0.9034, Val: 2.8706, Test: 3.4405\n",
      "\t\t -- train_counter: 1004, test_counter:62\n",
      "Sat Jan  1 22:47:53 2022\tEpoch: 199, Loss: 0.8989, Val: 3.2731, Test: 3.4738\n",
      "\t\t -- train_counter: 1005, test_counter:76\n",
      "Sat Jan  1 22:47:55 2022\tEpoch: 200, Loss: 0.9068, Val: 3.2853, Test: 3.6184\n",
      "\t\t -- train_counter: 983, test_counter:63\n",
      "Sat Jan  1 22:47:58 2022\tEpoch: 201, Loss: 0.9467, Val: 3.0437, Test: 3.3249\n",
      "\t\t -- train_counter: 975, test_counter:66\n",
      "Sat Jan  1 22:48:01 2022\tEpoch: 202, Loss: 0.8929, Val: 3.0958, Test: 3.3325\n",
      "\t\t -- train_counter: 974, test_counter:69\n",
      "Sat Jan  1 22:48:04 2022\tEpoch: 203, Loss: 0.9105, Val: 3.2132, Test: 3.2809\n",
      "\t\t -- train_counter: 987, test_counter:67\n",
      "Sat Jan  1 22:48:06 2022\tEpoch: 204, Loss: 0.8890, Val: 3.4954, Test: 3.5220\n",
      "\t\t -- train_counter: 1014, test_counter:73\n",
      "Sat Jan  1 22:48:09 2022\tEpoch: 205, Loss: 0.8546, Val: 3.1240, Test: 3.2339\n",
      "\t\t -- train_counter: 1014, test_counter:70\n",
      "Sat Jan  1 22:48:12 2022\tEpoch: 206, Loss: 0.8857, Val: 3.4695, Test: 3.5930\n",
      "\t\t -- train_counter: 1010, test_counter:71\n",
      "Sat Jan  1 22:48:14 2022\tEpoch: 207, Loss: 0.8462, Val: 3.0302, Test: 3.3156\n",
      "\t\t -- train_counter: 1009, test_counter:73\n",
      "Sat Jan  1 22:48:17 2022\tEpoch: 208, Loss: 0.8707, Val: 3.3734, Test: 3.8098\n",
      "\t\t -- train_counter: 1007, test_counter:67\n",
      "Sat Jan  1 22:48:20 2022\tEpoch: 209, Loss: 0.8445, Val: 3.8299, Test: 4.0228\n",
      "\t\t -- train_counter: 1023, test_counter:68\n",
      "Sat Jan  1 22:48:23 2022\tEpoch: 210, Loss: 0.8671, Val: 3.1143, Test: 3.3779\n",
      "\t\t -- train_counter: 1009, test_counter:77\n",
      "Sat Jan  1 22:48:26 2022\tEpoch: 211, Loss: 0.8781, Val: 3.1117, Test: 3.3505\n",
      "\t\t -- train_counter: 999, test_counter:87\n",
      "Sat Jan  1 22:48:28 2022\tEpoch: 212, Loss: 0.8626, Val: 4.1777, Test: 4.2826\n",
      "\t\t -- train_counter: 1016, test_counter:65\n",
      "Sat Jan  1 22:48:31 2022\tEpoch: 213, Loss: 0.8634, Val: 3.6562, Test: 3.8404\n",
      "\t\t -- train_counter: 1000, test_counter:58\n",
      "Sat Jan  1 22:48:34 2022\tEpoch: 214, Loss: 0.8835, Val: 3.4607, Test: 3.5252\n",
      "\t\t -- train_counter: 1002, test_counter:64\n",
      "Sat Jan  1 22:48:37 2022\tEpoch: 215, Loss: 0.8963, Val: 3.4264, Test: 3.6290\n",
      "\t\t -- train_counter: 991, test_counter:60\n",
      "Sat Jan  1 22:48:40 2022\tEpoch: 216, Loss: 0.8861, Val: 3.5737, Test: 3.8441\n",
      "\t\t -- train_counter: 1022, test_counter:77\n",
      "Sat Jan  1 22:48:43 2022\tEpoch: 217, Loss: 0.8622, Val: 3.3715, Test: 3.4049\n",
      "\t\t -- train_counter: 1023, test_counter:66\n",
      "Sat Jan  1 22:48:46 2022\tEpoch: 218, Loss: 0.9262, Val: 3.5213, Test: 3.7458\n",
      "\t\t -- train_counter: 985, test_counter:71\n",
      "Sat Jan  1 22:48:49 2022\tEpoch: 219, Loss: 0.8338, Val: 3.4051, Test: 3.7003\n",
      "\t\t -- train_counter: 1022, test_counter:70\n",
      "Sat Jan  1 22:48:51 2022\tEpoch: 220, Loss: 0.8797, Val: 3.1040, Test: 3.3135\n",
      "\t\t -- train_counter: 1000, test_counter:63\n",
      "Sat Jan  1 22:48:54 2022\tEpoch: 221, Loss: 0.8198, Val: 3.1398, Test: 3.2579\n",
      "\t\t -- train_counter: 1010, test_counter:62\n",
      "Sat Jan  1 22:48:57 2022\tEpoch: 222, Loss: 0.8390, Val: 3.2894, Test: 3.5683\n",
      "\t\t -- train_counter: 1046, test_counter:62\n",
      "Sat Jan  1 22:48:59 2022\tEpoch: 223, Loss: 0.8185, Val: 3.7432, Test: 3.5532\n",
      "\t\t -- train_counter: 1029, test_counter:74\n",
      "Sat Jan  1 22:49:02 2022\tEpoch: 224, Loss: 0.8521, Val: 3.2827, Test: 3.3395\n",
      "\t\t -- train_counter: 1037, test_counter:63\n",
      "Sat Jan  1 22:49:04 2022\tEpoch: 225, Loss: 0.8506, Val: 3.3597, Test: 3.5670\n",
      "\t\t -- train_counter: 1031, test_counter:61\n",
      "Sat Jan  1 22:49:07 2022\tEpoch: 226, Loss: 0.8875, Val: 3.1115, Test: 3.3298\n",
      "\t\t -- train_counter: 1014, test_counter:68\n",
      "Sat Jan  1 22:49:11 2022\tEpoch: 227, Loss: 0.8516, Val: 3.1052, Test: 3.1474\n",
      "\t\t -- train_counter: 1008, test_counter:73\n",
      "Sat Jan  1 22:49:14 2022\tEpoch: 228, Loss: 0.8717, Val: 10.1107, Test: 9.8444\n",
      "\t\t -- train_counter: 1007, test_counter:33\n",
      "Sat Jan  1 22:49:17 2022\tEpoch: 229, Loss: 0.8541, Val: 9.7464, Test: 9.5670\n",
      "\t\t -- train_counter: 1032, test_counter:34\n",
      "Sat Jan  1 22:49:19 2022\tEpoch: 230, Loss: 0.9281, Val: 7.2693, Test: 7.8680\n",
      "\t\t -- train_counter: 993, test_counter:35\n",
      "Sat Jan  1 22:49:22 2022\tEpoch: 231, Loss: 0.8785, Val: 3.3719, Test: 3.6442\n",
      "\t\t -- train_counter: 1006, test_counter:77\n",
      "Sat Jan  1 22:49:25 2022\tEpoch: 232, Loss: 0.8072, Val: 4.1459, Test: 4.2665\n",
      "\t\t -- train_counter: 1038, test_counter:33\n",
      "Sat Jan  1 22:49:27 2022\tEpoch: 233, Loss: 0.7863, Val: 3.3327, Test: 3.4811\n",
      "\t\t -- train_counter: 1039, test_counter:68\n",
      "Sat Jan  1 22:49:30 2022\tEpoch: 234, Loss: 0.7898, Val: 3.3129, Test: 3.7322\n",
      "\t\t -- train_counter: 1019, test_counter:61\n",
      "Sat Jan  1 22:49:33 2022\tEpoch: 235, Loss: 0.8353, Val: 3.4043, Test: 3.9732\n",
      "\t\t -- train_counter: 1017, test_counter:80\n",
      "Sat Jan  1 22:49:35 2022\tEpoch: 236, Loss: 0.7739, Val: 4.2569, Test: 4.8423\n",
      "\t\t -- train_counter: 1034, test_counter:61\n",
      "Sat Jan  1 22:49:38 2022\tEpoch: 237, Loss: 0.7136, Val: 3.4108, Test: 4.1082\n",
      "\t\t -- train_counter: 1076, test_counter:56\n",
      "Sat Jan  1 22:49:42 2022\tEpoch: 238, Loss: 0.7899, Val: 5.4953, Test: 5.6660\n",
      "\t\t -- train_counter: 1048, test_counter:50\n",
      "Sat Jan  1 22:49:44 2022\tEpoch: 239, Loss: 0.9147, Val: 14.7318, Test: 14.6758\n",
      "\t\t -- train_counter: 989, test_counter:30\n",
      "Sat Jan  1 22:49:47 2022\tEpoch: 240, Loss: 0.7793, Val: 4.7056, Test: 4.9910\n",
      "\t\t -- train_counter: 1042, test_counter:60\n",
      "Sat Jan  1 22:49:49 2022\tEpoch: 241, Loss: 0.7891, Val: 3.7585, Test: 3.8973\n",
      "\t\t -- train_counter: 1040, test_counter:75\n",
      "Sat Jan  1 22:49:52 2022\tEpoch: 242, Loss: 0.7993, Val: 4.1025, Test: 4.1063\n",
      "\t\t -- train_counter: 1031, test_counter:57\n",
      "Sat Jan  1 22:49:55 2022\tEpoch: 243, Loss: 0.8252, Val: 4.0246, Test: 5.0296\n",
      "\t\t -- train_counter: 1036, test_counter:45\n",
      "Sat Jan  1 22:49:57 2022\tEpoch: 244, Loss: 0.7572, Val: 4.1433, Test: 4.5233\n",
      "\t\t -- train_counter: 1041, test_counter:60\n",
      "Sat Jan  1 22:50:00 2022\tEpoch: 245, Loss: 0.7907, Val: 3.7558, Test: 4.1794\n",
      "\t\t -- train_counter: 1036, test_counter:60\n",
      "Sat Jan  1 22:50:03 2022\tEpoch: 246, Loss: 0.7466, Val: 3.3135, Test: 3.2396\n",
      "\t\t -- train_counter: 1055, test_counter:72\n",
      "Sat Jan  1 22:50:06 2022\tEpoch: 247, Loss: 0.7686, Val: 3.2909, Test: 3.4259\n",
      "\t\t -- train_counter: 1060, test_counter:74\n",
      "Sat Jan  1 22:50:09 2022\tEpoch: 248, Loss: 0.7866, Val: 3.9969, Test: 4.4147\n",
      "\t\t -- train_counter: 1042, test_counter:64\n",
      "Sat Jan  1 22:50:12 2022\tEpoch: 249, Loss: 0.8256, Val: 3.2543, Test: 3.5934\n",
      "\t\t -- train_counter: 1028, test_counter:69\n",
      "Sat Jan  1 22:50:14 2022\tEpoch: 250, Loss: 0.8315, Val: 2.9889, Test: 3.3838\n",
      "\t\t -- train_counter: 1045, test_counter:57\n",
      "Sat Jan  1 22:50:17 2022\tEpoch: 251, Loss: 0.7980, Val: 3.3203, Test: 3.2611\n",
      "\t\t -- train_counter: 1035, test_counter:81\n",
      "Sat Jan  1 22:50:20 2022\tEpoch: 252, Loss: 0.7115, Val: 3.2287, Test: 3.5307\n",
      "\t\t -- train_counter: 1080, test_counter:87\n",
      "Sat Jan  1 22:50:22 2022\tEpoch: 253, Loss: 0.7630, Val: 3.2672, Test: 3.5420\n",
      "\t\t -- train_counter: 1050, test_counter:66\n",
      "Sat Jan  1 22:50:25 2022\tEpoch: 254, Loss: 0.8227, Val: 3.7620, Test: 3.8426\n",
      "\t\t -- train_counter: 1028, test_counter:60\n",
      "Sat Jan  1 22:50:28 2022\tEpoch: 255, Loss: 0.7707, Val: 3.5987, Test: 3.4930\n",
      "\t\t -- train_counter: 1050, test_counter:70\n",
      "Sat Jan  1 22:50:30 2022\tEpoch: 256, Loss: 0.7482, Val: 3.6257, Test: 4.0887\n",
      "\t\t -- train_counter: 1037, test_counter:76\n",
      "Sat Jan  1 22:50:34 2022\tEpoch: 257, Loss: 0.7672, Val: 4.9673, Test: 5.4430\n",
      "\t\t -- train_counter: 1074, test_counter:52\n",
      "Sat Jan  1 22:50:37 2022\tEpoch: 258, Loss: 0.7288, Val: 3.5927, Test: 3.9908\n",
      "\t\t -- train_counter: 1067, test_counter:70\n",
      "Sat Jan  1 22:50:39 2022\tEpoch: 259, Loss: 0.7487, Val: 3.7548, Test: 4.0502\n",
      "\t\t -- train_counter: 1069, test_counter:64\n",
      "Sat Jan  1 22:50:42 2022\tEpoch: 260, Loss: 0.7757, Val: 3.4870, Test: 3.5954\n",
      "\t\t -- train_counter: 1055, test_counter:56\n",
      "Sat Jan  1 22:50:45 2022\tEpoch: 261, Loss: 0.7800, Val: 3.4912, Test: 3.3911\n",
      "\t\t -- train_counter: 1060, test_counter:73\n",
      "Sat Jan  1 22:50:47 2022\tEpoch: 262, Loss: 0.7716, Val: 3.3858, Test: 3.6854\n",
      "\t\t -- train_counter: 1056, test_counter:70\n",
      "Sat Jan  1 22:50:50 2022\tEpoch: 263, Loss: 0.7484, Val: 3.7773, Test: 4.1204\n",
      "\t\t -- train_counter: 1063, test_counter:59\n",
      "Sat Jan  1 22:50:53 2022\tEpoch: 264, Loss: 0.7446, Val: 4.0022, Test: 4.7515\n",
      "\t\t -- train_counter: 1059, test_counter:63\n",
      "Sat Jan  1 22:50:56 2022\tEpoch: 265, Loss: 0.7450, Val: 3.6533, Test: 3.9707\n",
      "\t\t -- train_counter: 1079, test_counter:67\n",
      "Sat Jan  1 22:50:58 2022\tEpoch: 266, Loss: 0.7573, Val: 3.3523, Test: 3.5307\n",
      "\t\t -- train_counter: 1048, test_counter:74\n",
      "Sat Jan  1 22:51:02 2022\tEpoch: 267, Loss: 0.7432, Val: 3.4534, Test: 3.4711\n",
      "\t\t -- train_counter: 1075, test_counter:61\n",
      "Sat Jan  1 22:51:05 2022\tEpoch: 268, Loss: 0.7553, Val: 3.4079, Test: 3.4931\n",
      "\t\t -- train_counter: 1069, test_counter:60\n",
      "Sat Jan  1 22:51:08 2022\tEpoch: 269, Loss: 0.7120, Val: 3.5089, Test: 3.8094\n",
      "\t\t -- train_counter: 1088, test_counter:60\n",
      "Sat Jan  1 22:51:10 2022\tEpoch: 270, Loss: 0.7774, Val: 3.5840, Test: 3.8652\n",
      "\t\t -- train_counter: 1052, test_counter:66\n",
      "Sat Jan  1 22:51:13 2022\tEpoch: 271, Loss: 0.7377, Val: 3.2601, Test: 3.6310\n",
      "\t\t -- train_counter: 1066, test_counter:60\n",
      "Sat Jan  1 22:51:16 2022\tEpoch: 272, Loss: 0.7398, Val: 3.4417, Test: 3.2357\n",
      "\t\t -- train_counter: 1075, test_counter:79\n",
      "Sat Jan  1 22:51:18 2022\tEpoch: 273, Loss: 0.7396, Val: 3.5683, Test: 3.6086\n",
      "\t\t -- train_counter: 1091, test_counter:55\n",
      "Sat Jan  1 22:51:21 2022\tEpoch: 274, Loss: 0.7478, Val: 3.1965, Test: 3.4671\n",
      "\t\t -- train_counter: 1089, test_counter:70\n",
      "Sat Jan  1 22:51:24 2022\tEpoch: 275, Loss: 0.7746, Val: 3.3147, Test: 3.6554\n",
      "\t\t -- train_counter: 1054, test_counter:65\n",
      "Sat Jan  1 22:51:26 2022\tEpoch: 276, Loss: 0.7935, Val: 3.3924, Test: 3.3796\n",
      "\t\t -- train_counter: 1053, test_counter:72\n",
      "Sat Jan  1 22:51:30 2022\tEpoch: 277, Loss: 0.7941, Val: 3.3794, Test: 3.4213\n",
      "\t\t -- train_counter: 1049, test_counter:61\n",
      "Sat Jan  1 22:51:33 2022\tEpoch: 278, Loss: 0.6813, Val: 4.2013, Test: 4.5124\n",
      "\t\t -- train_counter: 1104, test_counter:62\n",
      "Sat Jan  1 22:51:35 2022\tEpoch: 279, Loss: 0.7660, Val: 5.3034, Test: 5.5293\n",
      "\t\t -- train_counter: 1063, test_counter:65\n",
      "Sat Jan  1 22:51:38 2022\tEpoch: 280, Loss: 0.7431, Val: 3.5484, Test: 4.0660\n",
      "\t\t -- train_counter: 1077, test_counter:64\n",
      "Sat Jan  1 22:51:41 2022\tEpoch: 281, Loss: 0.7379, Val: 3.4181, Test: 3.5310\n",
      "\t\t -- train_counter: 1055, test_counter:68\n",
      "Sat Jan  1 22:51:43 2022\tEpoch: 282, Loss: 0.7064, Val: 3.4442, Test: 3.5257\n",
      "\t\t -- train_counter: 1098, test_counter:55\n",
      "Sat Jan  1 22:51:46 2022\tEpoch: 283, Loss: 0.7495, Val: 3.3458, Test: 3.5771\n",
      "\t\t -- train_counter: 1067, test_counter:65\n",
      "Sat Jan  1 22:51:49 2022\tEpoch: 284, Loss: 0.7214, Val: 3.4493, Test: 3.6721\n",
      "\t\t -- train_counter: 1081, test_counter:59\n",
      "Sat Jan  1 22:51:51 2022\tEpoch: 285, Loss: 0.7450, Val: 3.1740, Test: 3.2052\n",
      "\t\t -- train_counter: 1065, test_counter:67\n",
      "Sat Jan  1 22:51:54 2022\tEpoch: 286, Loss: 0.7150, Val: 3.4458, Test: 3.3565\n",
      "\t\t -- train_counter: 1074, test_counter:71\n",
      "Sat Jan  1 22:51:58 2022\tEpoch: 287, Loss: 0.7143, Val: 3.7032, Test: 3.6103\n",
      "\t\t -- train_counter: 1071, test_counter:75\n",
      "Sat Jan  1 22:52:01 2022\tEpoch: 288, Loss: 0.7550, Val: 3.7459, Test: 4.0238\n",
      "\t\t -- train_counter: 1073, test_counter:57\n",
      "Sat Jan  1 22:52:03 2022\tEpoch: 289, Loss: 0.7254, Val: 3.6250, Test: 4.0253\n",
      "\t\t -- train_counter: 1082, test_counter:61\n",
      "Sat Jan  1 22:52:06 2022\tEpoch: 290, Loss: 0.6616, Val: 3.3898, Test: 3.5196\n",
      "\t\t -- train_counter: 1088, test_counter:59\n",
      "Sat Jan  1 22:52:09 2022\tEpoch: 291, Loss: 0.7695, Val: 3.5823, Test: 3.4764\n",
      "\t\t -- train_counter: 1031, test_counter:65\n",
      "Sat Jan  1 22:52:11 2022\tEpoch: 292, Loss: 0.7242, Val: 3.9058, Test: 4.5784\n",
      "\t\t -- train_counter: 1092, test_counter:60\n",
      "Sat Jan  1 22:52:14 2022\tEpoch: 293, Loss: 0.6806, Val: 3.7392, Test: 3.9363\n",
      "\t\t -- train_counter: 1099, test_counter:63\n",
      "Sat Jan  1 22:52:16 2022\tEpoch: 294, Loss: 0.7220, Val: 3.8974, Test: 4.2527\n",
      "\t\t -- train_counter: 1091, test_counter:53\n",
      "Sat Jan  1 22:52:19 2022\tEpoch: 295, Loss: 0.6808, Val: 3.4764, Test: 3.6458\n",
      "\t\t -- train_counter: 1102, test_counter:64\n",
      "Sat Jan  1 22:52:23 2022\tEpoch: 296, Loss: 0.6943, Val: 3.5655, Test: 3.5656\n",
      "\t\t -- train_counter: 1094, test_counter:62\n",
      "Sat Jan  1 22:52:26 2022\tEpoch: 297, Loss: 0.6347, Val: 3.8188, Test: 3.7078\n",
      "\t\t -- train_counter: 1101, test_counter:74\n",
      "Sat Jan  1 22:52:29 2022\tEpoch: 298, Loss: 0.7082, Val: 3.6992, Test: 3.8297\n",
      "\t\t -- train_counter: 1088, test_counter:82\n",
      "Sat Jan  1 22:52:31 2022\tEpoch: 299, Loss: 0.6836, Val: 3.5408, Test: 3.5191\n",
      "\t\t -- train_counter: 1071, test_counter:67\n",
      "Sat Jan  1 22:52:34 2022\tEpoch: 300, Loss: 0.7150, Val: 3.3890, Test: 3.4808\n",
      "\t\t -- train_counter: 1067, test_counter:77\n",
      "Sat Jan  1 22:52:37 2022\tEpoch: 301, Loss: 0.6977, Val: 3.5106, Test: 3.8820\n",
      "\t\t -- train_counter: 1096, test_counter:68\n",
      "Sat Jan  1 22:52:39 2022\tEpoch: 302, Loss: 0.7538, Val: 4.4978, Test: 4.5007\n",
      "\t\t -- train_counter: 1068, test_counter:61\n",
      "Sat Jan  1 22:52:42 2022\tEpoch: 303, Loss: 0.6907, Val: 3.5215, Test: 3.6229\n",
      "\t\t -- train_counter: 1095, test_counter:69\n",
      "Sat Jan  1 22:52:44 2022\tEpoch: 304, Loss: 0.6739, Val: 3.8495, Test: 3.6236\n",
      "\t\t -- train_counter: 1107, test_counter:63\n",
      "Sat Jan  1 22:52:47 2022\tEpoch: 305, Loss: 0.7469, Val: 4.0259, Test: 4.6748\n",
      "\t\t -- train_counter: 1075, test_counter:55\n",
      "Sat Jan  1 22:52:50 2022\tEpoch: 306, Loss: 0.7276, Val: 3.5499, Test: 3.8593\n",
      "\t\t -- train_counter: 1075, test_counter:62\n",
      "Sat Jan  1 22:52:53 2022\tEpoch: 307, Loss: 0.6954, Val: 3.3608, Test: 3.6032\n",
      "\t\t -- train_counter: 1078, test_counter:67\n",
      "Sat Jan  1 22:52:56 2022\tEpoch: 308, Loss: 0.7053, Val: 3.4276, Test: 3.6552\n",
      "\t\t -- train_counter: 1082, test_counter:68\n",
      "Sat Jan  1 22:52:58 2022\tEpoch: 309, Loss: 0.7024, Val: 3.2269, Test: 4.0924\n",
      "\t\t -- train_counter: 1102, test_counter:58\n",
      "Sat Jan  1 22:53:01 2022\tEpoch: 310, Loss: 0.7085, Val: 3.7281, Test: 4.1983\n",
      "\t\t -- train_counter: 1066, test_counter:58\n",
      "Sat Jan  1 22:53:04 2022\tEpoch: 311, Loss: 0.7378, Val: 3.6458, Test: 4.0454\n",
      "\t\t -- train_counter: 1077, test_counter:65\n",
      "Sat Jan  1 22:53:06 2022\tEpoch: 312, Loss: 0.6407, Val: 3.4293, Test: 3.5088\n",
      "\t\t -- train_counter: 1137, test_counter:76\n",
      "Sat Jan  1 22:53:09 2022\tEpoch: 313, Loss: 0.7184, Val: 3.5071, Test: 3.7627\n",
      "\t\t -- train_counter: 1090, test_counter:51\n",
      "Sat Jan  1 22:53:12 2022\tEpoch: 314, Loss: 0.6962, Val: 3.8975, Test: 3.9098\n",
      "\t\t -- train_counter: 1105, test_counter:42\n",
      "Sat Jan  1 22:53:15 2022\tEpoch: 315, Loss: 0.7207, Val: 3.5273, Test: 3.7495\n",
      "\t\t -- train_counter: 1094, test_counter:79\n",
      "Sat Jan  1 22:53:18 2022\tEpoch: 316, Loss: 0.6889, Val: 3.4390, Test: 3.6030\n",
      "\t\t -- train_counter: 1098, test_counter:77\n",
      "Sat Jan  1 22:53:22 2022\tEpoch: 317, Loss: 0.6310, Val: 3.4572, Test: 3.4741\n",
      "\t\t -- train_counter: 1134, test_counter:74\n",
      "Sat Jan  1 22:53:24 2022\tEpoch: 318, Loss: 0.6371, Val: 3.5446, Test: 3.6700\n",
      "\t\t -- train_counter: 1109, test_counter:76\n",
      "Sat Jan  1 22:53:27 2022\tEpoch: 319, Loss: 0.6424, Val: 3.4544, Test: 3.4767\n",
      "\t\t -- train_counter: 1126, test_counter:81\n",
      "Sat Jan  1 22:53:30 2022\tEpoch: 320, Loss: 0.6683, Val: 4.2990, Test: 4.3492\n",
      "\t\t -- train_counter: 1096, test_counter:66\n",
      "Sat Jan  1 22:53:32 2022\tEpoch: 321, Loss: 0.6415, Val: 3.5938, Test: 3.7813\n",
      "\t\t -- train_counter: 1113, test_counter:72\n",
      "Sat Jan  1 22:53:35 2022\tEpoch: 322, Loss: 0.6620, Val: 3.5140, Test: 3.3764\n",
      "\t\t -- train_counter: 1093, test_counter:65\n",
      "Sat Jan  1 22:53:37 2022\tEpoch: 323, Loss: 0.6532, Val: 3.3970, Test: 3.5656\n",
      "\t\t -- train_counter: 1101, test_counter:67\n",
      "Sat Jan  1 22:53:40 2022\tEpoch: 324, Loss: 0.6382, Val: 3.5989, Test: 3.5182\n",
      "\t\t -- train_counter: 1108, test_counter:69\n",
      "Sat Jan  1 22:53:43 2022\tEpoch: 325, Loss: 0.7049, Val: 3.8715, Test: 4.1214\n",
      "\t\t -- train_counter: 1086, test_counter:65\n",
      "Sat Jan  1 22:53:46 2022\tEpoch: 326, Loss: 0.6351, Val: 3.1649, Test: 3.6016\n",
      "\t\t -- train_counter: 1105, test_counter:67\n",
      "Sat Jan  1 22:53:50 2022\tEpoch: 327, Loss: 0.6470, Val: 3.6223, Test: 3.4307\n",
      "\t\t -- train_counter: 1130, test_counter:65\n",
      "Sat Jan  1 22:53:52 2022\tEpoch: 328, Loss: 0.6617, Val: 3.5209, Test: 3.8903\n",
      "\t\t -- train_counter: 1117, test_counter:62\n",
      "Sat Jan  1 22:53:55 2022\tEpoch: 329, Loss: 0.6182, Val: 4.3943, Test: 4.4910\n",
      "\t\t -- train_counter: 1144, test_counter:59\n",
      "Sat Jan  1 22:53:58 2022\tEpoch: 330, Loss: 0.6458, Val: 4.3970, Test: 4.6258\n",
      "\t\t -- train_counter: 1108, test_counter:62\n",
      "Sat Jan  1 22:54:00 2022\tEpoch: 331, Loss: 0.7032, Val: 3.4544, Test: 3.9948\n",
      "\t\t -- train_counter: 1104, test_counter:49\n",
      "Sat Jan  1 22:54:03 2022\tEpoch: 332, Loss: 0.6684, Val: 3.6861, Test: 3.5601\n",
      "\t\t -- train_counter: 1093, test_counter:68\n",
      "Sat Jan  1 22:54:06 2022\tEpoch: 333, Loss: 0.6419, Val: 3.9542, Test: 4.2032\n",
      "\t\t -- train_counter: 1113, test_counter:67\n",
      "Sat Jan  1 22:54:08 2022\tEpoch: 334, Loss: 0.6053, Val: 3.4692, Test: 3.9340\n",
      "\t\t -- train_counter: 1109, test_counter:65\n",
      "Sat Jan  1 22:54:11 2022\tEpoch: 335, Loss: 0.6475, Val: 3.6036, Test: 3.5648\n",
      "\t\t -- train_counter: 1083, test_counter:68\n",
      "Sat Jan  1 22:54:14 2022\tEpoch: 336, Loss: 0.6349, Val: 3.3712, Test: 3.9381\n",
      "\t\t -- train_counter: 1107, test_counter:62\n",
      "Sat Jan  1 22:54:17 2022\tEpoch: 337, Loss: 0.6661, Val: 3.3809, Test: 3.5568\n",
      "\t\t -- train_counter: 1103, test_counter:65\n",
      "Sat Jan  1 22:54:20 2022\tEpoch: 338, Loss: 0.5875, Val: 3.1812, Test: 3.5417\n",
      "\t\t -- train_counter: 1122, test_counter:71\n",
      "Sat Jan  1 22:54:23 2022\tEpoch: 339, Loss: 0.6186, Val: 3.2688, Test: 3.5399\n",
      "\t\t -- train_counter: 1121, test_counter:69\n",
      "Sat Jan  1 22:54:25 2022\tEpoch: 340, Loss: 0.6596, Val: 3.4782, Test: 3.8213\n",
      "\t\t -- train_counter: 1104, test_counter:75\n",
      "Sat Jan  1 22:54:28 2022\tEpoch: 341, Loss: 0.6111, Val: 3.5801, Test: 3.7100\n",
      "\t\t -- train_counter: 1114, test_counter:64\n",
      "Sat Jan  1 22:54:31 2022\tEpoch: 342, Loss: 0.7026, Val: 4.0543, Test: 4.0887\n",
      "\t\t -- train_counter: 1103, test_counter:57\n",
      "Sat Jan  1 22:54:34 2022\tEpoch: 343, Loss: 0.5903, Val: 3.4175, Test: 3.5443\n",
      "\t\t -- train_counter: 1154, test_counter:65\n",
      "Sat Jan  1 22:54:36 2022\tEpoch: 344, Loss: 0.6121, Val: 3.3668, Test: 3.4503\n",
      "\t\t -- train_counter: 1126, test_counter:62\n",
      "Sat Jan  1 22:54:39 2022\tEpoch: 345, Loss: 0.6332, Val: 3.8698, Test: 4.4221\n",
      "\t\t -- train_counter: 1110, test_counter:71\n",
      "Sat Jan  1 22:54:41 2022\tEpoch: 346, Loss: 0.6016, Val: 4.8685, Test: 5.4588\n",
      "\t\t -- train_counter: 1149, test_counter:50\n",
      "Sat Jan  1 22:54:44 2022\tEpoch: 347, Loss: 0.5924, Val: 3.5564, Test: 3.8522\n",
      "\t\t -- train_counter: 1142, test_counter:79\n",
      "Sat Jan  1 22:54:47 2022\tEpoch: 348, Loss: 0.6471, Val: 3.7394, Test: 3.8507\n",
      "\t\t -- train_counter: 1114, test_counter:60\n",
      "Sat Jan  1 22:54:50 2022\tEpoch: 349, Loss: 0.6105, Val: 3.5618, Test: 3.7800\n",
      "\t\t -- train_counter: 1131, test_counter:68\n",
      "Sat Jan  1 22:54:53 2022\tEpoch: 350, Loss: 0.6374, Val: 3.4607, Test: 3.7872\n",
      "\t\t -- train_counter: 1125, test_counter:66\n",
      "Sat Jan  1 22:54:55 2022\tEpoch: 351, Loss: 0.6591, Val: 3.4580, Test: 3.8957\n",
      "\t\t -- train_counter: 1119, test_counter:67\n",
      "Sat Jan  1 22:54:58 2022\tEpoch: 352, Loss: 0.6449, Val: 3.7787, Test: 4.0997\n",
      "\t\t -- train_counter: 1139, test_counter:55\n",
      "Sat Jan  1 22:55:01 2022\tEpoch: 353, Loss: 0.6244, Val: 3.6717, Test: 3.7275\n",
      "\t\t -- train_counter: 1131, test_counter:63\n",
      "Sat Jan  1 22:55:04 2022\tEpoch: 354, Loss: 0.6452, Val: 3.4597, Test: 3.7482\n",
      "\t\t -- train_counter: 1107, test_counter:57\n",
      "Sat Jan  1 22:55:07 2022\tEpoch: 355, Loss: 0.6742, Val: 3.6369, Test: 3.8081\n",
      "\t\t -- train_counter: 1108, test_counter:60\n",
      "Sat Jan  1 22:55:10 2022\tEpoch: 356, Loss: 0.6892, Val: 4.0911, Test: 4.0330\n",
      "\t\t -- train_counter: 1097, test_counter:65\n",
      "Sat Jan  1 22:55:13 2022\tEpoch: 357, Loss: 0.6371, Val: 4.3163, Test: 4.6853\n",
      "\t\t -- train_counter: 1114, test_counter:57\n",
      "Sat Jan  1 22:55:16 2022\tEpoch: 358, Loss: 0.6846, Val: 3.2623, Test: 3.6900\n",
      "\t\t -- train_counter: 1100, test_counter:68\n",
      "Sat Jan  1 22:55:19 2022\tEpoch: 359, Loss: 0.6435, Val: 3.5647, Test: 3.2839\n",
      "\t\t -- train_counter: 1103, test_counter:71\n",
      "Sat Jan  1 22:55:21 2022\tEpoch: 360, Loss: 0.6119, Val: 3.4600, Test: 3.3920\n",
      "\t\t -- train_counter: 1114, test_counter:78\n",
      "Sat Jan  1 22:55:24 2022\tEpoch: 361, Loss: 0.6335, Val: 3.3744, Test: 3.8709\n",
      "\t\t -- train_counter: 1117, test_counter:77\n",
      "Sat Jan  1 22:55:26 2022\tEpoch: 362, Loss: 0.6113, Val: 4.2292, Test: 4.5470\n",
      "\t\t -- train_counter: 1139, test_counter:61\n",
      "Sat Jan  1 22:55:29 2022\tEpoch: 363, Loss: 0.5859, Val: 3.4924, Test: 3.6972\n",
      "\t\t -- train_counter: 1135, test_counter:68\n",
      "Sat Jan  1 22:55:32 2022\tEpoch: 364, Loss: 0.6385, Val: 3.6596, Test: 3.6553\n",
      "\t\t -- train_counter: 1136, test_counter:57\n",
      "Sat Jan  1 22:55:35 2022\tEpoch: 365, Loss: 0.6922, Val: 3.4196, Test: 3.7227\n",
      "\t\t -- train_counter: 1108, test_counter:64\n",
      "Sat Jan  1 22:55:38 2022\tEpoch: 366, Loss: 0.6458, Val: 3.5873, Test: 3.7254\n",
      "\t\t -- train_counter: 1106, test_counter:69\n",
      "Sat Jan  1 22:55:41 2022\tEpoch: 367, Loss: 0.5764, Val: 3.6853, Test: 3.7915\n",
      "\t\t -- train_counter: 1145, test_counter:74\n",
      "Sat Jan  1 22:55:44 2022\tEpoch: 368, Loss: 0.6510, Val: 3.5804, Test: 3.7383\n",
      "\t\t -- train_counter: 1134, test_counter:74\n",
      "Sat Jan  1 22:55:47 2022\tEpoch: 369, Loss: 0.6093, Val: 3.5735, Test: 3.8150\n",
      "\t\t -- train_counter: 1118, test_counter:54\n",
      "Sat Jan  1 22:55:49 2022\tEpoch: 370, Loss: 0.6647, Val: 4.0413, Test: 4.0880\n",
      "\t\t -- train_counter: 1114, test_counter:54\n",
      "Sat Jan  1 22:55:52 2022\tEpoch: 371, Loss: 0.6379, Val: 3.3541, Test: 3.5600\n",
      "\t\t -- train_counter: 1119, test_counter:73\n",
      "Sat Jan  1 22:55:55 2022\tEpoch: 372, Loss: 0.6293, Val: 3.7584, Test: 4.2003\n",
      "\t\t -- train_counter: 1129, test_counter:64\n",
      "Sat Jan  1 22:55:58 2022\tEpoch: 373, Loss: 0.6483, Val: 3.5205, Test: 3.6232\n",
      "\t\t -- train_counter: 1122, test_counter:73\n",
      "Sat Jan  1 22:56:00 2022\tEpoch: 374, Loss: 0.5976, Val: 3.3023, Test: 3.4484\n",
      "\t\t -- train_counter: 1125, test_counter:67\n",
      "Sat Jan  1 22:56:03 2022\tEpoch: 375, Loss: 0.6322, Val: 3.8882, Test: 4.0302\n",
      "\t\t -- train_counter: 1132, test_counter:44\n",
      "Sat Jan  1 22:56:06 2022\tEpoch: 376, Loss: 0.6176, Val: 3.2527, Test: 3.6106\n",
      "\t\t -- train_counter: 1131, test_counter:76\n",
      "Sat Jan  1 22:56:09 2022\tEpoch: 377, Loss: 0.6488, Val: 4.1394, Test: 4.3541\n",
      "\t\t -- train_counter: 1107, test_counter:63\n",
      "Sat Jan  1 22:56:12 2022\tEpoch: 378, Loss: 0.6367, Val: 3.4462, Test: 3.6120\n",
      "\t\t -- train_counter: 1122, test_counter:74\n",
      "Sat Jan  1 22:56:14 2022\tEpoch: 379, Loss: 0.5983, Val: 3.4180, Test: 3.6149\n",
      "\t\t -- train_counter: 1137, test_counter:82\n",
      "Sat Jan  1 22:56:17 2022\tEpoch: 380, Loss: 0.5941, Val: 3.6299, Test: 3.6871\n",
      "\t\t -- train_counter: 1137, test_counter:72\n",
      "Sat Jan  1 22:56:20 2022\tEpoch: 381, Loss: 0.6123, Val: 3.8686, Test: 3.9224\n",
      "\t\t -- train_counter: 1118, test_counter:61\n",
      "Sat Jan  1 22:56:22 2022\tEpoch: 382, Loss: 0.6109, Val: 4.7606, Test: 5.2365\n",
      "\t\t -- train_counter: 1133, test_counter:52\n",
      "Sat Jan  1 22:56:25 2022\tEpoch: 383, Loss: 0.5489, Val: 4.1415, Test: 4.5471\n",
      "\t\t -- train_counter: 1149, test_counter:60\n",
      "Sat Jan  1 22:56:28 2022\tEpoch: 384, Loss: 0.5785, Val: 3.7091, Test: 3.9209\n",
      "\t\t -- train_counter: 1141, test_counter:67\n",
      "Sat Jan  1 22:56:30 2022\tEpoch: 385, Loss: 0.5681, Val: 4.0414, Test: 4.6059\n",
      "\t\t -- train_counter: 1142, test_counter:61\n",
      "Sat Jan  1 22:56:33 2022\tEpoch: 386, Loss: 0.6291, Val: 4.6429, Test: 4.7343\n",
      "\t\t -- train_counter: 1136, test_counter:68\n",
      "Sat Jan  1 22:56:36 2022\tEpoch: 387, Loss: 0.6223, Val: 3.4766, Test: 3.6975\n",
      "\t\t -- train_counter: 1135, test_counter:64\n",
      "Sat Jan  1 22:56:39 2022\tEpoch: 388, Loss: 0.5870, Val: 3.3904, Test: 3.5208\n",
      "\t\t -- train_counter: 1134, test_counter:66\n",
      "Sat Jan  1 22:56:41 2022\tEpoch: 389, Loss: 0.6380, Val: 3.4377, Test: 3.9751\n",
      "\t\t -- train_counter: 1127, test_counter:45\n",
      "Sat Jan  1 22:56:44 2022\tEpoch: 390, Loss: 0.6071, Val: 3.3493, Test: 3.7819\n",
      "\t\t -- train_counter: 1150, test_counter:73\n",
      "Sat Jan  1 22:56:47 2022\tEpoch: 391, Loss: 0.5686, Val: 3.8494, Test: 4.6715\n",
      "\t\t -- train_counter: 1145, test_counter:61\n",
      "Sat Jan  1 22:56:49 2022\tEpoch: 392, Loss: 0.5889, Val: 3.6036, Test: 4.0980\n",
      "\t\t -- train_counter: 1137, test_counter:66\n",
      "Sat Jan  1 22:56:52 2022\tEpoch: 393, Loss: 0.5818, Val: 3.3738, Test: 4.1084\n",
      "\t\t -- train_counter: 1134, test_counter:65\n",
      "Sat Jan  1 22:56:54 2022\tEpoch: 394, Loss: 0.5928, Val: 3.4925, Test: 3.7586\n",
      "\t\t -- train_counter: 1163, test_counter:68\n",
      "Sat Jan  1 22:56:57 2022\tEpoch: 395, Loss: 0.5713, Val: 3.4067, Test: 3.7326\n",
      "\t\t -- train_counter: 1143, test_counter:76\n",
      "Sat Jan  1 22:57:00 2022\tEpoch: 396, Loss: 0.6192, Val: 3.4773, Test: 3.4452\n",
      "\t\t -- train_counter: 1129, test_counter:73\n",
      "Sat Jan  1 22:57:03 2022\tEpoch: 397, Loss: 0.6420, Val: 3.3585, Test: 3.5294\n",
      "\t\t -- train_counter: 1139, test_counter:81\n",
      "Sat Jan  1 22:57:06 2022\tEpoch: 398, Loss: 0.5584, Val: 3.3490, Test: 3.6643\n",
      "\t\t -- train_counter: 1154, test_counter:68\n",
      "Sat Jan  1 22:57:09 2022\tEpoch: 399, Loss: 0.5832, Val: 3.7473, Test: 3.9359\n",
      "\t\t -- train_counter: 1140, test_counter:58\n",
      "Sat Jan  1 22:57:12 2022\tEpoch: 400, Loss: 0.6498, Val: 3.7333, Test: 3.8163\n",
      "\t\t -- train_counter: 1142, test_counter:59\n",
      "Sat Jan  1 22:57:15 2022\tEpoch: 401, Loss: 0.6068, Val: 3.3576, Test: 3.8707\n",
      "\t\t -- train_counter: 1133, test_counter:65\n",
      "Sat Jan  1 22:57:18 2022\tEpoch: 402, Loss: 0.6181, Val: 3.1456, Test: 3.7204\n",
      "\t\t -- train_counter: 1145, test_counter:68\n",
      "Sat Jan  1 22:57:20 2022\tEpoch: 403, Loss: 0.5838, Val: 3.4421, Test: 3.6861\n",
      "\t\t -- train_counter: 1155, test_counter:70\n",
      "Sat Jan  1 22:57:23 2022\tEpoch: 404, Loss: 0.5915, Val: 3.6816, Test: 3.9143\n",
      "\t\t -- train_counter: 1138, test_counter:72\n",
      "Sat Jan  1 22:57:25 2022\tEpoch: 405, Loss: 0.5437, Val: 3.8695, Test: 3.7277\n",
      "\t\t -- train_counter: 1165, test_counter:68\n",
      "Sat Jan  1 22:57:28 2022\tEpoch: 406, Loss: 0.5579, Val: 3.8909, Test: 3.9566\n",
      "\t\t -- train_counter: 1147, test_counter:54\n",
      "Sat Jan  1 22:57:32 2022\tEpoch: 407, Loss: 0.5795, Val: 3.6436, Test: 3.7736\n",
      "\t\t -- train_counter: 1150, test_counter:73\n",
      "Sat Jan  1 22:57:35 2022\tEpoch: 408, Loss: 0.5915, Val: 3.8928, Test: 4.8478\n",
      "\t\t -- train_counter: 1168, test_counter:55\n",
      "Sat Jan  1 22:57:38 2022\tEpoch: 409, Loss: 0.6583, Val: 3.5123, Test: 3.6025\n",
      "\t\t -- train_counter: 1116, test_counter:62\n",
      "Sat Jan  1 22:57:41 2022\tEpoch: 410, Loss: 0.6269, Val: 3.6601, Test: 3.8635\n",
      "\t\t -- train_counter: 1125, test_counter:50\n",
      "Sat Jan  1 22:57:44 2022\tEpoch: 411, Loss: 0.6318, Val: 3.1689, Test: 3.4110\n",
      "\t\t -- train_counter: 1126, test_counter:69\n",
      "Sat Jan  1 22:57:46 2022\tEpoch: 412, Loss: 0.5811, Val: 3.3753, Test: 3.7653\n",
      "\t\t -- train_counter: 1165, test_counter:65\n",
      "Sat Jan  1 22:57:49 2022\tEpoch: 413, Loss: 0.5790, Val: 3.6692, Test: 3.9533\n",
      "\t\t -- train_counter: 1160, test_counter:62\n",
      "Sat Jan  1 22:57:52 2022\tEpoch: 414, Loss: 0.5811, Val: 3.4207, Test: 3.6725\n",
      "\t\t -- train_counter: 1156, test_counter:68\n",
      "Sat Jan  1 22:57:54 2022\tEpoch: 415, Loss: 0.5626, Val: 3.5714, Test: 3.6554\n",
      "\t\t -- train_counter: 1163, test_counter:61\n",
      "Sat Jan  1 22:57:57 2022\tEpoch: 416, Loss: 0.6027, Val: 3.8243, Test: 3.6554\n",
      "\t\t -- train_counter: 1141, test_counter:70\n",
      "Sat Jan  1 22:58:01 2022\tEpoch: 417, Loss: 0.5814, Val: 4.0522, Test: 5.0166\n",
      "\t\t -- train_counter: 1154, test_counter:46\n",
      "Sat Jan  1 22:58:03 2022\tEpoch: 418, Loss: 0.5425, Val: 3.8417, Test: 3.9455\n",
      "\t\t -- train_counter: 1166, test_counter:58\n",
      "Sat Jan  1 22:58:06 2022\tEpoch: 419, Loss: 0.5895, Val: 3.4179, Test: 3.6992\n",
      "\t\t -- train_counter: 1136, test_counter:63\n",
      "Sat Jan  1 22:58:09 2022\tEpoch: 420, Loss: 0.5148, Val: 3.7660, Test: 3.8185\n",
      "\t\t -- train_counter: 1166, test_counter:50\n",
      "Sat Jan  1 22:58:12 2022\tEpoch: 421, Loss: 0.5628, Val: 3.3474, Test: 3.7490\n",
      "\t\t -- train_counter: 1156, test_counter:62\n",
      "Sat Jan  1 22:58:14 2022\tEpoch: 422, Loss: 0.5723, Val: 4.0722, Test: 4.1249\n",
      "\t\t -- train_counter: 1159, test_counter:60\n",
      "Sat Jan  1 22:58:17 2022\tEpoch: 423, Loss: 0.6021, Val: 3.7734, Test: 3.7500\n",
      "\t\t -- train_counter: 1151, test_counter:65\n",
      "Sat Jan  1 22:58:20 2022\tEpoch: 424, Loss: 0.5261, Val: 3.7388, Test: 4.2596\n",
      "\t\t -- train_counter: 1162, test_counter:56\n",
      "Sat Jan  1 22:58:23 2022\tEpoch: 425, Loss: 0.5256, Val: 3.5577, Test: 3.5152\n",
      "\t\t -- train_counter: 1174, test_counter:77\n",
      "Sat Jan  1 22:58:25 2022\tEpoch: 426, Loss: 0.5718, Val: 3.9279, Test: 3.8791\n",
      "\t\t -- train_counter: 1140, test_counter:73\n",
      "Sat Jan  1 22:58:29 2022\tEpoch: 427, Loss: 0.5657, Val: 3.8259, Test: 4.2675\n",
      "\t\t -- train_counter: 1155, test_counter:60\n",
      "Sat Jan  1 22:58:32 2022\tEpoch: 428, Loss: 0.5137, Val: 3.6650, Test: 3.6688\n",
      "\t\t -- train_counter: 1167, test_counter:79\n",
      "Sat Jan  1 22:58:34 2022\tEpoch: 429, Loss: 0.5850, Val: 3.4815, Test: 3.7800\n",
      "\t\t -- train_counter: 1160, test_counter:65\n",
      "Sat Jan  1 22:58:37 2022\tEpoch: 430, Loss: 0.5207, Val: 3.8734, Test: 3.8646\n",
      "\t\t -- train_counter: 1167, test_counter:72\n",
      "Sat Jan  1 22:58:40 2022\tEpoch: 431, Loss: 0.5780, Val: 3.6238, Test: 3.6047\n",
      "\t\t -- train_counter: 1151, test_counter:72\n",
      "Sat Jan  1 22:58:43 2022\tEpoch: 432, Loss: 0.5713, Val: 3.6590, Test: 3.4651\n",
      "\t\t -- train_counter: 1170, test_counter:72\n",
      "Sat Jan  1 22:58:46 2022\tEpoch: 433, Loss: 0.5408, Val: 3.9734, Test: 3.8847\n",
      "\t\t -- train_counter: 1157, test_counter:63\n",
      "Sat Jan  1 22:58:48 2022\tEpoch: 434, Loss: 0.6021, Val: 4.3038, Test: 4.9662\n",
      "\t\t -- train_counter: 1146, test_counter:52\n",
      "Sat Jan  1 22:58:51 2022\tEpoch: 435, Loss: 0.5769, Val: 3.5577, Test: 3.7345\n",
      "\t\t -- train_counter: 1143, test_counter:67\n",
      "Sat Jan  1 22:58:54 2022\tEpoch: 436, Loss: 0.6025, Val: 4.4303, Test: 4.8002\n",
      "\t\t -- train_counter: 1136, test_counter:51\n",
      "Sat Jan  1 22:58:57 2022\tEpoch: 437, Loss: 0.5606, Val: 3.4190, Test: 3.7333\n",
      "\t\t -- train_counter: 1151, test_counter:79\n",
      "Sat Jan  1 22:59:00 2022\tEpoch: 438, Loss: 0.5188, Val: 3.5298, Test: 3.8709\n",
      "\t\t -- train_counter: 1176, test_counter:71\n",
      "Sat Jan  1 22:59:03 2022\tEpoch: 439, Loss: 0.5072, Val: 3.6917, Test: 3.9745\n",
      "\t\t -- train_counter: 1168, test_counter:66\n",
      "Sat Jan  1 22:59:06 2022\tEpoch: 440, Loss: 0.5668, Val: 3.6469, Test: 3.9698\n",
      "\t\t -- train_counter: 1148, test_counter:75\n",
      "Sat Jan  1 22:59:08 2022\tEpoch: 441, Loss: 0.6288, Val: 3.6177, Test: 3.7184\n",
      "\t\t -- train_counter: 1115, test_counter:83\n",
      "Sat Jan  1 22:59:11 2022\tEpoch: 442, Loss: 0.5818, Val: 3.7452, Test: 3.6922\n",
      "\t\t -- train_counter: 1151, test_counter:68\n",
      "Sat Jan  1 22:59:14 2022\tEpoch: 443, Loss: 0.5251, Val: 3.7611, Test: 3.9970\n",
      "\t\t -- train_counter: 1167, test_counter:69\n",
      "Sat Jan  1 22:59:17 2022\tEpoch: 444, Loss: 0.5308, Val: 3.5177, Test: 3.5538\n",
      "\t\t -- train_counter: 1174, test_counter:69\n",
      "Sat Jan  1 22:59:19 2022\tEpoch: 445, Loss: 0.5326, Val: 3.4756, Test: 3.5223\n",
      "\t\t -- train_counter: 1159, test_counter:66\n",
      "Sat Jan  1 22:59:22 2022\tEpoch: 446, Loss: 0.6177, Val: 3.4280, Test: 3.6094\n",
      "\t\t -- train_counter: 1142, test_counter:68\n",
      "Sat Jan  1 22:59:26 2022\tEpoch: 447, Loss: 0.5989, Val: 3.6254, Test: 3.9193\n",
      "\t\t -- train_counter: 1141, test_counter:63\n",
      "Sat Jan  1 22:59:29 2022\tEpoch: 448, Loss: 0.5594, Val: 3.6166, Test: 4.1595\n",
      "\t\t -- train_counter: 1150, test_counter:61\n",
      "Sat Jan  1 22:59:31 2022\tEpoch: 449, Loss: 0.6230, Val: 4.8322, Test: 5.8410\n",
      "\t\t -- train_counter: 1131, test_counter:44\n",
      "Sat Jan  1 22:59:34 2022\tEpoch: 450, Loss: 0.5623, Val: 4.6548, Test: 4.9740\n",
      "\t\t -- train_counter: 1153, test_counter:54\n",
      "Sat Jan  1 22:59:37 2022\tEpoch: 451, Loss: 0.5869, Val: 3.7156, Test: 3.7709\n",
      "\t\t -- train_counter: 1140, test_counter:65\n",
      "Sat Jan  1 22:59:39 2022\tEpoch: 452, Loss: 0.5687, Val: 3.8327, Test: 4.0834\n",
      "\t\t -- train_counter: 1139, test_counter:62\n",
      "Sat Jan  1 22:59:42 2022\tEpoch: 453, Loss: 0.5721, Val: 3.3510, Test: 3.6393\n",
      "\t\t -- train_counter: 1166, test_counter:76\n",
      "Sat Jan  1 22:59:45 2022\tEpoch: 454, Loss: 0.5452, Val: 3.4883, Test: 3.5964\n",
      "\t\t -- train_counter: 1146, test_counter:66\n",
      "Sat Jan  1 22:59:48 2022\tEpoch: 455, Loss: 0.6138, Val: 3.5277, Test: 3.5007\n",
      "\t\t -- train_counter: 1139, test_counter:72\n",
      "Sat Jan  1 22:59:51 2022\tEpoch: 456, Loss: 0.5530, Val: 3.5237, Test: 3.4748\n",
      "\t\t -- train_counter: 1153, test_counter:69\n",
      "Sat Jan  1 22:59:54 2022\tEpoch: 457, Loss: 0.5710, Val: 3.7016, Test: 3.7514\n",
      "\t\t -- train_counter: 1170, test_counter:66\n",
      "Sat Jan  1 22:59:57 2022\tEpoch: 458, Loss: 0.5301, Val: 3.3980, Test: 3.5650\n",
      "\t\t -- train_counter: 1181, test_counter:78\n",
      "Sat Jan  1 23:00:00 2022\tEpoch: 459, Loss: 0.5152, Val: 3.7809, Test: 4.0476\n",
      "\t\t -- train_counter: 1178, test_counter:74\n",
      "Sat Jan  1 23:00:03 2022\tEpoch: 460, Loss: 0.5440, Val: 3.9194, Test: 4.3365\n",
      "\t\t -- train_counter: 1164, test_counter:72\n",
      "Sat Jan  1 23:00:06 2022\tEpoch: 461, Loss: 0.5769, Val: 3.8661, Test: 3.9097\n",
      "\t\t -- train_counter: 1155, test_counter:65\n",
      "Sat Jan  1 23:00:08 2022\tEpoch: 462, Loss: 0.5395, Val: 3.6992, Test: 4.1219\n",
      "\t\t -- train_counter: 1194, test_counter:63\n",
      "Sat Jan  1 23:00:11 2022\tEpoch: 463, Loss: 0.5759, Val: 3.7392, Test: 4.0026\n",
      "\t\t -- train_counter: 1159, test_counter:71\n",
      "Sat Jan  1 23:00:14 2022\tEpoch: 464, Loss: 0.5533, Val: 4.0414, Test: 3.9601\n",
      "\t\t -- train_counter: 1152, test_counter:66\n",
      "Sat Jan  1 23:00:17 2022\tEpoch: 465, Loss: 0.5107, Val: 4.0418, Test: 4.0398\n",
      "\t\t -- train_counter: 1172, test_counter:65\n",
      "Sat Jan  1 23:00:20 2022\tEpoch: 466, Loss: 0.5177, Val: 3.4384, Test: 3.7300\n",
      "\t\t -- train_counter: 1173, test_counter:66\n",
      "Sat Jan  1 23:00:23 2022\tEpoch: 467, Loss: 0.5285, Val: 3.6756, Test: 3.6736\n",
      "\t\t -- train_counter: 1169, test_counter:68\n",
      "Sat Jan  1 23:00:26 2022\tEpoch: 468, Loss: 0.5634, Val: 3.6691, Test: 3.6031\n",
      "\t\t -- train_counter: 1154, test_counter:73\n",
      "Sat Jan  1 23:00:29 2022\tEpoch: 469, Loss: 0.5846, Val: 3.7557, Test: 3.8072\n",
      "\t\t -- train_counter: 1149, test_counter:69\n",
      "Sat Jan  1 23:00:31 2022\tEpoch: 470, Loss: 0.5945, Val: 3.7514, Test: 3.6231\n",
      "\t\t -- train_counter: 1150, test_counter:69\n",
      "Sat Jan  1 23:00:34 2022\tEpoch: 471, Loss: 0.6000, Val: 3.8319, Test: 4.1363\n",
      "\t\t -- train_counter: 1127, test_counter:67\n",
      "Sat Jan  1 23:00:37 2022\tEpoch: 472, Loss: 0.5870, Val: 3.8480, Test: 3.8218\n",
      "\t\t -- train_counter: 1178, test_counter:82\n",
      "Sat Jan  1 23:00:40 2022\tEpoch: 473, Loss: 0.6121, Val: 4.9350, Test: 5.1001\n",
      "\t\t -- train_counter: 1147, test_counter:65\n",
      "Sat Jan  1 23:00:42 2022\tEpoch: 474, Loss: 0.5864, Val: 3.4826, Test: 3.7561\n",
      "\t\t -- train_counter: 1150, test_counter:65\n",
      "Sat Jan  1 23:00:45 2022\tEpoch: 475, Loss: 0.5190, Val: 3.6414, Test: 3.7115\n",
      "\t\t -- train_counter: 1180, test_counter:57\n",
      "Sat Jan  1 23:00:48 2022\tEpoch: 476, Loss: 0.5106, Val: 3.5708, Test: 3.6895\n",
      "\t\t -- train_counter: 1180, test_counter:75\n",
      "Sat Jan  1 23:00:51 2022\tEpoch: 477, Loss: 0.5324, Val: 3.8318, Test: 3.7338\n",
      "\t\t -- train_counter: 1156, test_counter:66\n",
      "Sat Jan  1 23:00:54 2022\tEpoch: 478, Loss: 0.5175, Val: 3.9463, Test: 4.0233\n",
      "\t\t -- train_counter: 1174, test_counter:68\n",
      "Sat Jan  1 23:00:57 2022\tEpoch: 479, Loss: 0.5860, Val: 3.8088, Test: 3.6477\n",
      "\t\t -- train_counter: 1151, test_counter:83\n",
      "Sat Jan  1 23:01:00 2022\tEpoch: 480, Loss: 0.6066, Val: 3.6620, Test: 3.6744\n",
      "\t\t -- train_counter: 1152, test_counter:54\n",
      "Sat Jan  1 23:01:03 2022\tEpoch: 481, Loss: 0.5904, Val: 3.4884, Test: 3.5426\n",
      "\t\t -- train_counter: 1147, test_counter:80\n",
      "Sat Jan  1 23:01:05 2022\tEpoch: 482, Loss: 0.5653, Val: 3.8305, Test: 4.1997\n",
      "\t\t -- train_counter: 1161, test_counter:66\n",
      "Sat Jan  1 23:01:08 2022\tEpoch: 483, Loss: 0.5412, Val: 4.0907, Test: 4.3688\n",
      "\t\t -- train_counter: 1165, test_counter:55\n",
      "Sat Jan  1 23:01:11 2022\tEpoch: 484, Loss: 0.5615, Val: 5.4969, Test: 5.7956\n",
      "\t\t -- train_counter: 1158, test_counter:51\n",
      "Sat Jan  1 23:01:13 2022\tEpoch: 485, Loss: 0.5964, Val: 3.3634, Test: 3.3690\n",
      "\t\t -- train_counter: 1144, test_counter:73\n",
      "Sat Jan  1 23:01:16 2022\tEpoch: 486, Loss: 0.5240, Val: 3.6386, Test: 3.7144\n",
      "\t\t -- train_counter: 1178, test_counter:71\n",
      "Sat Jan  1 23:01:19 2022\tEpoch: 487, Loss: 0.5823, Val: 3.9653, Test: 3.8611\n",
      "\t\t -- train_counter: 1163, test_counter:65\n",
      "Sat Jan  1 23:01:23 2022\tEpoch: 488, Loss: 0.5662, Val: 4.0189, Test: 4.2224\n",
      "\t\t -- train_counter: 1158, test_counter:61\n",
      "Sat Jan  1 23:01:25 2022\tEpoch: 489, Loss: 0.5539, Val: 3.5408, Test: 4.1217\n",
      "\t\t -- train_counter: 1166, test_counter:64\n",
      "Sat Jan  1 23:01:28 2022\tEpoch: 490, Loss: 0.5913, Val: 3.4449, Test: 3.8110\n",
      "\t\t -- train_counter: 1138, test_counter:69\n",
      "Sat Jan  1 23:01:31 2022\tEpoch: 491, Loss: 0.5319, Val: 3.3231, Test: 3.6345\n",
      "\t\t -- train_counter: 1160, test_counter:68\n",
      "Sat Jan  1 23:01:34 2022\tEpoch: 492, Loss: 0.5315, Val: 3.3200, Test: 3.4745\n",
      "\t\t -- train_counter: 1171, test_counter:63\n",
      "Sat Jan  1 23:01:37 2022\tEpoch: 493, Loss: 0.5573, Val: 3.4867, Test: 3.8712\n",
      "\t\t -- train_counter: 1174, test_counter:72\n",
      "Sat Jan  1 23:01:39 2022\tEpoch: 494, Loss: 0.5643, Val: 3.4543, Test: 3.4622\n",
      "\t\t -- train_counter: 1175, test_counter:78\n",
      "Sat Jan  1 23:01:42 2022\tEpoch: 495, Loss: 0.5229, Val: 3.4839, Test: 3.5847\n",
      "\t\t -- train_counter: 1171, test_counter:70\n",
      "Sat Jan  1 23:01:45 2022\tEpoch: 496, Loss: 0.5647, Val: 5.2875, Test: 5.3108\n",
      "\t\t -- train_counter: 1145, test_counter:61\n",
      "Sat Jan  1 23:01:49 2022\tEpoch: 497, Loss: 0.5776, Val: 4.2794, Test: 4.5482\n",
      "\t\t -- train_counter: 1139, test_counter:67\n",
      "Sat Jan  1 23:01:51 2022\tEpoch: 498, Loss: 0.5616, Val: 4.6091, Test: 4.6873\n",
      "\t\t -- train_counter: 1152, test_counter:62\n",
      "Sat Jan  1 23:01:54 2022\tEpoch: 499, Loss: 0.5669, Val: 3.5312, Test: 4.4007\n",
      "\t\t -- train_counter: 1177, test_counter:61\n",
      "Sat Jan  1 23:01:57 2022\tEpoch: 500, Loss: 0.6006, Val: 3.2800, Test: 3.8134\n",
      "\t\t -- train_counter: 1143, test_counter:71\n",
      "Sat Jan  1 23:02:00 2022\tEpoch: 501, Loss: 0.5730, Val: 2.9870, Test: 3.6319\n",
      "\t\t -- train_counter: 1162, test_counter:67\n",
      "Sat Jan  1 23:02:03 2022\tEpoch: 502, Loss: 0.5626, Val: 3.4627, Test: 3.6598\n",
      "\t\t -- train_counter: 1155, test_counter:71\n",
      "Sat Jan  1 23:02:06 2022\tEpoch: 503, Loss: 0.5986, Val: 4.2174, Test: 4.1745\n",
      "\t\t -- train_counter: 1143, test_counter:73\n",
      "Sat Jan  1 23:02:08 2022\tEpoch: 504, Loss: 0.5661, Val: 4.4024, Test: 4.4708\n",
      "\t\t -- train_counter: 1150, test_counter:67\n",
      "Sat Jan  1 23:02:11 2022\tEpoch: 505, Loss: 0.5269, Val: 3.6448, Test: 3.7219\n",
      "\t\t -- train_counter: 1169, test_counter:65\n",
      "Sat Jan  1 23:02:14 2022\tEpoch: 506, Loss: 0.5826, Val: 3.4322, Test: 3.4081\n",
      "\t\t -- train_counter: 1164, test_counter:72\n",
      "Sat Jan  1 23:02:17 2022\tEpoch: 507, Loss: 0.5335, Val: 3.7344, Test: 3.7679\n",
      "\t\t -- train_counter: 1173, test_counter:74\n",
      "Sat Jan  1 23:02:20 2022\tEpoch: 508, Loss: 0.5290, Val: 3.6502, Test: 3.7355\n",
      "\t\t -- train_counter: 1154, test_counter:73\n",
      "Sat Jan  1 23:02:23 2022\tEpoch: 509, Loss: 0.5660, Val: 3.4129, Test: 3.7807\n",
      "\t\t -- train_counter: 1153, test_counter:80\n",
      "Sat Jan  1 23:02:26 2022\tEpoch: 510, Loss: 0.5236, Val: 3.9504, Test: 3.9167\n",
      "\t\t -- train_counter: 1182, test_counter:42\n",
      "Sat Jan  1 23:02:29 2022\tEpoch: 511, Loss: 0.5327, Val: 3.5760, Test: 3.4198\n",
      "\t\t -- train_counter: 1181, test_counter:72\n",
      "Sat Jan  1 23:02:31 2022\tEpoch: 512, Loss: 0.5622, Val: 3.5458, Test: 3.7898\n",
      "\t\t -- train_counter: 1159, test_counter:75\n",
      "Sat Jan  1 23:02:34 2022\tEpoch: 513, Loss: 0.5399, Val: 3.3339, Test: 3.5892\n",
      "\t\t -- train_counter: 1158, test_counter:70\n",
      "Sat Jan  1 23:02:37 2022\tEpoch: 514, Loss: 0.5709, Val: 3.4608, Test: 3.7857\n",
      "\t\t -- train_counter: 1160, test_counter:75\n",
      "Sat Jan  1 23:02:40 2022\tEpoch: 515, Loss: 0.5340, Val: 3.7381, Test: 3.6284\n",
      "\t\t -- train_counter: 1170, test_counter:78\n",
      "Sat Jan  1 23:02:42 2022\tEpoch: 516, Loss: 0.5032, Val: 4.1695, Test: 4.5661\n",
      "\t\t -- train_counter: 1168, test_counter:61\n",
      "Sat Jan  1 23:02:45 2022\tEpoch: 517, Loss: 0.5122, Val: 5.6479, Test: 5.7264\n",
      "\t\t -- train_counter: 1171, test_counter:44\n",
      "Sat Jan  1 23:02:48 2022\tEpoch: 518, Loss: 0.5302, Val: 4.2944, Test: 4.3197\n",
      "\t\t -- train_counter: 1176, test_counter:68\n",
      "Sat Jan  1 23:02:51 2022\tEpoch: 519, Loss: 0.5078, Val: 3.5946, Test: 3.5287\n",
      "\t\t -- train_counter: 1180, test_counter:71\n",
      "Sat Jan  1 23:02:54 2022\tEpoch: 520, Loss: 0.5894, Val: 4.0038, Test: 3.7997\n",
      "\t\t -- train_counter: 1154, test_counter:81\n",
      "Sat Jan  1 23:02:57 2022\tEpoch: 521, Loss: 0.5391, Val: 3.5418, Test: 3.6026\n",
      "\t\t -- train_counter: 1156, test_counter:75\n",
      "Sat Jan  1 23:03:00 2022\tEpoch: 522, Loss: 0.4808, Val: 3.3397, Test: 3.4640\n",
      "\t\t -- train_counter: 1195, test_counter:64\n",
      "Sat Jan  1 23:03:02 2022\tEpoch: 523, Loss: 0.5445, Val: 3.6355, Test: 3.7569\n",
      "\t\t -- train_counter: 1173, test_counter:51\n",
      "Sat Jan  1 23:03:05 2022\tEpoch: 524, Loss: 0.4877, Val: 3.5627, Test: 3.4193\n",
      "\t\t -- train_counter: 1168, test_counter:67\n",
      "Sat Jan  1 23:03:08 2022\tEpoch: 525, Loss: 0.5683, Val: 3.6753, Test: 3.4638\n",
      "\t\t -- train_counter: 1165, test_counter:76\n",
      "Sat Jan  1 23:03:11 2022\tEpoch: 526, Loss: 0.5520, Val: 3.5374, Test: 3.4988\n",
      "\t\t -- train_counter: 1165, test_counter:74\n",
      "Sat Jan  1 23:03:15 2022\tEpoch: 527, Loss: 0.5471, Val: 3.7577, Test: 3.5189\n",
      "\t\t -- train_counter: 1160, test_counter:80\n",
      "Sat Jan  1 23:03:17 2022\tEpoch: 528, Loss: 0.4891, Val: 3.9127, Test: 3.9352\n",
      "\t\t -- train_counter: 1179, test_counter:74\n",
      "Sat Jan  1 23:03:20 2022\tEpoch: 529, Loss: 0.5227, Val: 3.6245, Test: 3.6016\n",
      "\t\t -- train_counter: 1159, test_counter:78\n",
      "Sat Jan  1 23:03:23 2022\tEpoch: 530, Loss: 0.5282, Val: 3.5674, Test: 3.6717\n",
      "\t\t -- train_counter: 1168, test_counter:58\n",
      "Sat Jan  1 23:03:26 2022\tEpoch: 531, Loss: 0.5840, Val: 3.5652, Test: 3.4562\n",
      "\t\t -- train_counter: 1153, test_counter:75\n",
      "Sat Jan  1 23:03:28 2022\tEpoch: 532, Loss: 0.4959, Val: 3.6377, Test: 3.5336\n",
      "\t\t -- train_counter: 1189, test_counter:77\n",
      "Sat Jan  1 23:03:31 2022\tEpoch: 533, Loss: 0.4957, Val: 3.6985, Test: 3.8681\n",
      "\t\t -- train_counter: 1195, test_counter:63\n",
      "Sat Jan  1 23:03:34 2022\tEpoch: 534, Loss: 0.4982, Val: 3.8862, Test: 4.0904\n",
      "\t\t -- train_counter: 1188, test_counter:58\n",
      "Sat Jan  1 23:03:36 2022\tEpoch: 535, Loss: 0.5504, Val: 3.8814, Test: 4.4736\n",
      "\t\t -- train_counter: 1175, test_counter:56\n",
      "Sat Jan  1 23:03:39 2022\tEpoch: 536, Loss: 0.5516, Val: 3.8273, Test: 3.5044\n",
      "\t\t -- train_counter: 1172, test_counter:65\n",
      "Sat Jan  1 23:03:42 2022\tEpoch: 537, Loss: 0.5679, Val: 3.4513, Test: 3.3223\n",
      "\t\t -- train_counter: 1177, test_counter:70\n",
      "Sat Jan  1 23:03:45 2022\tEpoch: 538, Loss: 0.5444, Val: 3.8904, Test: 3.6792\n",
      "\t\t -- train_counter: 1182, test_counter:51\n",
      "Sat Jan  1 23:03:48 2022\tEpoch: 539, Loss: 0.5355, Val: 6.0170, Test: 6.4975\n",
      "\t\t -- train_counter: 1178, test_counter:38\n",
      "Sat Jan  1 23:03:51 2022\tEpoch: 540, Loss: 0.5601, Val: 4.7165, Test: 5.2846\n",
      "\t\t -- train_counter: 1148, test_counter:54\n",
      "Sat Jan  1 23:03:53 2022\tEpoch: 541, Loss: 0.5523, Val: 3.6075, Test: 4.1767\n",
      "\t\t -- train_counter: 1162, test_counter:58\n",
      "Sat Jan  1 23:03:56 2022\tEpoch: 542, Loss: 0.5134, Val: 3.5394, Test: 3.7499\n",
      "\t\t -- train_counter: 1172, test_counter:69\n",
      "Sat Jan  1 23:03:59 2022\tEpoch: 543, Loss: 0.4781, Val: 3.9671, Test: 3.7200\n",
      "\t\t -- train_counter: 1196, test_counter:73\n",
      "Sat Jan  1 23:04:02 2022\tEpoch: 544, Loss: 0.5738, Val: 3.5285, Test: 3.4491\n",
      "\t\t -- train_counter: 1157, test_counter:77\n",
      "Sat Jan  1 23:04:05 2022\tEpoch: 545, Loss: 0.5208, Val: 3.4727, Test: 3.6326\n",
      "\t\t -- train_counter: 1181, test_counter:66\n",
      "Sat Jan  1 23:04:07 2022\tEpoch: 546, Loss: 0.5660, Val: 3.6070, Test: 3.4632\n",
      "\t\t -- train_counter: 1163, test_counter:72\n",
      "Sat Jan  1 23:04:11 2022\tEpoch: 547, Loss: 0.4977, Val: 3.4853, Test: 3.4184\n",
      "\t\t -- train_counter: 1205, test_counter:77\n",
      "Sat Jan  1 23:04:14 2022\tEpoch: 548, Loss: 0.5368, Val: 3.7256, Test: 3.5923\n",
      "\t\t -- train_counter: 1182, test_counter:71\n",
      "Sat Jan  1 23:04:17 2022\tEpoch: 549, Loss: 0.5394, Val: 3.3612, Test: 3.5331\n",
      "\t\t -- train_counter: 1174, test_counter:78\n",
      "Sat Jan  1 23:04:19 2022\tEpoch: 550, Loss: 0.5469, Val: 3.4899, Test: 3.5066\n",
      "\t\t -- train_counter: 1171, test_counter:63\n",
      "Sat Jan  1 23:04:22 2022\tEpoch: 551, Loss: 0.5929, Val: 3.3348, Test: 3.5715\n",
      "\t\t -- train_counter: 1172, test_counter:74\n",
      "Sat Jan  1 23:04:25 2022\tEpoch: 552, Loss: 0.5253, Val: 3.6180, Test: 3.6803\n",
      "\t\t -- train_counter: 1170, test_counter:84\n",
      "Sat Jan  1 23:04:28 2022\tEpoch: 553, Loss: 0.5039, Val: 3.7760, Test: 3.7319\n",
      "\t\t -- train_counter: 1185, test_counter:63\n",
      "Sat Jan  1 23:04:30 2022\tEpoch: 554, Loss: 0.5541, Val: 3.6847, Test: 3.7737\n",
      "\t\t -- train_counter: 1178, test_counter:53\n",
      "Sat Jan  1 23:04:33 2022\tEpoch: 555, Loss: 0.4566, Val: 6.1402, Test: 6.0597\n",
      "\t\t -- train_counter: 1195, test_counter:31\n",
      "Sat Jan  1 23:04:36 2022\tEpoch: 556, Loss: 0.5178, Val: 6.0776, Test: 6.6181\n",
      "\t\t -- train_counter: 1184, test_counter:47\n",
      "Sat Jan  1 23:04:39 2022\tEpoch: 557, Loss: 0.5251, Val: 4.1813, Test: 4.7901\n",
      "\t\t -- train_counter: 1182, test_counter:57\n",
      "Sat Jan  1 23:04:42 2022\tEpoch: 558, Loss: 0.5139, Val: 4.3866, Test: 4.7032\n",
      "\t\t -- train_counter: 1192, test_counter:54\n",
      "Sat Jan  1 23:04:45 2022\tEpoch: 559, Loss: 0.4963, Val: 3.6536, Test: 3.8691\n",
      "\t\t -- train_counter: 1181, test_counter:66\n",
      "Sat Jan  1 23:04:48 2022\tEpoch: 560, Loss: 0.5357, Val: 3.8279, Test: 4.1276\n",
      "\t\t -- train_counter: 1161, test_counter:65\n",
      "Sat Jan  1 23:04:50 2022\tEpoch: 561, Loss: 0.5174, Val: 3.9473, Test: 3.9316\n",
      "\t\t -- train_counter: 1180, test_counter:82\n",
      "Sat Jan  1 23:04:53 2022\tEpoch: 562, Loss: 0.5311, Val: 3.7088, Test: 3.6428\n",
      "\t\t -- train_counter: 1164, test_counter:76\n",
      "Sat Jan  1 23:04:56 2022\tEpoch: 563, Loss: 0.5230, Val: 3.2444, Test: 3.4115\n",
      "\t\t -- train_counter: 1187, test_counter:70\n",
      "Sat Jan  1 23:04:59 2022\tEpoch: 564, Loss: 0.5331, Val: 3.7018, Test: 3.3104\n",
      "\t\t -- train_counter: 1170, test_counter:75\n",
      "Sat Jan  1 23:05:01 2022\tEpoch: 565, Loss: 0.4781, Val: 3.9303, Test: 3.9556\n",
      "\t\t -- train_counter: 1193, test_counter:74\n",
      "Sat Jan  1 23:05:04 2022\tEpoch: 566, Loss: 0.5127, Val: 3.5957, Test: 3.6272\n",
      "\t\t -- train_counter: 1191, test_counter:74\n",
      "Sat Jan  1 23:05:07 2022\tEpoch: 567, Loss: 0.5384, Val: 3.7961, Test: 3.4333\n",
      "\t\t -- train_counter: 1159, test_counter:75\n",
      "Sat Jan  1 23:05:10 2022\tEpoch: 568, Loss: 0.5476, Val: 3.6256, Test: 3.4668\n",
      "\t\t -- train_counter: 1180, test_counter:79\n",
      "Sat Jan  1 23:05:13 2022\tEpoch: 569, Loss: 0.5177, Val: 3.6570, Test: 3.5527\n",
      "\t\t -- train_counter: 1183, test_counter:74\n",
      "Sat Jan  1 23:05:16 2022\tEpoch: 570, Loss: 0.4755, Val: 3.5135, Test: 3.4619\n",
      "\t\t -- train_counter: 1177, test_counter:69\n",
      "Sat Jan  1 23:05:18 2022\tEpoch: 571, Loss: 0.5667, Val: 3.7052, Test: 3.9346\n",
      "\t\t -- train_counter: 1169, test_counter:70\n",
      "Sat Jan  1 23:05:21 2022\tEpoch: 572, Loss: 0.5911, Val: 3.7618, Test: 3.4692\n",
      "\t\t -- train_counter: 1146, test_counter:74\n",
      "Sat Jan  1 23:05:24 2022\tEpoch: 573, Loss: 0.4801, Val: 3.3154, Test: 3.4524\n",
      "\t\t -- train_counter: 1190, test_counter:72\n",
      "Sat Jan  1 23:05:27 2022\tEpoch: 574, Loss: 0.4883, Val: 3.6375, Test: 3.6332\n",
      "\t\t -- train_counter: 1204, test_counter:83\n",
      "Sat Jan  1 23:05:29 2022\tEpoch: 575, Loss: 0.4855, Val: 3.5156, Test: 3.4812\n",
      "\t\t -- train_counter: 1199, test_counter:64\n",
      "Sat Jan  1 23:05:32 2022\tEpoch: 576, Loss: 0.5439, Val: 6.4680, Test: 6.4629\n",
      "\t\t -- train_counter: 1171, test_counter:44\n",
      "Sat Jan  1 23:05:35 2022\tEpoch: 577, Loss: 0.5454, Val: 7.1028, Test: 6.8994\n",
      "\t\t -- train_counter: 1188, test_counter:37\n",
      "Sat Jan  1 23:05:38 2022\tEpoch: 578, Loss: 0.5317, Val: 3.8182, Test: 4.1355\n",
      "\t\t -- train_counter: 1171, test_counter:67\n",
      "Sat Jan  1 23:05:41 2022\tEpoch: 579, Loss: 0.4835, Val: 3.4789, Test: 3.6502\n",
      "\t\t -- train_counter: 1182, test_counter:68\n",
      "Sat Jan  1 23:05:44 2022\tEpoch: 580, Loss: 0.5128, Val: 3.7369, Test: 3.5674\n",
      "\t\t -- train_counter: 1184, test_counter:62\n",
      "Sat Jan  1 23:05:47 2022\tEpoch: 581, Loss: 0.5078, Val: 3.9812, Test: 4.0011\n",
      "\t\t -- train_counter: 1172, test_counter:65\n",
      "Sat Jan  1 23:05:49 2022\tEpoch: 582, Loss: 0.5383, Val: 3.8125, Test: 3.6189\n",
      "\t\t -- train_counter: 1171, test_counter:82\n",
      "Sat Jan  1 23:05:52 2022\tEpoch: 583, Loss: 0.5073, Val: 3.6277, Test: 3.4601\n",
      "\t\t -- train_counter: 1177, test_counter:78\n",
      "Sat Jan  1 23:05:55 2022\tEpoch: 584, Loss: 0.5555, Val: 4.4744, Test: 4.1561\n",
      "\t\t -- train_counter: 1149, test_counter:68\n",
      "Sat Jan  1 23:05:58 2022\tEpoch: 585, Loss: 0.5344, Val: 5.6645, Test: 6.0346\n",
      "\t\t -- train_counter: 1189, test_counter:40\n",
      "Sat Jan  1 23:06:01 2022\tEpoch: 586, Loss: 0.5517, Val: 5.7786, Test: 5.9047\n",
      "\t\t -- train_counter: 1166, test_counter:38\n",
      "Sat Jan  1 23:06:04 2022\tEpoch: 587, Loss: 0.5074, Val: 8.9198, Test: 9.6584\n",
      "\t\t -- train_counter: 1179, test_counter:37\n",
      "Sat Jan  1 23:06:07 2022\tEpoch: 588, Loss: 0.5432, Val: 7.3043, Test: 8.7658\n",
      "\t\t -- train_counter: 1177, test_counter:27\n",
      "Sat Jan  1 23:06:10 2022\tEpoch: 589, Loss: 0.5305, Val: 4.2283, Test: 4.0166\n",
      "\t\t -- train_counter: 1164, test_counter:58\n",
      "Sat Jan  1 23:06:13 2022\tEpoch: 590, Loss: 1.0711, Val: 3.6131, Test: 3.8969\n",
      "\t\t -- train_counter: 977, test_counter:51\n",
      "Sat Jan  1 23:06:15 2022\tEpoch: 591, Loss: 0.8142, Val: 13.1604, Test: 13.3862\n",
      "\t\t -- train_counter: 1049, test_counter:34\n",
      "Sat Jan  1 23:06:18 2022\tEpoch: 592, Loss: 0.7122, Val: 10.7854, Test: 11.4546\n",
      "\t\t -- train_counter: 1081, test_counter:30\n",
      "Sat Jan  1 23:06:21 2022\tEpoch: 593, Loss: 0.6641, Val: 6.6943, Test: 7.3002\n",
      "\t\t -- train_counter: 1106, test_counter:27\n",
      "Sat Jan  1 23:06:24 2022\tEpoch: 594, Loss: 0.5898, Val: 6.1409, Test: 6.4112\n",
      "\t\t -- train_counter: 1149, test_counter:37\n",
      "Sat Jan  1 23:06:26 2022\tEpoch: 595, Loss: 0.5642, Val: 5.0801, Test: 5.9271\n",
      "\t\t -- train_counter: 1160, test_counter:47\n",
      "Sat Jan  1 23:06:29 2022\tEpoch: 596, Loss: 0.6117, Val: 3.4607, Test: 3.6675\n",
      "\t\t -- train_counter: 1155, test_counter:66\n",
      "Sat Jan  1 23:06:32 2022\tEpoch: 597, Loss: 0.5185, Val: 3.6097, Test: 3.5396\n",
      "\t\t -- train_counter: 1173, test_counter:71\n",
      "Sat Jan  1 23:06:35 2022\tEpoch: 598, Loss: 0.5181, Val: 3.5878, Test: 3.6076\n",
      "\t\t -- train_counter: 1170, test_counter:65\n",
      "Sat Jan  1 23:06:38 2022\tEpoch: 599, Loss: 0.5615, Val: 3.7843, Test: 3.8370\n",
      "\t\t -- train_counter: 1167, test_counter:56\n",
      "Sat Jan  1 23:06:41 2022\tEpoch: 600, Loss: 0.5318, Val: 3.7372, Test: 3.4099\n",
      "\t\t -- train_counter: 1172, test_counter:66\n",
      "Sat Jan  1 23:06:43 2022\tEpoch: 601, Loss: 0.4889, Val: 3.5097, Test: 3.6378\n",
      "\t\t -- train_counter: 1184, test_counter:73\n",
      "Sat Jan  1 23:06:47 2022\tEpoch: 602, Loss: 0.5408, Val: 3.8612, Test: 3.9529\n",
      "\t\t -- train_counter: 1162, test_counter:57\n",
      "Sat Jan  1 23:06:49 2022\tEpoch: 603, Loss: 0.5449, Val: 3.6532, Test: 3.7427\n",
      "\t\t -- train_counter: 1169, test_counter:66\n",
      "Sat Jan  1 23:06:52 2022\tEpoch: 604, Loss: 0.4800, Val: 3.5892, Test: 3.6492\n",
      "\t\t -- train_counter: 1191, test_counter:68\n",
      "Sat Jan  1 23:06:55 2022\tEpoch: 605, Loss: 0.5243, Val: 3.4979, Test: 3.8637\n",
      "\t\t -- train_counter: 1164, test_counter:65\n",
      "Sat Jan  1 23:06:58 2022\tEpoch: 606, Loss: 0.5118, Val: 3.9797, Test: 4.1026\n",
      "\t\t -- train_counter: 1173, test_counter:72\n",
      "Sat Jan  1 23:07:00 2022\tEpoch: 607, Loss: 0.4588, Val: 3.5963, Test: 3.7127\n",
      "\t\t -- train_counter: 1202, test_counter:78\n",
      "Sat Jan  1 23:07:04 2022\tEpoch: 608, Loss: 0.5217, Val: 3.5109, Test: 3.7056\n",
      "\t\t -- train_counter: 1176, test_counter:68\n",
      "Sat Jan  1 23:07:07 2022\tEpoch: 609, Loss: 0.4839, Val: 3.6305, Test: 3.7605\n",
      "\t\t -- train_counter: 1194, test_counter:77\n",
      "Sat Jan  1 23:07:09 2022\tEpoch: 610, Loss: 0.5256, Val: 3.8260, Test: 3.9512\n",
      "\t\t -- train_counter: 1176, test_counter:80\n",
      "Sat Jan  1 23:07:12 2022\tEpoch: 611, Loss: 0.5107, Val: 3.7896, Test: 3.9861\n",
      "\t\t -- train_counter: 1186, test_counter:70\n",
      "Sat Jan  1 23:07:15 2022\tEpoch: 612, Loss: 0.4888, Val: 3.9001, Test: 4.0310\n",
      "\t\t -- train_counter: 1186, test_counter:68\n",
      "Sat Jan  1 23:07:18 2022\tEpoch: 613, Loss: 0.5448, Val: 3.4604, Test: 3.6627\n",
      "\t\t -- train_counter: 1166, test_counter:58\n",
      "Sat Jan  1 23:07:20 2022\tEpoch: 614, Loss: 0.5590, Val: 3.2364, Test: 3.2405\n",
      "\t\t -- train_counter: 1158, test_counter:70\n",
      "Sat Jan  1 23:07:23 2022\tEpoch: 615, Loss: 0.5268, Val: 3.4647, Test: 3.7983\n",
      "\t\t -- train_counter: 1173, test_counter:59\n",
      "Sat Jan  1 23:07:26 2022\tEpoch: 616, Loss: 0.5211, Val: 3.3790, Test: 3.6590\n",
      "\t\t -- train_counter: 1187, test_counter:69\n",
      "Sat Jan  1 23:07:29 2022\tEpoch: 617, Loss: 0.5387, Val: 3.2383, Test: 3.4194\n",
      "\t\t -- train_counter: 1175, test_counter:74\n",
      "Sat Jan  1 23:07:32 2022\tEpoch: 618, Loss: 0.5685, Val: 5.7890, Test: 6.0882\n",
      "\t\t -- train_counter: 1170, test_counter:46\n",
      "Sat Jan  1 23:07:35 2022\tEpoch: 619, Loss: 0.7105, Val: 22.9177, Test: 22.7384\n",
      "\t\t -- train_counter: 1106, test_counter:26\n",
      "Sat Jan  1 23:07:38 2022\tEpoch: 620, Loss: 0.5832, Val: 5.4407, Test: 5.6718\n",
      "\t\t -- train_counter: 1147, test_counter:48\n",
      "Sat Jan  1 23:07:41 2022\tEpoch: 621, Loss: 0.5354, Val: 4.9257, Test: 5.3436\n",
      "\t\t -- train_counter: 1188, test_counter:68\n",
      "Sat Jan  1 23:07:43 2022\tEpoch: 622, Loss: 0.5885, Val: 4.4154, Test: 5.0181\n",
      "\t\t -- train_counter: 1168, test_counter:55\n",
      "Sat Jan  1 23:07:46 2022\tEpoch: 623, Loss: 0.5066, Val: 4.3022, Test: 4.7238\n",
      "\t\t -- train_counter: 1176, test_counter:55\n",
      "Sat Jan  1 23:07:49 2022\tEpoch: 624, Loss: 0.5643, Val: 3.3106, Test: 3.5181\n",
      "\t\t -- train_counter: 1158, test_counter:75\n",
      "Sat Jan  1 23:07:52 2022\tEpoch: 625, Loss: 0.5605, Val: 3.8069, Test: 3.7204\n",
      "\t\t -- train_counter: 1176, test_counter:74\n",
      "Sat Jan  1 23:07:55 2022\tEpoch: 626, Loss: 0.5251, Val: 3.5984, Test: 3.5099\n",
      "\t\t -- train_counter: 1175, test_counter:69\n",
      "Sat Jan  1 23:07:57 2022\tEpoch: 627, Loss: 0.4704, Val: 3.6477, Test: 3.4924\n",
      "\t\t -- train_counter: 1208, test_counter:68\n",
      "Sat Jan  1 23:08:00 2022\tEpoch: 628, Loss: 0.5030, Val: 3.5994, Test: 3.7250\n",
      "\t\t -- train_counter: 1191, test_counter:81\n",
      "Sat Jan  1 23:08:03 2022\tEpoch: 629, Loss: 0.5312, Val: 3.7331, Test: 3.6874\n",
      "\t\t -- train_counter: 1173, test_counter:60\n",
      "Sat Jan  1 23:08:06 2022\tEpoch: 630, Loss: 0.4829, Val: 3.2964, Test: 3.5485\n",
      "\t\t -- train_counter: 1196, test_counter:65\n",
      "Sat Jan  1 23:08:09 2022\tEpoch: 631, Loss: 0.5322, Val: 3.2002, Test: 3.3210\n",
      "\t\t -- train_counter: 1181, test_counter:76\n",
      "Sat Jan  1 23:08:12 2022\tEpoch: 632, Loss: 0.5668, Val: 3.4341, Test: 3.3384\n",
      "\t\t -- train_counter: 1158, test_counter:78\n",
      "Sat Jan  1 23:08:14 2022\tEpoch: 633, Loss: 0.4876, Val: 3.0870, Test: 3.4966\n",
      "\t\t -- train_counter: 1191, test_counter:71\n",
      "Sat Jan  1 23:08:17 2022\tEpoch: 634, Loss: 0.4940, Val: 3.3995, Test: 3.4691\n",
      "\t\t -- train_counter: 1195, test_counter:69\n",
      "Sat Jan  1 23:08:20 2022\tEpoch: 635, Loss: 0.4591, Val: 3.6263, Test: 3.6946\n",
      "\t\t -- train_counter: 1213, test_counter:74\n",
      "Sat Jan  1 23:08:23 2022\tEpoch: 636, Loss: 0.5521, Val: 3.4538, Test: 3.7021\n",
      "\t\t -- train_counter: 1171, test_counter:63\n",
      "Sat Jan  1 23:08:26 2022\tEpoch: 637, Loss: 0.5672, Val: 3.5025, Test: 3.3453\n",
      "\t\t -- train_counter: 1170, test_counter:73\n",
      "Sat Jan  1 23:08:28 2022\tEpoch: 638, Loss: 0.4589, Val: 3.8461, Test: 3.6099\n",
      "\t\t -- train_counter: 1194, test_counter:74\n",
      "Sat Jan  1 23:08:31 2022\tEpoch: 639, Loss: 0.5143, Val: 3.9999, Test: 4.0668\n",
      "\t\t -- train_counter: 1181, test_counter:65\n",
      "Sat Jan  1 23:08:34 2022\tEpoch: 640, Loss: 0.4916, Val: 3.4101, Test: 3.4989\n",
      "\t\t -- train_counter: 1223, test_counter:73\n",
      "Sat Jan  1 23:08:37 2022\tEpoch: 641, Loss: 0.5169, Val: 3.5735, Test: 3.1585\n",
      "\t\t -- train_counter: 1190, test_counter:76\n",
      "Sat Jan  1 23:08:40 2022\tEpoch: 642, Loss: 0.4721, Val: 3.6498, Test: 3.8814\n",
      "\t\t -- train_counter: 1195, test_counter:77\n",
      "Sat Jan  1 23:08:43 2022\tEpoch: 643, Loss: 0.4826, Val: 3.5870, Test: 3.7985\n",
      "\t\t -- train_counter: 1198, test_counter:73\n",
      "Sat Jan  1 23:08:45 2022\tEpoch: 644, Loss: 0.4896, Val: 3.7397, Test: 3.7984\n",
      "\t\t -- train_counter: 1202, test_counter:74\n",
      "Sat Jan  1 23:08:48 2022\tEpoch: 645, Loss: 0.5072, Val: 3.6508, Test: 3.8709\n",
      "\t\t -- train_counter: 1168, test_counter:76\n",
      "Sat Jan  1 23:08:51 2022\tEpoch: 646, Loss: 0.5087, Val: 3.6418, Test: 3.6450\n",
      "\t\t -- train_counter: 1193, test_counter:74\n",
      "Sat Jan  1 23:08:54 2022\tEpoch: 647, Loss: 0.5242, Val: 3.7801, Test: 3.7041\n",
      "\t\t -- train_counter: 1183, test_counter:69\n",
      "Sat Jan  1 23:08:57 2022\tEpoch: 648, Loss: 0.5489, Val: 3.5162, Test: 3.6712\n",
      "\t\t -- train_counter: 1158, test_counter:66\n",
      "Sat Jan  1 23:09:00 2022\tEpoch: 649, Loss: 0.5211, Val: 3.5204, Test: 3.5283\n",
      "\t\t -- train_counter: 1170, test_counter:69\n",
      "Sat Jan  1 23:09:03 2022\tEpoch: 650, Loss: 0.4868, Val: 3.5287, Test: 3.5353\n",
      "\t\t -- train_counter: 1174, test_counter:74\n",
      "Sat Jan  1 23:09:06 2022\tEpoch: 651, Loss: 0.4755, Val: 3.4698, Test: 3.7183\n",
      "\t\t -- train_counter: 1205, test_counter:73\n",
      "Sat Jan  1 23:09:08 2022\tEpoch: 652, Loss: 0.4669, Val: 3.6253, Test: 3.8728\n",
      "\t\t -- train_counter: 1212, test_counter:68\n",
      "Sat Jan  1 23:09:11 2022\tEpoch: 653, Loss: 0.4863, Val: 3.7143, Test: 3.9054\n",
      "\t\t -- train_counter: 1201, test_counter:74\n",
      "Sat Jan  1 23:09:14 2022\tEpoch: 654, Loss: 0.4462, Val: 3.2782, Test: 3.6422\n",
      "\t\t -- train_counter: 1211, test_counter:75\n",
      "Sat Jan  1 23:09:17 2022\tEpoch: 655, Loss: 0.5087, Val: 4.0796, Test: 4.3179\n",
      "\t\t -- train_counter: 1193, test_counter:58\n",
      "Sat Jan  1 23:09:20 2022\tEpoch: 656, Loss: 0.4836, Val: 4.0879, Test: 4.9725\n",
      "\t\t -- train_counter: 1199, test_counter:53\n",
      "Sat Jan  1 23:09:22 2022\tEpoch: 657, Loss: 0.4595, Val: 3.6392, Test: 3.9974\n",
      "\t\t -- train_counter: 1204, test_counter:59\n",
      "Sat Jan  1 23:09:25 2022\tEpoch: 658, Loss: 0.5099, Val: 3.7020, Test: 3.8363\n",
      "\t\t -- train_counter: 1191, test_counter:69\n",
      "Sat Jan  1 23:09:29 2022\tEpoch: 659, Loss: 0.4534, Val: 3.7994, Test: 4.0940\n",
      "\t\t -- train_counter: 1208, test_counter:74\n",
      "Sat Jan  1 23:09:32 2022\tEpoch: 660, Loss: 0.4810, Val: 3.8122, Test: 3.6918\n",
      "\t\t -- train_counter: 1208, test_counter:59\n",
      "Sat Jan  1 23:09:34 2022\tEpoch: 661, Loss: 0.4884, Val: 3.8153, Test: 3.8850\n",
      "\t\t -- train_counter: 1191, test_counter:72\n",
      "Sat Jan  1 23:09:37 2022\tEpoch: 662, Loss: 0.5093, Val: 3.4450, Test: 3.6296\n",
      "\t\t -- train_counter: 1180, test_counter:82\n",
      "Sat Jan  1 23:09:40 2022\tEpoch: 663, Loss: 0.4914, Val: 3.4458, Test: 3.8396\n",
      "\t\t -- train_counter: 1174, test_counter:70\n",
      "Sat Jan  1 23:09:42 2022\tEpoch: 664, Loss: 0.4721, Val: 3.6611, Test: 3.7171\n",
      "\t\t -- train_counter: 1196, test_counter:78\n",
      "Sat Jan  1 23:09:45 2022\tEpoch: 665, Loss: 0.5018, Val: 3.7984, Test: 3.5065\n",
      "\t\t -- train_counter: 1199, test_counter:69\n",
      "Sat Jan  1 23:09:48 2022\tEpoch: 666, Loss: 0.4352, Val: 3.7788, Test: 3.6167\n",
      "\t\t -- train_counter: 1212, test_counter:68\n",
      "Sat Jan  1 23:09:51 2022\tEpoch: 667, Loss: 0.5294, Val: 3.6493, Test: 3.4663\n",
      "\t\t -- train_counter: 1175, test_counter:70\n",
      "Sat Jan  1 23:09:53 2022\tEpoch: 668, Loss: 0.4771, Val: 3.5403, Test: 3.5287\n",
      "\t\t -- train_counter: 1182, test_counter:84\n",
      "Sat Jan  1 23:09:57 2022\tEpoch: 669, Loss: 0.4539, Val: 4.2489, Test: 4.3402\n",
      "\t\t -- train_counter: 1213, test_counter:64\n",
      "Sat Jan  1 23:10:00 2022\tEpoch: 670, Loss: 0.4520, Val: 3.5113, Test: 3.9407\n",
      "\t\t -- train_counter: 1213, test_counter:68\n",
      "Sat Jan  1 23:10:03 2022\tEpoch: 671, Loss: 0.5050, Val: 3.4258, Test: 3.3788\n",
      "\t\t -- train_counter: 1199, test_counter:77\n",
      "Sat Jan  1 23:10:06 2022\tEpoch: 672, Loss: 0.5057, Val: 3.8324, Test: 3.6593\n",
      "\t\t -- train_counter: 1198, test_counter:62\n",
      "Sat Jan  1 23:10:09 2022\tEpoch: 673, Loss: 0.4966, Val: 3.3133, Test: 3.2966\n",
      "\t\t -- train_counter: 1176, test_counter:76\n",
      "Sat Jan  1 23:10:12 2022\tEpoch: 674, Loss: 0.5104, Val: 3.7178, Test: 3.8222\n",
      "\t\t -- train_counter: 1197, test_counter:73\n",
      "Sat Jan  1 23:10:14 2022\tEpoch: 675, Loss: 0.5116, Val: 3.4473, Test: 3.8147\n",
      "\t\t -- train_counter: 1185, test_counter:65\n",
      "Sat Jan  1 23:10:17 2022\tEpoch: 676, Loss: 0.5140, Val: 3.4344, Test: 3.3795\n",
      "\t\t -- train_counter: 1194, test_counter:70\n",
      "Sat Jan  1 23:10:20 2022\tEpoch: 677, Loss: 0.5021, Val: 3.4615, Test: 3.3796\n",
      "\t\t -- train_counter: 1189, test_counter:92\n",
      "Sat Jan  1 23:10:23 2022\tEpoch: 678, Loss: 0.5930, Val: 3.7780, Test: 3.6351\n",
      "\t\t -- train_counter: 1159, test_counter:73\n",
      "Sat Jan  1 23:10:26 2022\tEpoch: 679, Loss: 0.5648, Val: 3.5855, Test: 3.4839\n",
      "\t\t -- train_counter: 1179, test_counter:80\n",
      "Sat Jan  1 23:10:29 2022\tEpoch: 680, Loss: 0.5033, Val: 3.9282, Test: 3.7095\n",
      "\t\t -- train_counter: 1187, test_counter:62\n",
      "Sat Jan  1 23:10:31 2022\tEpoch: 681, Loss: 0.4832, Val: 3.4599, Test: 3.1968\n",
      "\t\t -- train_counter: 1190, test_counter:79\n",
      "Sat Jan  1 23:10:34 2022\tEpoch: 682, Loss: 0.5195, Val: 3.4748, Test: 3.5724\n",
      "\t\t -- train_counter: 1191, test_counter:90\n",
      "Sat Jan  1 23:10:37 2022\tEpoch: 683, Loss: 0.4996, Val: 3.4298, Test: 3.6359\n",
      "\t\t -- train_counter: 1194, test_counter:66\n",
      "Sat Jan  1 23:10:40 2022\tEpoch: 684, Loss: 0.4950, Val: 3.4072, Test: 3.6805\n",
      "\t\t -- train_counter: 1210, test_counter:77\n",
      "Sat Jan  1 23:10:43 2022\tEpoch: 685, Loss: 0.4686, Val: 3.6053, Test: 3.5954\n",
      "\t\t -- train_counter: 1208, test_counter:77\n",
      "Sat Jan  1 23:10:45 2022\tEpoch: 686, Loss: 0.4712, Val: 3.6664, Test: 3.5656\n",
      "\t\t -- train_counter: 1203, test_counter:69\n",
      "Sat Jan  1 23:10:48 2022\tEpoch: 687, Loss: 0.4858, Val: 3.6153, Test: 3.5275\n",
      "\t\t -- train_counter: 1204, test_counter:67\n",
      "Sat Jan  1 23:10:51 2022\tEpoch: 688, Loss: 0.4860, Val: 3.6065, Test: 3.4612\n",
      "\t\t -- train_counter: 1187, test_counter:75\n",
      "Sat Jan  1 23:10:54 2022\tEpoch: 689, Loss: 0.5013, Val: 3.5481, Test: 3.3792\n",
      "\t\t -- train_counter: 1188, test_counter:69\n",
      "Sat Jan  1 23:10:57 2022\tEpoch: 690, Loss: 0.4354, Val: 3.5081, Test: 3.5754\n",
      "\t\t -- train_counter: 1207, test_counter:80\n",
      "Sat Jan  1 23:11:00 2022\tEpoch: 691, Loss: 0.4357, Val: 3.3864, Test: 3.5584\n",
      "\t\t -- train_counter: 1213, test_counter:73\n",
      "Sat Jan  1 23:11:03 2022\tEpoch: 692, Loss: 0.5039, Val: 3.7624, Test: 3.8365\n",
      "\t\t -- train_counter: 1200, test_counter:70\n",
      "Sat Jan  1 23:11:06 2022\tEpoch: 693, Loss: 0.4932, Val: 3.5035, Test: 4.4991\n",
      "\t\t -- train_counter: 1213, test_counter:64\n",
      "Sat Jan  1 23:11:08 2022\tEpoch: 694, Loss: 0.4982, Val: 3.5424, Test: 3.8665\n",
      "\t\t -- train_counter: 1184, test_counter:67\n",
      "Sat Jan  1 23:11:11 2022\tEpoch: 695, Loss: 0.4919, Val: 3.3121, Test: 3.5525\n",
      "\t\t -- train_counter: 1195, test_counter:71\n",
      "Sat Jan  1 23:11:14 2022\tEpoch: 696, Loss: 0.4655, Val: 3.4382, Test: 3.7268\n",
      "\t\t -- train_counter: 1195, test_counter:66\n",
      "Sat Jan  1 23:11:16 2022\tEpoch: 697, Loss: 0.4758, Val: 3.6221, Test: 3.4237\n",
      "\t\t -- train_counter: 1194, test_counter:77\n",
      "Sat Jan  1 23:11:19 2022\tEpoch: 698, Loss: 0.4473, Val: 3.7106, Test: 3.4959\n",
      "\t\t -- train_counter: 1218, test_counter:63\n",
      "Sat Jan  1 23:11:22 2022\tEpoch: 699, Loss: 0.4691, Val: 3.6115, Test: 3.6903\n",
      "\t\t -- train_counter: 1221, test_counter:73\n",
      "Sat Jan  1 23:11:25 2022\tEpoch: 700, Loss: 0.4580, Val: 3.7148, Test: 3.8668\n",
      "\t\t -- train_counter: 1221, test_counter:73\n",
      "Sat Jan  1 23:11:28 2022\tEpoch: 701, Loss: 0.4832, Val: 3.6904, Test: 3.8231\n",
      "\t\t -- train_counter: 1206, test_counter:73\n",
      "Sat Jan  1 23:11:30 2022\tEpoch: 702, Loss: 0.4594, Val: 3.4807, Test: 3.6205\n",
      "\t\t -- train_counter: 1213, test_counter:76\n",
      "Sat Jan  1 23:11:33 2022\tEpoch: 703, Loss: 0.4349, Val: 3.4260, Test: 3.5003\n",
      "\t\t -- train_counter: 1208, test_counter:78\n",
      "Sat Jan  1 23:11:36 2022\tEpoch: 704, Loss: 0.5251, Val: 3.4289, Test: 3.6782\n",
      "\t\t -- train_counter: 1212, test_counter:56\n",
      "Sat Jan  1 23:11:39 2022\tEpoch: 705, Loss: 0.4756, Val: 3.5336, Test: 3.7632\n",
      "\t\t -- train_counter: 1192, test_counter:65\n",
      "Sat Jan  1 23:11:41 2022\tEpoch: 706, Loss: 0.4933, Val: 3.7273, Test: 3.7025\n",
      "\t\t -- train_counter: 1203, test_counter:65\n",
      "Sat Jan  1 23:11:44 2022\tEpoch: 707, Loss: 0.4673, Val: 3.7067, Test: 3.5420\n",
      "\t\t -- train_counter: 1196, test_counter:84\n",
      "Sat Jan  1 23:11:46 2022\tEpoch: 708, Loss: 0.4863, Val: 3.7151, Test: 3.3914\n",
      "\t\t -- train_counter: 1201, test_counter:85\n",
      "Sat Jan  1 23:11:49 2022\tEpoch: 709, Loss: 0.4989, Val: 3.3486, Test: 4.0227\n",
      "\t\t -- train_counter: 1195, test_counter:72\n",
      "Sat Jan  1 23:11:53 2022\tEpoch: 710, Loss: 0.4851, Val: 3.4995, Test: 3.6031\n",
      "\t\t -- train_counter: 1205, test_counter:70\n",
      "Sat Jan  1 23:11:56 2022\tEpoch: 711, Loss: 0.4938, Val: 3.1724, Test: 3.3341\n",
      "\t\t -- train_counter: 1198, test_counter:70\n",
      "Sat Jan  1 23:11:58 2022\tEpoch: 712, Loss: 0.4637, Val: 3.4398, Test: 3.3036\n",
      "\t\t -- train_counter: 1208, test_counter:72\n",
      "Sat Jan  1 23:12:01 2022\tEpoch: 713, Loss: 0.4744, Val: 3.5414, Test: 3.4675\n",
      "\t\t -- train_counter: 1195, test_counter:59\n",
      "Sat Jan  1 23:12:04 2022\tEpoch: 714, Loss: 0.4352, Val: 3.6246, Test: 3.5135\n",
      "\t\t -- train_counter: 1201, test_counter:78\n",
      "Sat Jan  1 23:12:06 2022\tEpoch: 715, Loss: 0.4561, Val: 3.4483, Test: 3.8375\n",
      "\t\t -- train_counter: 1209, test_counter:65\n",
      "Sat Jan  1 23:12:09 2022\tEpoch: 716, Loss: 0.4318, Val: 3.8445, Test: 3.6475\n",
      "\t\t -- train_counter: 1220, test_counter:67\n",
      "Sat Jan  1 23:12:12 2022\tEpoch: 717, Loss: 0.4636, Val: 3.8885, Test: 4.0339\n",
      "\t\t -- train_counter: 1201, test_counter:66\n",
      "Sat Jan  1 23:12:14 2022\tEpoch: 718, Loss: 0.4504, Val: 3.9784, Test: 4.2161\n",
      "\t\t -- train_counter: 1223, test_counter:57\n",
      "Sat Jan  1 23:12:17 2022\tEpoch: 719, Loss: 0.5519, Val: 3.7612, Test: 3.6138\n",
      "\t\t -- train_counter: 1188, test_counter:67\n",
      "Sat Jan  1 23:12:21 2022\tEpoch: 720, Loss: 0.5494, Val: 3.5119, Test: 3.5854\n",
      "\t\t -- train_counter: 1175, test_counter:83\n",
      "Sat Jan  1 23:12:23 2022\tEpoch: 721, Loss: 0.4697, Val: 3.5224, Test: 3.4528\n",
      "\t\t -- train_counter: 1201, test_counter:75\n",
      "Sat Jan  1 23:12:26 2022\tEpoch: 722, Loss: 0.4925, Val: 3.6234, Test: 3.7598\n",
      "\t\t -- train_counter: 1192, test_counter:70\n",
      "Sat Jan  1 23:12:29 2022\tEpoch: 723, Loss: 0.4564, Val: 3.6563, Test: 3.7113\n",
      "\t\t -- train_counter: 1196, test_counter:74\n",
      "Sat Jan  1 23:12:31 2022\tEpoch: 724, Loss: 0.4679, Val: 3.6067, Test: 3.6475\n",
      "\t\t -- train_counter: 1198, test_counter:75\n",
      "Sat Jan  1 23:12:34 2022\tEpoch: 725, Loss: 0.4721, Val: 3.6688, Test: 3.5247\n",
      "\t\t -- train_counter: 1203, test_counter:80\n",
      "Sat Jan  1 23:12:36 2022\tEpoch: 726, Loss: 0.4500, Val: 3.9232, Test: 3.4326\n",
      "\t\t -- train_counter: 1205, test_counter:79\n",
      "Sat Jan  1 23:12:39 2022\tEpoch: 727, Loss: 0.4612, Val: 3.7017, Test: 3.4777\n",
      "\t\t -- train_counter: 1203, test_counter:79\n",
      "Sat Jan  1 23:12:41 2022\tEpoch: 728, Loss: 0.5533, Val: 3.6062, Test: 3.8952\n",
      "\t\t -- train_counter: 1166, test_counter:68\n",
      "Sat Jan  1 23:12:44 2022\tEpoch: 729, Loss: 0.4792, Val: 3.7018, Test: 3.5356\n",
      "\t\t -- train_counter: 1208, test_counter:69\n",
      "Sat Jan  1 23:12:48 2022\tEpoch: 730, Loss: 0.5047, Val: 3.6592, Test: 4.2579\n",
      "\t\t -- train_counter: 1185, test_counter:75\n",
      "Sat Jan  1 23:12:51 2022\tEpoch: 731, Loss: 0.5077, Val: 3.7782, Test: 3.9235\n",
      "\t\t -- train_counter: 1193, test_counter:67\n",
      "Sat Jan  1 23:12:53 2022\tEpoch: 732, Loss: 0.4788, Val: 3.7806, Test: 3.8473\n",
      "\t\t -- train_counter: 1189, test_counter:67\n",
      "Sat Jan  1 23:12:56 2022\tEpoch: 733, Loss: 0.5087, Val: 3.7326, Test: 3.3531\n",
      "\t\t -- train_counter: 1183, test_counter:75\n",
      "Sat Jan  1 23:12:58 2022\tEpoch: 734, Loss: 0.4976, Val: 3.3825, Test: 3.3791\n",
      "\t\t -- train_counter: 1200, test_counter:74\n",
      "Sat Jan  1 23:13:01 2022\tEpoch: 735, Loss: 0.4763, Val: 3.3856, Test: 3.5468\n",
      "\t\t -- train_counter: 1213, test_counter:64\n",
      "Sat Jan  1 23:13:04 2022\tEpoch: 736, Loss: 0.4079, Val: 3.7333, Test: 3.5593\n",
      "\t\t -- train_counter: 1211, test_counter:67\n",
      "Sat Jan  1 23:13:07 2022\tEpoch: 737, Loss: 0.4856, Val: 3.6113, Test: 3.4348\n",
      "\t\t -- train_counter: 1203, test_counter:72\n",
      "Sat Jan  1 23:13:09 2022\tEpoch: 738, Loss: 0.4123, Val: 3.5968, Test: 3.4380\n",
      "\t\t -- train_counter: 1228, test_counter:55\n",
      "Sat Jan  1 23:13:12 2022\tEpoch: 739, Loss: 0.4450, Val: 3.3686, Test: 3.4315\n",
      "\t\t -- train_counter: 1199, test_counter:67\n",
      "Sat Jan  1 23:13:15 2022\tEpoch: 740, Loss: 0.4396, Val: 3.8065, Test: 3.6980\n",
      "\t\t -- train_counter: 1221, test_counter:69\n",
      "Sat Jan  1 23:13:18 2022\tEpoch: 741, Loss: 0.4613, Val: 3.9545, Test: 4.0194\n",
      "\t\t -- train_counter: 1189, test_counter:67\n",
      "Sat Jan  1 23:13:21 2022\tEpoch: 742, Loss: 0.4643, Val: 4.3681, Test: 5.0081\n",
      "\t\t -- train_counter: 1208, test_counter:51\n",
      "Sat Jan  1 23:13:23 2022\tEpoch: 743, Loss: 0.4825, Val: 3.3864, Test: 3.5999\n",
      "\t\t -- train_counter: 1218, test_counter:62\n",
      "Sat Jan  1 23:13:26 2022\tEpoch: 744, Loss: 0.5115, Val: 4.2846, Test: 4.6511\n",
      "\t\t -- train_counter: 1194, test_counter:63\n",
      "Sat Jan  1 23:13:28 2022\tEpoch: 745, Loss: 0.5625, Val: 6.8809, Test: 7.9082\n",
      "\t\t -- train_counter: 1169, test_counter:32\n",
      "Sat Jan  1 23:13:31 2022\tEpoch: 746, Loss: 0.4807, Val: 4.7370, Test: 5.5561\n",
      "\t\t -- train_counter: 1199, test_counter:55\n",
      "Sat Jan  1 23:13:34 2022\tEpoch: 747, Loss: 0.5044, Val: 4.2640, Test: 4.5234\n",
      "\t\t -- train_counter: 1187, test_counter:61\n",
      "Sat Jan  1 23:13:36 2022\tEpoch: 748, Loss: 0.5082, Val: 3.5097, Test: 3.5912\n",
      "\t\t -- train_counter: 1181, test_counter:82\n",
      "Sat Jan  1 23:13:39 2022\tEpoch: 749, Loss: 0.5079, Val: 3.5363, Test: 3.4803\n",
      "\t\t -- train_counter: 1178, test_counter:82\n",
      "Sat Jan  1 23:13:43 2022\tEpoch: 750, Loss: 0.4694, Val: 3.6109, Test: 3.3798\n",
      "\t\t -- train_counter: 1221, test_counter:72\n",
      "Sat Jan  1 23:13:46 2022\tEpoch: 751, Loss: 0.4983, Val: 3.6659, Test: 4.0733\n",
      "\t\t -- train_counter: 1207, test_counter:81\n",
      "Sat Jan  1 23:13:48 2022\tEpoch: 752, Loss: 0.4046, Val: 3.4702, Test: 3.5322\n",
      "\t\t -- train_counter: 1234, test_counter:79\n",
      "Sat Jan  1 23:13:51 2022\tEpoch: 753, Loss: 0.4556, Val: 3.4474, Test: 3.4528\n",
      "\t\t -- train_counter: 1206, test_counter:82\n",
      "Sat Jan  1 23:13:54 2022\tEpoch: 754, Loss: 0.4925, Val: 3.4145, Test: 3.2989\n",
      "\t\t -- train_counter: 1191, test_counter:78\n",
      "Sat Jan  1 23:13:56 2022\tEpoch: 755, Loss: 0.4258, Val: 3.5023, Test: 3.6236\n",
      "\t\t -- train_counter: 1214, test_counter:89\n",
      "Sat Jan  1 23:13:59 2022\tEpoch: 756, Loss: 0.4229, Val: 3.6662, Test: 3.5288\n",
      "\t\t -- train_counter: 1219, test_counter:84\n",
      "Sat Jan  1 23:14:02 2022\tEpoch: 757, Loss: 0.4784, Val: 3.7014, Test: 3.5232\n",
      "\t\t -- train_counter: 1196, test_counter:78\n",
      "Sat Jan  1 23:14:05 2022\tEpoch: 758, Loss: 0.5063, Val: 3.5121, Test: 3.3313\n",
      "\t\t -- train_counter: 1200, test_counter:80\n",
      "Sat Jan  1 23:14:08 2022\tEpoch: 759, Loss: 0.4516, Val: 3.2774, Test: 3.3199\n",
      "\t\t -- train_counter: 1212, test_counter:70\n",
      "Sat Jan  1 23:14:11 2022\tEpoch: 760, Loss: 0.5075, Val: 3.4849, Test: 3.3831\n",
      "\t\t -- train_counter: 1206, test_counter:79\n",
      "Sat Jan  1 23:14:14 2022\tEpoch: 761, Loss: 0.4620, Val: 3.4170, Test: 3.4379\n",
      "\t\t -- train_counter: 1198, test_counter:76\n",
      "Sat Jan  1 23:14:16 2022\tEpoch: 762, Loss: 0.4430, Val: 3.6712, Test: 3.6942\n",
      "\t\t -- train_counter: 1207, test_counter:74\n",
      "Sat Jan  1 23:14:19 2022\tEpoch: 763, Loss: 0.4274, Val: 3.5520, Test: 3.7272\n",
      "\t\t -- train_counter: 1229, test_counter:73\n",
      "Sat Jan  1 23:14:21 2022\tEpoch: 764, Loss: 0.4628, Val: 3.4990, Test: 3.7791\n",
      "\t\t -- train_counter: 1212, test_counter:79\n",
      "Sat Jan  1 23:14:24 2022\tEpoch: 765, Loss: 0.4834, Val: 3.5328, Test: 3.6802\n",
      "\t\t -- train_counter: 1205, test_counter:65\n",
      "Sat Jan  1 23:14:26 2022\tEpoch: 766, Loss: 0.5025, Val: 3.6129, Test: 3.5676\n",
      "\t\t -- train_counter: 1205, test_counter:73\n",
      "Sat Jan  1 23:14:29 2022\tEpoch: 767, Loss: 0.4782, Val: 3.3806, Test: 3.8237\n",
      "\t\t -- train_counter: 1216, test_counter:65\n",
      "Sat Jan  1 23:14:32 2022\tEpoch: 768, Loss: 0.4671, Val: 3.2996, Test: 3.6191\n",
      "\t\t -- train_counter: 1201, test_counter:70\n",
      "Sat Jan  1 23:14:34 2022\tEpoch: 769, Loss: 0.4535, Val: 3.3211, Test: 3.2941\n",
      "\t\t -- train_counter: 1207, test_counter:86\n",
      "Sat Jan  1 23:14:38 2022\tEpoch: 770, Loss: 0.4883, Val: 3.3850, Test: 3.2848\n",
      "\t\t -- train_counter: 1210, test_counter:86\n",
      "Sat Jan  1 23:14:40 2022\tEpoch: 771, Loss: 0.4412, Val: 3.4843, Test: 3.3768\n",
      "\t\t -- train_counter: 1197, test_counter:65\n",
      "Sat Jan  1 23:14:43 2022\tEpoch: 772, Loss: 0.4548, Val: 3.7658, Test: 3.7570\n",
      "\t\t -- train_counter: 1208, test_counter:76\n",
      "Sat Jan  1 23:14:46 2022\tEpoch: 773, Loss: 0.4353, Val: 3.6702, Test: 3.5367\n",
      "\t\t -- train_counter: 1228, test_counter:77\n",
      "Sat Jan  1 23:14:48 2022\tEpoch: 774, Loss: 0.5282, Val: 3.4488, Test: 3.4104\n",
      "\t\t -- train_counter: 1184, test_counter:76\n",
      "Sat Jan  1 23:14:50 2022\tEpoch: 775, Loss: 0.4528, Val: 3.5773, Test: 3.4602\n",
      "\t\t -- train_counter: 1203, test_counter:80\n",
      "Sat Jan  1 23:14:53 2022\tEpoch: 776, Loss: 0.4842, Val: 3.5068, Test: 3.6124\n",
      "\t\t -- train_counter: 1187, test_counter:78\n",
      "Sat Jan  1 23:14:56 2022\tEpoch: 777, Loss: 0.4346, Val: 4.0997, Test: 4.0380\n",
      "\t\t -- train_counter: 1221, test_counter:66\n",
      "Sat Jan  1 23:14:59 2022\tEpoch: 778, Loss: 0.4561, Val: 3.9971, Test: 3.9341\n",
      "\t\t -- train_counter: 1222, test_counter:67\n",
      "Sat Jan  1 23:15:02 2022\tEpoch: 779, Loss: 0.4147, Val: 3.4899, Test: 3.5342\n",
      "\t\t -- train_counter: 1209, test_counter:71\n",
      "Sat Jan  1 23:15:05 2022\tEpoch: 780, Loss: 0.4641, Val: 3.3304, Test: 3.5417\n",
      "\t\t -- train_counter: 1213, test_counter:87\n",
      "Sat Jan  1 23:15:07 2022\tEpoch: 781, Loss: 0.4429, Val: 3.3214, Test: 3.7085\n",
      "\t\t -- train_counter: 1211, test_counter:77\n",
      "Sat Jan  1 23:15:10 2022\tEpoch: 782, Loss: 0.5014, Val: 3.5661, Test: 3.3267\n",
      "\t\t -- train_counter: 1193, test_counter:75\n",
      "Sat Jan  1 23:15:13 2022\tEpoch: 783, Loss: 0.4513, Val: 3.5187, Test: 3.6539\n",
      "\t\t -- train_counter: 1203, test_counter:75\n",
      "Sat Jan  1 23:15:15 2022\tEpoch: 784, Loss: 0.4099, Val: 3.6667, Test: 3.4804\n",
      "\t\t -- train_counter: 1230, test_counter:88\n",
      "Sat Jan  1 23:15:18 2022\tEpoch: 785, Loss: 0.4014, Val: 3.4293, Test: 3.7189\n",
      "\t\t -- train_counter: 1221, test_counter:73\n",
      "Sat Jan  1 23:15:21 2022\tEpoch: 786, Loss: 0.3989, Val: 3.5023, Test: 3.5188\n",
      "\t\t -- train_counter: 1219, test_counter:79\n",
      "Sat Jan  1 23:15:24 2022\tEpoch: 787, Loss: 0.4286, Val: 3.4810, Test: 3.6283\n",
      "\t\t -- train_counter: 1209, test_counter:83\n",
      "Sat Jan  1 23:15:27 2022\tEpoch: 788, Loss: 0.4188, Val: 4.0355, Test: 3.7176\n",
      "\t\t -- train_counter: 1229, test_counter:80\n",
      "Sat Jan  1 23:15:30 2022\tEpoch: 789, Loss: 0.4673, Val: 3.6083, Test: 3.7077\n",
      "\t\t -- train_counter: 1194, test_counter:79\n",
      "Sat Jan  1 23:15:33 2022\tEpoch: 790, Loss: 0.4493, Val: 3.6584, Test: 3.6189\n",
      "\t\t -- train_counter: 1216, test_counter:78\n",
      "Sat Jan  1 23:15:35 2022\tEpoch: 791, Loss: 0.4223, Val: 3.7657, Test: 3.5153\n",
      "\t\t -- train_counter: 1223, test_counter:85\n",
      "Sat Jan  1 23:15:38 2022\tEpoch: 792, Loss: 0.4154, Val: 3.5410, Test: 3.3484\n",
      "\t\t -- train_counter: 1227, test_counter:85\n",
      "Sat Jan  1 23:15:41 2022\tEpoch: 793, Loss: 0.4223, Val: 3.5445, Test: 3.4856\n",
      "\t\t -- train_counter: 1218, test_counter:70\n",
      "Sat Jan  1 23:15:43 2022\tEpoch: 794, Loss: 0.4851, Val: 3.8956, Test: 3.5931\n",
      "\t\t -- train_counter: 1196, test_counter:88\n",
      "Sat Jan  1 23:15:46 2022\tEpoch: 795, Loss: 0.4266, Val: 3.7906, Test: 3.4648\n",
      "\t\t -- train_counter: 1213, test_counter:79\n",
      "Sat Jan  1 23:15:49 2022\tEpoch: 796, Loss: 0.4611, Val: 3.6295, Test: 3.5390\n",
      "\t\t -- train_counter: 1204, test_counter:68\n",
      "Sat Jan  1 23:15:52 2022\tEpoch: 797, Loss: 0.4161, Val: 3.5334, Test: 3.4219\n",
      "\t\t -- train_counter: 1227, test_counter:69\n",
      "Sat Jan  1 23:15:54 2022\tEpoch: 798, Loss: 0.4442, Val: 3.5941, Test: 3.3644\n",
      "\t\t -- train_counter: 1222, test_counter:78\n",
      "Sat Jan  1 23:15:57 2022\tEpoch: 799, Loss: 0.4632, Val: 3.2690, Test: 3.5774\n",
      "\t\t -- train_counter: 1214, test_counter:66\n",
      "Sat Jan  1 23:16:00 2022\tEpoch: 800, Loss: 0.4379, Val: 3.4355, Test: 3.7575\n",
      "\t\t -- train_counter: 1215, test_counter:72\n",
      "Sat Jan  1 23:16:03 2022\tEpoch: 801, Loss: 0.4670, Val: 3.6641, Test: 3.7298\n",
      "\t\t -- train_counter: 1206, test_counter:68\n",
      "Sat Jan  1 23:16:06 2022\tEpoch: 802, Loss: 0.4711, Val: 3.7171, Test: 3.7222\n",
      "\t\t -- train_counter: 1215, test_counter:74\n",
      "Sat Jan  1 23:16:08 2022\tEpoch: 803, Loss: 0.4426, Val: 3.5801, Test: 3.5308\n",
      "\t\t -- train_counter: 1208, test_counter:69\n",
      "Sat Jan  1 23:16:11 2022\tEpoch: 804, Loss: 0.4617, Val: 3.6869, Test: 3.6524\n",
      "\t\t -- train_counter: 1206, test_counter:70\n",
      "Sat Jan  1 23:16:14 2022\tEpoch: 805, Loss: 0.4259, Val: 3.6160, Test: 3.7518\n",
      "\t\t -- train_counter: 1210, test_counter:79\n",
      "Sat Jan  1 23:16:16 2022\tEpoch: 806, Loss: 0.4568, Val: 3.6549, Test: 3.8622\n",
      "\t\t -- train_counter: 1209, test_counter:70\n",
      "Sat Jan  1 23:16:19 2022\tEpoch: 807, Loss: 0.4476, Val: 3.7580, Test: 4.2036\n",
      "\t\t -- train_counter: 1224, test_counter:94\n",
      "Sat Jan  1 23:16:22 2022\tEpoch: 808, Loss: 0.4408, Val: 3.9604, Test: 4.4681\n",
      "\t\t -- train_counter: 1231, test_counter:64\n",
      "Sat Jan  1 23:16:25 2022\tEpoch: 809, Loss: 0.4192, Val: 3.6702, Test: 4.0189\n",
      "\t\t -- train_counter: 1224, test_counter:66\n",
      "Sat Jan  1 23:16:28 2022\tEpoch: 810, Loss: 0.4959, Val: 3.3552, Test: 3.4596\n",
      "\t\t -- train_counter: 1197, test_counter:63\n",
      "Sat Jan  1 23:16:31 2022\tEpoch: 811, Loss: 0.4741, Val: 3.7523, Test: 3.7321\n",
      "\t\t -- train_counter: 1208, test_counter:60\n",
      "Sat Jan  1 23:16:34 2022\tEpoch: 812, Loss: 0.4722, Val: 3.7815, Test: 3.5609\n",
      "\t\t -- train_counter: 1206, test_counter:73\n",
      "Sat Jan  1 23:16:37 2022\tEpoch: 813, Loss: 0.4398, Val: 3.4055, Test: 3.4307\n",
      "\t\t -- train_counter: 1218, test_counter:78\n",
      "Sat Jan  1 23:16:39 2022\tEpoch: 814, Loss: 0.4289, Val: 3.5053, Test: 3.9806\n",
      "\t\t -- train_counter: 1207, test_counter:67\n",
      "Sat Jan  1 23:16:42 2022\tEpoch: 815, Loss: 0.4513, Val: 3.4302, Test: 3.4507\n",
      "\t\t -- train_counter: 1194, test_counter:81\n",
      "Sat Jan  1 23:16:45 2022\tEpoch: 816, Loss: 0.4135, Val: 3.5708, Test: 3.5867\n",
      "\t\t -- train_counter: 1226, test_counter:69\n",
      "Sat Jan  1 23:16:48 2022\tEpoch: 817, Loss: 0.4453, Val: 3.8955, Test: 3.8727\n",
      "\t\t -- train_counter: 1227, test_counter:75\n",
      "Sat Jan  1 23:16:51 2022\tEpoch: 818, Loss: 0.4885, Val: 4.0325, Test: 4.5614\n",
      "\t\t -- train_counter: 1199, test_counter:39\n",
      "Sat Jan  1 23:16:54 2022\tEpoch: 819, Loss: 0.4241, Val: 3.7742, Test: 4.0331\n",
      "\t\t -- train_counter: 1218, test_counter:37\n",
      "Sat Jan  1 23:16:56 2022\tEpoch: 820, Loss: 0.4050, Val: 4.6739, Test: 5.4611\n",
      "\t\t -- train_counter: 1237, test_counter:46\n",
      "Sat Jan  1 23:16:59 2022\tEpoch: 821, Loss: 0.5038, Val: 5.6093, Test: 5.7892\n",
      "\t\t -- train_counter: 1196, test_counter:52\n",
      "Sat Jan  1 23:17:02 2022\tEpoch: 822, Loss: 0.4051, Val: 4.1041, Test: 4.1266\n",
      "\t\t -- train_counter: 1229, test_counter:75\n",
      "Sat Jan  1 23:17:05 2022\tEpoch: 823, Loss: 0.4540, Val: 3.4482, Test: 3.7996\n",
      "\t\t -- train_counter: 1224, test_counter:82\n",
      "Sat Jan  1 23:17:07 2022\tEpoch: 824, Loss: 0.4572, Val: 3.6889, Test: 3.5066\n",
      "\t\t -- train_counter: 1201, test_counter:72\n",
      "Sat Jan  1 23:17:10 2022\tEpoch: 825, Loss: 0.5001, Val: 3.7201, Test: 3.6679\n",
      "\t\t -- train_counter: 1195, test_counter:74\n",
      "Sat Jan  1 23:17:13 2022\tEpoch: 826, Loss: 0.4881, Val: 3.5221, Test: 3.5562\n",
      "\t\t -- train_counter: 1205, test_counter:70\n",
      "Sat Jan  1 23:17:15 2022\tEpoch: 827, Loss: 0.4294, Val: 3.6455, Test: 3.6217\n",
      "\t\t -- train_counter: 1207, test_counter:75\n",
      "Sat Jan  1 23:17:19 2022\tEpoch: 828, Loss: 0.5293, Val: 3.3225, Test: 3.5388\n",
      "\t\t -- train_counter: 1194, test_counter:72\n",
      "Sat Jan  1 23:17:22 2022\tEpoch: 829, Loss: 0.4649, Val: 3.5651, Test: 3.5844\n",
      "\t\t -- train_counter: 1207, test_counter:76\n",
      "Sat Jan  1 23:17:24 2022\tEpoch: 830, Loss: 0.4247, Val: 3.3807, Test: 3.4298\n",
      "\t\t -- train_counter: 1218, test_counter:72\n",
      "Sat Jan  1 23:17:27 2022\tEpoch: 831, Loss: 0.4539, Val: 3.5579, Test: 3.5890\n",
      "\t\t -- train_counter: 1206, test_counter:69\n",
      "Sat Jan  1 23:17:30 2022\tEpoch: 832, Loss: 0.4462, Val: 3.4649, Test: 3.4682\n",
      "\t\t -- train_counter: 1217, test_counter:76\n",
      "Sat Jan  1 23:17:33 2022\tEpoch: 833, Loss: 0.3192, Val: 3.6511, Test: 3.5496\n",
      "\t\t -- train_counter: 1257, test_counter:76\n",
      "Sat Jan  1 23:17:36 2022\tEpoch: 834, Loss: 0.4328, Val: 3.7266, Test: 3.6611\n",
      "\t\t -- train_counter: 1224, test_counter:60\n",
      "Sat Jan  1 23:17:39 2022\tEpoch: 835, Loss: 0.4170, Val: 3.6867, Test: 3.6441\n",
      "\t\t -- train_counter: 1220, test_counter:70\n",
      "Sat Jan  1 23:17:41 2022\tEpoch: 836, Loss: 0.4615, Val: 3.7197, Test: 3.5025\n",
      "\t\t -- train_counter: 1199, test_counter:62\n",
      "Sat Jan  1 23:17:45 2022\tEpoch: 837, Loss: 0.4403, Val: 3.7019, Test: 3.6092\n",
      "\t\t -- train_counter: 1215, test_counter:64\n",
      "Sat Jan  1 23:17:47 2022\tEpoch: 838, Loss: 0.4556, Val: 3.7040, Test: 3.4830\n",
      "\t\t -- train_counter: 1215, test_counter:61\n",
      "Sat Jan  1 23:17:50 2022\tEpoch: 839, Loss: 0.4821, Val: 3.6482, Test: 3.8157\n",
      "\t\t -- train_counter: 1212, test_counter:70\n",
      "Sat Jan  1 23:17:53 2022\tEpoch: 840, Loss: 0.4165, Val: 3.8288, Test: 3.7674\n",
      "\t\t -- train_counter: 1226, test_counter:71\n",
      "Sat Jan  1 23:17:56 2022\tEpoch: 841, Loss: 0.4169, Val: 3.9563, Test: 4.2534\n",
      "\t\t -- train_counter: 1239, test_counter:62\n",
      "Sat Jan  1 23:17:59 2022\tEpoch: 842, Loss: 0.4359, Val: 3.6407, Test: 3.9351\n",
      "\t\t -- train_counter: 1209, test_counter:78\n",
      "Sat Jan  1 23:18:01 2022\tEpoch: 843, Loss: 0.4371, Val: 3.5343, Test: 3.6857\n",
      "\t\t -- train_counter: 1218, test_counter:76\n",
      "Sat Jan  1 23:18:04 2022\tEpoch: 844, Loss: 0.4225, Val: 3.4307, Test: 3.8085\n",
      "\t\t -- train_counter: 1236, test_counter:72\n",
      "Sat Jan  1 23:18:07 2022\tEpoch: 845, Loss: 0.4325, Val: 3.4410, Test: 3.7711\n",
      "\t\t -- train_counter: 1230, test_counter:78\n",
      "Sat Jan  1 23:18:10 2022\tEpoch: 846, Loss: 0.4045, Val: 3.4637, Test: 3.6268\n",
      "\t\t -- train_counter: 1236, test_counter:65\n",
      "Sat Jan  1 23:18:13 2022\tEpoch: 847, Loss: 0.4235, Val: 7.6969, Test: 8.7067\n",
      "\t\t -- train_counter: 1222, test_counter:35\n",
      "Sat Jan  1 23:18:16 2022\tEpoch: 848, Loss: 0.4206, Val: 5.6354, Test: 5.8843\n",
      "\t\t -- train_counter: 1213, test_counter:45\n",
      "Sat Jan  1 23:18:19 2022\tEpoch: 849, Loss: 0.4887, Val: 4.4328, Test: 4.7548\n",
      "\t\t -- train_counter: 1186, test_counter:65\n",
      "Sat Jan  1 23:18:21 2022\tEpoch: 850, Loss: 0.4505, Val: 3.9176, Test: 4.0017\n",
      "\t\t -- train_counter: 1215, test_counter:74\n",
      "Sat Jan  1 23:18:24 2022\tEpoch: 851, Loss: 0.4794, Val: 3.6795, Test: 3.6989\n",
      "\t\t -- train_counter: 1204, test_counter:74\n",
      "Sat Jan  1 23:18:27 2022\tEpoch: 852, Loss: 0.4280, Val: 3.6558, Test: 3.5778\n",
      "\t\t -- train_counter: 1215, test_counter:74\n",
      "Sat Jan  1 23:18:30 2022\tEpoch: 853, Loss: 0.4738, Val: 3.6715, Test: 3.5248\n",
      "\t\t -- train_counter: 1201, test_counter:69\n",
      "Sat Jan  1 23:18:33 2022\tEpoch: 854, Loss: 0.4554, Val: 3.4622, Test: 3.5769\n",
      "\t\t -- train_counter: 1204, test_counter:68\n",
      "Sat Jan  1 23:18:35 2022\tEpoch: 855, Loss: 0.4282, Val: 3.6777, Test: 3.5664\n",
      "\t\t -- train_counter: 1210, test_counter:73\n",
      "Sat Jan  1 23:18:39 2022\tEpoch: 856, Loss: 0.4725, Val: 3.5079, Test: 3.6569\n",
      "\t\t -- train_counter: 1203, test_counter:77\n",
      "Sat Jan  1 23:18:41 2022\tEpoch: 857, Loss: 0.4445, Val: 3.6582, Test: 3.7963\n",
      "\t\t -- train_counter: 1231, test_counter:80\n",
      "Sat Jan  1 23:18:45 2022\tEpoch: 858, Loss: 0.4435, Val: 3.5314, Test: 3.6186\n",
      "\t\t -- train_counter: 1231, test_counter:69\n",
      "Sat Jan  1 23:18:47 2022\tEpoch: 859, Loss: 0.4281, Val: 3.4281, Test: 3.6500\n",
      "\t\t -- train_counter: 1220, test_counter:63\n",
      "Sat Jan  1 23:18:50 2022\tEpoch: 860, Loss: 0.4202, Val: 3.5766, Test: 3.6287\n",
      "\t\t -- train_counter: 1226, test_counter:73\n",
      "Sat Jan  1 23:18:53 2022\tEpoch: 861, Loss: 0.4784, Val: 3.7949, Test: 3.5580\n",
      "\t\t -- train_counter: 1209, test_counter:67\n",
      "Sat Jan  1 23:18:56 2022\tEpoch: 862, Loss: 0.3984, Val: 3.8151, Test: 3.5791\n",
      "\t\t -- train_counter: 1242, test_counter:82\n",
      "Sat Jan  1 23:18:59 2022\tEpoch: 863, Loss: 0.4488, Val: 3.5970, Test: 3.6382\n",
      "\t\t -- train_counter: 1210, test_counter:72\n",
      "Sat Jan  1 23:19:01 2022\tEpoch: 864, Loss: 0.3912, Val: 3.3848, Test: 3.7917\n",
      "\t\t -- train_counter: 1235, test_counter:61\n",
      "Sat Jan  1 23:19:05 2022\tEpoch: 865, Loss: 0.3801, Val: 3.4574, Test: 3.5165\n",
      "\t\t -- train_counter: 1245, test_counter:75\n",
      "Sat Jan  1 23:19:08 2022\tEpoch: 866, Loss: 0.3723, Val: 3.8680, Test: 3.6298\n",
      "\t\t -- train_counter: 1234, test_counter:70\n",
      "Sat Jan  1 23:19:10 2022\tEpoch: 867, Loss: 0.3557, Val: 3.5920, Test: 3.6596\n",
      "\t\t -- train_counter: 1243, test_counter:66\n",
      "Sat Jan  1 23:19:13 2022\tEpoch: 868, Loss: 0.4011, Val: 3.9404, Test: 4.1740\n",
      "\t\t -- train_counter: 1235, test_counter:78\n",
      "Sat Jan  1 23:19:16 2022\tEpoch: 869, Loss: 0.4051, Val: 3.9131, Test: 3.6693\n",
      "\t\t -- train_counter: 1211, test_counter:69\n",
      "Sat Jan  1 23:19:19 2022\tEpoch: 870, Loss: 0.3974, Val: 3.7694, Test: 4.0633\n",
      "\t\t -- train_counter: 1234, test_counter:66\n",
      "Sat Jan  1 23:19:21 2022\tEpoch: 871, Loss: 0.4306, Val: 4.4532, Test: 4.5503\n",
      "\t\t -- train_counter: 1212, test_counter:59\n",
      "Sat Jan  1 23:19:24 2022\tEpoch: 872, Loss: 0.4481, Val: 3.8695, Test: 4.1462\n",
      "\t\t -- train_counter: 1228, test_counter:66\n",
      "Sat Jan  1 23:19:27 2022\tEpoch: 873, Loss: 0.4522, Val: 3.8728, Test: 3.6614\n",
      "\t\t -- train_counter: 1208, test_counter:66\n",
      "Sat Jan  1 23:19:30 2022\tEpoch: 874, Loss: 0.3932, Val: 3.6781, Test: 3.4506\n",
      "\t\t -- train_counter: 1233, test_counter:72\n",
      "Sat Jan  1 23:19:33 2022\tEpoch: 875, Loss: 0.4556, Val: 3.5029, Test: 3.5371\n",
      "\t\t -- train_counter: 1202, test_counter:81\n",
      "Sat Jan  1 23:19:36 2022\tEpoch: 876, Loss: 0.4667, Val: 3.5212, Test: 3.3958\n",
      "\t\t -- train_counter: 1208, test_counter:73\n",
      "Sat Jan  1 23:19:39 2022\tEpoch: 877, Loss: 0.4295, Val: 3.5373, Test: 3.4304\n",
      "\t\t -- train_counter: 1223, test_counter:82\n",
      "Sat Jan  1 23:19:41 2022\tEpoch: 878, Loss: 0.4317, Val: 3.4938, Test: 3.6592\n",
      "\t\t -- train_counter: 1230, test_counter:62\n",
      "Sat Jan  1 23:19:44 2022\tEpoch: 879, Loss: 0.4299, Val: 3.9856, Test: 4.0292\n",
      "\t\t -- train_counter: 1204, test_counter:64\n",
      "Sat Jan  1 23:19:47 2022\tEpoch: 880, Loss: 0.4150, Val: 3.6240, Test: 4.0934\n",
      "\t\t -- train_counter: 1226, test_counter:65\n",
      "Sat Jan  1 23:19:50 2022\tEpoch: 881, Loss: 0.3971, Val: 3.7278, Test: 3.7318\n",
      "\t\t -- train_counter: 1241, test_counter:64\n",
      "Sat Jan  1 23:19:53 2022\tEpoch: 882, Loss: 0.3947, Val: 4.1156, Test: 3.5507\n",
      "\t\t -- train_counter: 1230, test_counter:70\n",
      "Sat Jan  1 23:19:55 2022\tEpoch: 883, Loss: 0.3706, Val: 4.2331, Test: 3.8709\n",
      "\t\t -- train_counter: 1229, test_counter:74\n",
      "Sat Jan  1 23:19:58 2022\tEpoch: 884, Loss: 0.4101, Val: 3.9343, Test: 4.0728\n",
      "\t\t -- train_counter: 1225, test_counter:75\n",
      "Sat Jan  1 23:20:01 2022\tEpoch: 885, Loss: 0.4317, Val: 3.7123, Test: 3.6255\n",
      "\t\t -- train_counter: 1229, test_counter:75\n",
      "Sat Jan  1 23:20:04 2022\tEpoch: 886, Loss: 0.5075, Val: 3.6415, Test: 3.5345\n",
      "\t\t -- train_counter: 1198, test_counter:77\n",
      "Sat Jan  1 23:20:07 2022\tEpoch: 887, Loss: 0.4269, Val: 3.5477, Test: 3.7953\n",
      "\t\t -- train_counter: 1217, test_counter:79\n",
      "Sat Jan  1 23:20:10 2022\tEpoch: 888, Loss: 0.4602, Val: 3.8162, Test: 3.7350\n",
      "\t\t -- train_counter: 1216, test_counter:74\n",
      "Sat Jan  1 23:20:12 2022\tEpoch: 889, Loss: 0.4715, Val: 3.6648, Test: 3.8340\n",
      "\t\t -- train_counter: 1215, test_counter:72\n",
      "Sat Jan  1 23:20:15 2022\tEpoch: 890, Loss: 0.4403, Val: 3.4272, Test: 3.6208\n",
      "\t\t -- train_counter: 1218, test_counter:64\n",
      "Sat Jan  1 23:20:18 2022\tEpoch: 891, Loss: 0.4112, Val: 3.7802, Test: 3.6682\n",
      "\t\t -- train_counter: 1228, test_counter:64\n",
      "Sat Jan  1 23:20:21 2022\tEpoch: 892, Loss: 0.4194, Val: 3.7176, Test: 3.6797\n",
      "\t\t -- train_counter: 1223, test_counter:67\n",
      "Sat Jan  1 23:20:24 2022\tEpoch: 893, Loss: 0.4030, Val: 3.4943, Test: 3.7043\n",
      "\t\t -- train_counter: 1234, test_counter:82\n",
      "Sat Jan  1 23:20:27 2022\tEpoch: 894, Loss: 0.4335, Val: 3.6924, Test: 3.5544\n",
      "\t\t -- train_counter: 1237, test_counter:73\n",
      "Sat Jan  1 23:20:29 2022\tEpoch: 895, Loss: 0.4886, Val: 3.5099, Test: 3.4574\n",
      "\t\t -- train_counter: 1205, test_counter:70\n",
      "Sat Jan  1 23:20:32 2022\tEpoch: 896, Loss: 0.4283, Val: 3.3991, Test: 3.4281\n",
      "\t\t -- train_counter: 1225, test_counter:70\n",
      "Sat Jan  1 23:20:35 2022\tEpoch: 897, Loss: 0.4410, Val: 3.4135, Test: 3.3156\n",
      "\t\t -- train_counter: 1228, test_counter:74\n",
      "Sat Jan  1 23:20:38 2022\tEpoch: 898, Loss: 0.4276, Val: 3.5011, Test: 3.7413\n",
      "\t\t -- train_counter: 1223, test_counter:63\n",
      "Sat Jan  1 23:20:41 2022\tEpoch: 899, Loss: 0.4541, Val: 3.6568, Test: 3.4157\n",
      "\t\t -- train_counter: 1209, test_counter:73\n",
      "Sat Jan  1 23:20:43 2022\tEpoch: 900, Loss: 0.4438, Val: 3.5971, Test: 3.4463\n",
      "\t\t -- train_counter: 1202, test_counter:80\n",
      "Sat Jan  1 23:20:46 2022\tEpoch: 901, Loss: 0.4184, Val: 3.6758, Test: 3.8326\n",
      "\t\t -- train_counter: 1233, test_counter:66\n",
      "Sat Jan  1 23:20:49 2022\tEpoch: 902, Loss: 0.4767, Val: 3.6955, Test: 3.6841\n",
      "\t\t -- train_counter: 1197, test_counter:73\n",
      "Sat Jan  1 23:20:52 2022\tEpoch: 903, Loss: 0.3959, Val: 3.7444, Test: 3.6200\n",
      "\t\t -- train_counter: 1231, test_counter:70\n",
      "Sat Jan  1 23:20:55 2022\tEpoch: 904, Loss: 0.3760, Val: 3.6315, Test: 3.5244\n",
      "\t\t -- train_counter: 1239, test_counter:86\n",
      "Sat Jan  1 23:20:57 2022\tEpoch: 905, Loss: 0.4656, Val: 3.6996, Test: 3.9918\n",
      "\t\t -- train_counter: 1211, test_counter:58\n",
      "Sat Jan  1 23:21:00 2022\tEpoch: 906, Loss: 0.3949, Val: 3.3212, Test: 3.7746\n",
      "\t\t -- train_counter: 1230, test_counter:67\n",
      "Sat Jan  1 23:21:03 2022\tEpoch: 907, Loss: 0.4706, Val: 3.8028, Test: 3.9621\n",
      "\t\t -- train_counter: 1206, test_counter:69\n",
      "Sat Jan  1 23:21:05 2022\tEpoch: 908, Loss: 0.4136, Val: 3.6604, Test: 3.6256\n",
      "\t\t -- train_counter: 1218, test_counter:77\n",
      "Sat Jan  1 23:21:08 2022\tEpoch: 909, Loss: 0.4626, Val: 3.3389, Test: 3.6923\n",
      "\t\t -- train_counter: 1216, test_counter:74\n",
      "Sat Jan  1 23:21:11 2022\tEpoch: 910, Loss: 0.4493, Val: 3.3749, Test: 3.6686\n",
      "\t\t -- train_counter: 1222, test_counter:72\n",
      "Sat Jan  1 23:21:14 2022\tEpoch: 911, Loss: 0.4147, Val: 3.8780, Test: 4.4796\n",
      "\t\t -- train_counter: 1215, test_counter:37\n",
      "Sat Jan  1 23:21:17 2022\tEpoch: 912, Loss: 0.3910, Val: 4.0314, Test: 4.1431\n",
      "\t\t -- train_counter: 1229, test_counter:48\n",
      "Sat Jan  1 23:21:20 2022\tEpoch: 913, Loss: 0.3874, Val: 3.4512, Test: 3.5689\n",
      "\t\t -- train_counter: 1237, test_counter:79\n",
      "Sat Jan  1 23:21:23 2022\tEpoch: 914, Loss: 0.4288, Val: 4.3779, Test: 4.4978\n",
      "\t\t -- train_counter: 1234, test_counter:65\n",
      "Sat Jan  1 23:21:25 2022\tEpoch: 915, Loss: 0.4163, Val: 3.5922, Test: 3.7676\n",
      "\t\t -- train_counter: 1222, test_counter:68\n",
      "Sat Jan  1 23:21:28 2022\tEpoch: 916, Loss: 0.4491, Val: 3.4695, Test: 3.7140\n",
      "\t\t -- train_counter: 1220, test_counter:66\n",
      "Sat Jan  1 23:21:31 2022\tEpoch: 917, Loss: 0.4413, Val: 3.3370, Test: 3.7063\n",
      "\t\t -- train_counter: 1224, test_counter:69\n",
      "Sat Jan  1 23:21:34 2022\tEpoch: 918, Loss: 0.4240, Val: 4.1024, Test: 3.6444\n",
      "\t\t -- train_counter: 1217, test_counter:69\n",
      "Sat Jan  1 23:21:36 2022\tEpoch: 919, Loss: 0.4178, Val: 3.9035, Test: 3.6892\n",
      "\t\t -- train_counter: 1239, test_counter:81\n",
      "Sat Jan  1 23:21:39 2022\tEpoch: 920, Loss: 0.3999, Val: 3.7547, Test: 3.5497\n",
      "\t\t -- train_counter: 1240, test_counter:62\n",
      "Sat Jan  1 23:21:42 2022\tEpoch: 921, Loss: 0.4022, Val: 3.3560, Test: 3.6702\n",
      "\t\t -- train_counter: 1232, test_counter:59\n",
      "Sat Jan  1 23:21:46 2022\tEpoch: 922, Loss: 0.4645, Val: 3.6042, Test: 3.6203\n",
      "\t\t -- train_counter: 1221, test_counter:77\n",
      "Sat Jan  1 23:21:48 2022\tEpoch: 923, Loss: 0.4156, Val: 3.7080, Test: 3.5075\n",
      "\t\t -- train_counter: 1237, test_counter:77\n",
      "Sat Jan  1 23:21:51 2022\tEpoch: 924, Loss: 0.4025, Val: 3.9385, Test: 4.1026\n",
      "\t\t -- train_counter: 1234, test_counter:59\n",
      "Sat Jan  1 23:21:54 2022\tEpoch: 925, Loss: 0.4474, Val: 3.1815, Test: 3.4861\n",
      "\t\t -- train_counter: 1215, test_counter:81\n",
      "Sat Jan  1 23:21:57 2022\tEpoch: 926, Loss: 0.4073, Val: 3.2021, Test: 3.3063\n",
      "\t\t -- train_counter: 1226, test_counter:73\n",
      "Sat Jan  1 23:21:59 2022\tEpoch: 927, Loss: 0.4132, Val: 3.4379, Test: 3.2949\n",
      "\t\t -- train_counter: 1230, test_counter:79\n",
      "Sat Jan  1 23:22:02 2022\tEpoch: 928, Loss: 0.4204, Val: 4.0796, Test: 4.2207\n",
      "\t\t -- train_counter: 1216, test_counter:72\n",
      "Sat Jan  1 23:22:05 2022\tEpoch: 929, Loss: 0.4546, Val: 5.7759, Test: 5.5606\n",
      "\t\t -- train_counter: 1225, test_counter:49\n",
      "Sat Jan  1 23:22:08 2022\tEpoch: 930, Loss: 0.4086, Val: 6.4077, Test: 6.5381\n",
      "\t\t -- train_counter: 1219, test_counter:42\n",
      "Sat Jan  1 23:22:11 2022\tEpoch: 931, Loss: 0.4205, Val: 4.2932, Test: 4.0810\n",
      "\t\t -- train_counter: 1227, test_counter:66\n",
      "Sat Jan  1 23:22:14 2022\tEpoch: 932, Loss: 0.4092, Val: 3.8193, Test: 3.9237\n",
      "\t\t -- train_counter: 1222, test_counter:65\n",
      "Sat Jan  1 23:22:17 2022\tEpoch: 933, Loss: 0.4278, Val: 3.6227, Test: 3.7159\n",
      "\t\t -- train_counter: 1210, test_counter:67\n",
      "Sat Jan  1 23:22:20 2022\tEpoch: 934, Loss: 0.4183, Val: 4.0076, Test: 4.0539\n",
      "\t\t -- train_counter: 1205, test_counter:61\n",
      "Sat Jan  1 23:22:22 2022\tEpoch: 935, Loss: 0.4286, Val: 3.7696, Test: 3.7546\n",
      "\t\t -- train_counter: 1224, test_counter:67\n",
      "Sat Jan  1 23:22:25 2022\tEpoch: 936, Loss: 0.4339, Val: 3.9367, Test: 3.7324\n",
      "\t\t -- train_counter: 1216, test_counter:68\n",
      "Sat Jan  1 23:22:28 2022\tEpoch: 937, Loss: 0.4270, Val: 3.5526, Test: 3.3648\n",
      "\t\t -- train_counter: 1218, test_counter:74\n",
      "Sat Jan  1 23:22:31 2022\tEpoch: 938, Loss: 0.4823, Val: 3.3739, Test: 3.6564\n",
      "\t\t -- train_counter: 1219, test_counter:68\n",
      "Sat Jan  1 23:22:33 2022\tEpoch: 939, Loss: 0.4064, Val: 3.1288, Test: 3.4652\n",
      "\t\t -- train_counter: 1219, test_counter:67\n",
      "Sat Jan  1 23:22:37 2022\tEpoch: 940, Loss: 0.4429, Val: 3.2801, Test: 3.4504\n",
      "\t\t -- train_counter: 1229, test_counter:62\n",
      "Sat Jan  1 23:22:40 2022\tEpoch: 941, Loss: 0.4110, Val: 3.5121, Test: 3.5380\n",
      "\t\t -- train_counter: 1221, test_counter:76\n",
      "Sat Jan  1 23:22:43 2022\tEpoch: 942, Loss: 0.4441, Val: 3.5392, Test: 3.4476\n",
      "\t\t -- train_counter: 1214, test_counter:74\n",
      "Sat Jan  1 23:22:46 2022\tEpoch: 943, Loss: 0.4417, Val: 3.2708, Test: 3.4355\n",
      "\t\t -- train_counter: 1220, test_counter:72\n",
      "Sat Jan  1 23:22:49 2022\tEpoch: 944, Loss: 0.3969, Val: 3.5680, Test: 3.4560\n",
      "\t\t -- train_counter: 1235, test_counter:67\n",
      "Sat Jan  1 23:22:51 2022\tEpoch: 945, Loss: 0.4411, Val: 3.2342, Test: 3.5296\n",
      "\t\t -- train_counter: 1211, test_counter:76\n",
      "Sat Jan  1 23:22:54 2022\tEpoch: 946, Loss: 0.3933, Val: 3.6006, Test: 3.7654\n",
      "\t\t -- train_counter: 1227, test_counter:79\n",
      "Sat Jan  1 23:22:57 2022\tEpoch: 947, Loss: 0.3946, Val: 4.0967, Test: 3.8574\n",
      "\t\t -- train_counter: 1241, test_counter:71\n",
      "Sat Jan  1 23:22:59 2022\tEpoch: 948, Loss: 0.4292, Val: 3.6480, Test: 3.6104\n",
      "\t\t -- train_counter: 1235, test_counter:74\n",
      "Sat Jan  1 23:23:02 2022\tEpoch: 949, Loss: 0.4560, Val: 3.3951, Test: 3.7766\n",
      "\t\t -- train_counter: 1224, test_counter:77\n",
      "Sat Jan  1 23:23:05 2022\tEpoch: 950, Loss: 0.4162, Val: 3.5868, Test: 3.6086\n",
      "\t\t -- train_counter: 1226, test_counter:52\n",
      "Sat Jan  1 23:23:08 2022\tEpoch: 951, Loss: 0.4039, Val: 3.7094, Test: 3.8552\n",
      "\t\t -- train_counter: 1229, test_counter:70\n",
      "Sat Jan  1 23:23:11 2022\tEpoch: 952, Loss: 0.4466, Val: 3.5165, Test: 3.7271\n",
      "\t\t -- train_counter: 1212, test_counter:66\n",
      "Sat Jan  1 23:23:13 2022\tEpoch: 953, Loss: 0.4491, Val: 3.5546, Test: 3.8207\n",
      "\t\t -- train_counter: 1215, test_counter:67\n",
      "Sat Jan  1 23:23:16 2022\tEpoch: 954, Loss: 0.4730, Val: 3.4990, Test: 3.5466\n",
      "\t\t -- train_counter: 1211, test_counter:66\n",
      "Sat Jan  1 23:23:19 2022\tEpoch: 955, Loss: 0.4419, Val: 3.9392, Test: 3.8646\n",
      "\t\t -- train_counter: 1219, test_counter:70\n",
      "Sat Jan  1 23:23:22 2022\tEpoch: 956, Loss: 0.4568, Val: 3.3220, Test: 3.4923\n",
      "\t\t -- train_counter: 1213, test_counter:67\n",
      "Sat Jan  1 23:23:25 2022\tEpoch: 957, Loss: 0.3761, Val: 3.3734, Test: 3.4545\n",
      "\t\t -- train_counter: 1229, test_counter:79\n",
      "Sat Jan  1 23:23:27 2022\tEpoch: 958, Loss: 0.4498, Val: 3.5512, Test: 3.5008\n",
      "\t\t -- train_counter: 1211, test_counter:80\n",
      "Sat Jan  1 23:23:31 2022\tEpoch: 959, Loss: 0.4177, Val: 4.0675, Test: 3.7568\n",
      "\t\t -- train_counter: 1233, test_counter:53\n",
      "Sat Jan  1 23:23:33 2022\tEpoch: 960, Loss: 0.4243, Val: 3.3065, Test: 3.3536\n",
      "\t\t -- train_counter: 1219, test_counter:80\n",
      "Sat Jan  1 23:23:36 2022\tEpoch: 961, Loss: 0.4213, Val: 3.3193, Test: 3.3610\n",
      "\t\t -- train_counter: 1240, test_counter:75\n",
      "Sat Jan  1 23:23:39 2022\tEpoch: 962, Loss: 0.4344, Val: 3.6592, Test: 3.6147\n",
      "\t\t -- train_counter: 1218, test_counter:58\n",
      "Sat Jan  1 23:23:42 2022\tEpoch: 963, Loss: 0.4322, Val: 3.4382, Test: 3.6232\n",
      "\t\t -- train_counter: 1233, test_counter:84\n",
      "Sat Jan  1 23:23:45 2022\tEpoch: 964, Loss: 0.3850, Val: 3.6652, Test: 4.1074\n",
      "\t\t -- train_counter: 1227, test_counter:70\n",
      "Sat Jan  1 23:23:47 2022\tEpoch: 965, Loss: 0.4373, Val: 3.6986, Test: 3.9098\n",
      "\t\t -- train_counter: 1228, test_counter:76\n",
      "Sat Jan  1 23:23:50 2022\tEpoch: 966, Loss: 0.4457, Val: 3.5470, Test: 3.9947\n",
      "\t\t -- train_counter: 1207, test_counter:68\n",
      "Sat Jan  1 23:23:53 2022\tEpoch: 967, Loss: 0.4035, Val: 3.5404, Test: 3.3552\n",
      "\t\t -- train_counter: 1224, test_counter:76\n",
      "Sat Jan  1 23:23:56 2022\tEpoch: 968, Loss: 0.4446, Val: 3.4109, Test: 3.3418\n",
      "\t\t -- train_counter: 1216, test_counter:97\n",
      "Sat Jan  1 23:23:59 2022\tEpoch: 969, Loss: 0.4539, Val: 3.5110, Test: 3.4068\n",
      "\t\t -- train_counter: 1201, test_counter:81\n",
      "Sat Jan  1 23:24:02 2022\tEpoch: 970, Loss: 0.3968, Val: 3.1971, Test: 3.6625\n",
      "\t\t -- train_counter: 1235, test_counter:45\n",
      "Sat Jan  1 23:24:05 2022\tEpoch: 971, Loss: 0.3778, Val: 3.4660, Test: 3.4262\n",
      "\t\t -- train_counter: 1238, test_counter:64\n",
      "Sat Jan  1 23:24:07 2022\tEpoch: 972, Loss: 0.4007, Val: 3.7493, Test: 3.4942\n",
      "\t\t -- train_counter: 1236, test_counter:72\n",
      "Sat Jan  1 23:24:10 2022\tEpoch: 973, Loss: 0.4690, Val: 3.5040, Test: 3.5300\n",
      "\t\t -- train_counter: 1226, test_counter:76\n",
      "Sat Jan  1 23:24:13 2022\tEpoch: 974, Loss: 0.3686, Val: 3.4427, Test: 3.6624\n",
      "\t\t -- train_counter: 1253, test_counter:76\n",
      "Sat Jan  1 23:24:15 2022\tEpoch: 975, Loss: 0.4188, Val: 3.7145, Test: 3.8758\n",
      "\t\t -- train_counter: 1214, test_counter:70\n",
      "Sat Jan  1 23:24:18 2022\tEpoch: 976, Loss: 0.3919, Val: 3.7380, Test: 3.6228\n",
      "\t\t -- train_counter: 1229, test_counter:82\n",
      "Sat Jan  1 23:24:21 2022\tEpoch: 977, Loss: 0.4148, Val: 3.6586, Test: 4.0819\n",
      "\t\t -- train_counter: 1231, test_counter:63\n",
      "Sat Jan  1 23:24:24 2022\tEpoch: 978, Loss: 0.4477, Val: 4.3961, Test: 4.3771\n",
      "\t\t -- train_counter: 1225, test_counter:75\n",
      "Sat Jan  1 23:24:27 2022\tEpoch: 979, Loss: 0.4152, Val: 3.9421, Test: 4.1176\n",
      "\t\t -- train_counter: 1231, test_counter:68\n",
      "Sat Jan  1 23:24:30 2022\tEpoch: 980, Loss: 0.4001, Val: 6.6765, Test: 7.5179\n",
      "\t\t -- train_counter: 1242, test_counter:38\n",
      "Sat Jan  1 23:24:33 2022\tEpoch: 981, Loss: 0.3619, Val: 5.3698, Test: 5.7229\n",
      "\t\t -- train_counter: 1236, test_counter:44\n",
      "Sat Jan  1 23:24:36 2022\tEpoch: 982, Loss: 0.4289, Val: 3.5053, Test: 3.9173\n",
      "\t\t -- train_counter: 1224, test_counter:70\n",
      "Sat Jan  1 23:24:38 2022\tEpoch: 983, Loss: 0.4259, Val: 3.3361, Test: 3.3949\n",
      "\t\t -- train_counter: 1213, test_counter:68\n",
      "Sat Jan  1 23:24:41 2022\tEpoch: 984, Loss: 0.3863, Val: 3.4608, Test: 3.4376\n",
      "\t\t -- train_counter: 1243, test_counter:67\n",
      "Sat Jan  1 23:24:44 2022\tEpoch: 985, Loss: 0.3969, Val: 3.5542, Test: 3.6983\n",
      "\t\t -- train_counter: 1219, test_counter:78\n",
      "Sat Jan  1 23:24:47 2022\tEpoch: 986, Loss: 0.4480, Val: 3.4831, Test: 3.6133\n",
      "\t\t -- train_counter: 1210, test_counter:75\n",
      "Sat Jan  1 23:24:50 2022\tEpoch: 987, Loss: 0.4163, Val: 3.6670, Test: 3.5214\n",
      "\t\t -- train_counter: 1229, test_counter:64\n",
      "Sat Jan  1 23:24:53 2022\tEpoch: 988, Loss: 0.4153, Val: 3.7270, Test: 3.4657\n",
      "\t\t -- train_counter: 1224, test_counter:74\n",
      "Sat Jan  1 23:24:56 2022\tEpoch: 989, Loss: 0.3854, Val: 3.8304, Test: 3.8231\n",
      "\t\t -- train_counter: 1233, test_counter:65\n",
      "Sat Jan  1 23:24:59 2022\tEpoch: 990, Loss: 0.4188, Val: 3.3956, Test: 3.9173\n",
      "\t\t -- train_counter: 1228, test_counter:70\n",
      "Sat Jan  1 23:25:02 2022\tEpoch: 991, Loss: 0.3696, Val: 3.3252, Test: 3.6396\n",
      "\t\t -- train_counter: 1254, test_counter:73\n",
      "Sat Jan  1 23:25:04 2022\tEpoch: 992, Loss: 0.3903, Val: 3.2183, Test: 3.4680\n",
      "\t\t -- train_counter: 1235, test_counter:83\n",
      "Sat Jan  1 23:25:07 2022\tEpoch: 993, Loss: 0.3901, Val: 3.5691, Test: 3.5140\n",
      "\t\t -- train_counter: 1229, test_counter:80\n",
      "Sat Jan  1 23:25:10 2022\tEpoch: 994, Loss: 0.4101, Val: 3.5853, Test: 3.9810\n",
      "\t\t -- train_counter: 1224, test_counter:65\n",
      "Sat Jan  1 23:25:13 2022\tEpoch: 995, Loss: 0.4014, Val: 3.8997, Test: 3.9940\n",
      "\t\t -- train_counter: 1215, test_counter:73\n",
      "Sat Jan  1 23:25:15 2022\tEpoch: 996, Loss: 0.4109, Val: 3.8924, Test: 4.1510\n",
      "\t\t -- train_counter: 1237, test_counter:72\n",
      "Sat Jan  1 23:25:19 2022\tEpoch: 997, Loss: 0.3714, Val: 3.6796, Test: 3.8448\n",
      "\t\t -- train_counter: 1248, test_counter:75\n",
      "Sat Jan  1 23:25:21 2022\tEpoch: 998, Loss: 0.4140, Val: 3.6503, Test: 3.6382\n",
      "\t\t -- train_counter: 1232, test_counter:63\n",
      "Sat Jan  1 23:25:24 2022\tEpoch: 999, Loss: 0.4053, Val: 3.7352, Test: 3.6668\n",
      "\t\t -- train_counter: 1231, test_counter:60\n",
      "Sat Jan  1 23:25:27 2022\tEpoch: 1000, Loss: 0.4082, Val: 3.5171, Test: 3.6029\n",
      "\t\t -- train_counter: 1230, test_counter:69\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for epoch in range(1, 1001):\n",
    "    loss, train_counter = train(train_loader)\n",
    "    test_mae, test_counter = test(test_loader)\n",
    "    val_mae, _ = test(val_loader)\n",
    "    \n",
    "    # scheduler.step(loss)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "    writer.add_scalar('Loss/test', test_mae, epoch)\n",
    "    writer.add_scalar('Loss/val', val_mae, epoch)\n",
    "    writer.add_scalar('Counter/train', train_counter/len(train_loader.dataset), epoch)\n",
    "    writer.add_scalar('Counter/test', test_counter/len(test_loader.dataset), epoch)\n",
    "    \n",
    "    print(f'{time.ctime()}\\t'\n",
    "          f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n",
    "          f'Test: {test_mae:.4f}')\n",
    "    \n",
    "    print(f'\\t\\t -- train_counter: {train_counter}, test_counter:{test_counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb52095-743c-4a75-947d-7e728e87c0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G2Dist_GCNConv(\n",
       "  (node_emb): Embedding(10000, 2)\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(80, 100)\n",
       "    (1): GCNConv(49, 49)\n",
       "    (2): GCNConv(24, 24)\n",
       "    (3): GCNConv(12, 12)\n",
       "  )\n",
       "  (pools): ModuleList(\n",
       "    (0): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (batch_norms): ModuleList(\n",
       "    (0): BatchNorm(49)\n",
       "    (1): BatchNorm(24)\n",
       "    (2): BatchNorm(12)\n",
       "    (3): BatchNorm(11)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  )\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=440, out_features=200, bias=True)\n",
       "    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=25, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b771e75-9824-4e0b-9d67-b98b87acdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tld0 = list(train_loader)[0].to(device)\n",
    "tld1 = list(test_loader)[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb990c5f-3804-447f-9ec4-ff38f99732e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = model(tld0.x, tld0.edge_index, tld0.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f77c526c-1fa0-4498-9f4d-5510a9d5c3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -8.4753,  -7.4071,  -8.9221,  ..., -16.6858,  -4.0825, -10.8624],\n",
       "        [ -5.8732,  -3.6731,  -2.8419,  ...,  -7.1670, -10.9246,  -7.7702],\n",
       "        [ 18.4081,  11.3594,   7.4205,  ..., -19.2981, -24.3923, -22.6856],\n",
       "        ...,\n",
       "        [ -5.9228,  -3.5704,  -3.0236,  ...,  -6.3995,  -7.5215,  -6.1516],\n",
       "        [  3.6426,   6.2284,   3.1293,  ..., -14.0113,  -9.8113, -13.2710],\n",
       "        [ -8.6124,  -6.8912,  -7.3845,  ..., -10.0457,  -5.4492,  -7.9943]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f709262e-4b24-4720-98d5-d3d934d80962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  9,  0,  8, 14, 14, 10,  7,  8, 14,  2,  8,  6, 11, 16, 13,  4,  5,\n",
       "         1,  7, 13, 13, 12, 10,  7,  6, 14, 14, 11,  5,  2,  1,  2,  3, 12,  6,\n",
       "         8, 14,  2,  2,  9, 10, 17,  6,  5, 14, 13,  4,  0, 14,  4,  5, 12, 12,\n",
       "         2,  2, 11, 16,  6,  4, 11,  4, 12, 11, 12,  0,  1, 10,  6, 13,  4, 10,\n",
       "         0, 11, 13, 12, 10,  7,  4, 15, 14,  7, 12,  8, 13,  8,  5,  0, 12, 12,\n",
       "         4, 15, 16,  0,  2,  1, 16, 12, 12, 12,  2, 11, 12,  5, 11, 12,  3,  6,\n",
       "         5, 15, 13, 11, 12, 14,  4, 13, 13,  4,  1, 13,  1,  6, 11, 10,  7,  1,\n",
       "        13,  3, 13, 17,  9, 15, 16, 12,  2, 14,  5,  5,  4, 14, 11,  0,  3,  7,\n",
       "         6,  2,  1,  8,  9,  7,  1, 15,  2,  4, 14,  4,  7, 12,  3,  5, 10,  1,\n",
       "         9, 14,  5, 11,  8, 15, 13,  1,  5, 15, 16,  4, 13, 15, 15,  2,  9, 13,\n",
       "        11,  3,  2, 16,  4, 17,  2,  2,  6,  9,  4,  8, 11,  0,  4,  8,  4, 15,\n",
       "        13, 10, 14, 14,  0, 15, 15, 14, 14,  4, 12,  6, 13,  5,  7, 15,  1, 15,\n",
       "        12, 14,  4, 15,  5, 10,  3, 11,  2,  9,  0,  8, 14,  9,  4, 18,  8, 14,\n",
       "         2,  6, 12, 13,  6, 12, 12,  3, 12,  9, 10, 14,  5,  0, 12,  9,  0, 14,\n",
       "         6,  9,  1, 10], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res0.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609f9b9c-5456-4492-90ed-cbe9c261d5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  9,  0,  8, 14, 14, 10,  7,  8, 14,  2,  8,  6, 11, 14, 13,  4,  5,\n",
       "         1,  7, 13, 13, 12, 10,  7,  6, 14, 14, 11,  5,  2,  1,  2,  3, 12,  6,\n",
       "         8, 14,  2,  2,  9, 10, 17,  6,  5, 14, 14,  4,  0, 14,  4,  5, 12, 12,\n",
       "         2,  2, 11, 16,  6,  4, 11,  4, 12, 11, 12,  0,  1, 10,  6, 13,  4, 10,\n",
       "         0, 11, 13,  5, 10,  7,  4, 15, 14,  7, 12,  8, 13,  8,  5,  0, 12,  8,\n",
       "         1, 15, 16,  0,  2,  1, 10, 10, 12, 12,  2,  6, 12,  5, 11, 12,  3,  6,\n",
       "         5, 15, 13, 14,  9, 14,  4, 13, 13,  4,  1, 13,  1,  6,  9, 10,  7,  1,\n",
       "        10,  2, 13, 17,  9, 15, 10, 12,  2,  9,  5,  5,  4, 14, 11,  0,  3,  7,\n",
       "         6,  2,  1,  8,  9,  7,  1, 15,  2,  4, 14,  4,  7, 12,  1,  5, 10,  1,\n",
       "         9, 15,  5, 11,  8,  8,  6,  1,  5, 12, 11,  4, 13, 15, 15,  2,  9, 13,\n",
       "        11,  3,  2, 14,  4, 17,  2,  2,  6,  9,  4,  8, 11,  0,  4,  8,  4, 15,\n",
       "        13, 10, 11, 14,  1, 15, 13, 14, 14,  4, 12,  6, 13,  5,  7, 15,  1, 15,\n",
       "        12, 14,  4, 15,  5, 10,  1, 11,  2,  9,  0,  8, 14,  9,  0, 18,  8, 18,\n",
       "         3,  6, 12, 14,  6, 12, 12,  3, 12,  9, 10, 14,  5,  0, 12,  9,  0, 14,\n",
       "         6,  9,  1, 10], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tld0.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e86c48-0a60-48b8-ac35-8776deadb25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4018, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(res0, tld0.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a85b7691-9bec-4d6f-ba36-07213d45cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3828, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss()(res0.argmax(axis = 1).to(torch.float), tld0.y.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e5a3380-01eb-4ff9-9485-ca018689bde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3828125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res0.argmax(axis = 1) - tld0.y).abs().sum().item()/len(tld0.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "340f9c83-9877-4df9-a4d4-235e1facaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model(tld1.x, tld1.edge_index, tld1.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "092b0b1f-3a5f-427e-abb4-3ef7723ef7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  0, 12,  7, 14,  8, 14, 12,  1, 11,  6,  2,  0, 16,  8,  3, 14, 11,\n",
       "        16,  0, 15, 12, 15, 13,  2, 12,  8,  3, 15,  9, 15, 16, 12,  6, 13, 13,\n",
       "         4, 12, 15,  0, 13,  3, 11, 13,  5, 12,  9, 14, 12,  6, 10, 17, 13, 14,\n",
       "        10, 12,  7,  2, 12,  4, 13, 15, 15, 14], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f488421d-cdc8-4ea1-9617-b0fbedeab631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0,  8,  4, 13, 11, 17, 14,  1,  4, 13,  3,  0, 12,  5,  4, 10,  8,\n",
       "        12,  0, 15, 13, 12, 13,  2,  7,  9,  8, 18, 10, 13, 17, 14,  3,  8, 12,\n",
       "         2, 17,  8,  0, 16,  6,  7,  5,  4, 14,  9,  8,  5,  4,  8, 12,  9, 11,\n",
       "        12, 11,  9,  3,  9,  7, 10, 14, 15, 11], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tld1.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3df503c-618d-40c8-a040-a3cc36f23817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6951, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(res1, tld1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e359cd-f57b-4c36-9854-e893f651c5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6562, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss()(res1.argmax(axis = 1).to(torch.float), tld1.y.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5ee4bdc-004c-4a80-ab9b-322a83e784f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [d.y.item() for d in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80c6323a-9b77-4f60-b075-c8dbfdf37c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f8702e1-17db-4b05-a5d9-9a02d86bd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [d.y.item() for d in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bbb9e24-7048-404c-9cff-01b3025ce878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "432e542f-d058-4e5c-9ccc-f2ce3828072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([d.y.item() for d in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec70e5-62dc-4e3f-b3fa-aa666e6b3089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep AI",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
