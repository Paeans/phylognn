{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aa328c-fbde-4c86-837d-b109eac25828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, Embedding\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, L1Loss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, PNAConv, BatchNorm, global_add_pool\n",
    "\n",
    "from phylognn_model import G2Dist_GCNConv_Global\n",
    "\n",
    "from gene_graph_dataset import GeneGraphDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1afe07e-f45d-4435-9efd-f7be458f83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p, test_p = 0.7, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8f1633-bee2-464b-93e2-6fea1a471948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating...\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = GeneGraphDataset('dataset', 20, 5, graph_num = 400)\n",
    "data_size = len(dataset)\n",
    "train_size, test_size = (int)(data_size * train_p), (int)(data_size * test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2f694a-7ae1-455e-9582-8b7eb9ed67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95dcce3-4aaf-4d68-b153-a9581899a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:(train_size + test_size)]\n",
    "val_dataset = dataset[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f6283c-d51a-4747-8f1b-f437ca523abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbf1dce-6f12-4fdd-be53-37271e03d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c85b3a-1bdf-49db-8494-d04d29ba39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader), len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c79a8d-bb5d-4875-80ff-6c22ece243e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = G2Dist_GCNConv_Global().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.005)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fba2c20-6dee-4b91-acdb-8ee1fa2319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs_g2d_10/g2dist_20_05_02000-mean-run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e364bfa2-7153-493c-9d74-ba7b1ae117ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = MSELoss()\n",
    "# l1_fn = L1Loss()\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss, counter = 0, 0\n",
    "    size = len(train_loader)\n",
    "    for batch, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #loss = (out.squeeze() - data.y).abs().sum()\n",
    "        pred, y = out.softmax(axis = 1).argmax(axis = 1), data.y\n",
    "        counter += (pred == y).sum().item()\n",
    "        \n",
    "        loss = loss_fn(out, data.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / len(train_loader), counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1b9829-772b-4e9b-a75e-1e9904d80afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_error, counter = 0, 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        pred, y = out.softmax(axis = 1).argmax(axis = 1), data.y\n",
    "        counter += (pred == y).sum().item()\n",
    "        \n",
    "        # total_error += (out.squeeze() - data.y).abs().sum().item()\n",
    "        \n",
    "        total_error += loss_fn(out, data.y).item()\n",
    "        \n",
    "    return total_error / len(loader), counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23bb307-e484-493c-a60e-69911d93d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan  2 22:27:50 2022\tEpoch: 001, Loss: 4.1724, Val: 3.0756, Test: 3.1187\n",
      "Sun Jan  2 22:27:55 2022\tEpoch: 002, Loss: 3.0898, Val: 2.7414, Test: 2.8029\n",
      "Sun Jan  2 22:28:01 2022\tEpoch: 003, Loss: 2.4643, Val: 2.5111, Test: 2.6015\n",
      "Sun Jan  2 22:28:07 2022\tEpoch: 004, Loss: 2.0938, Val: 2.3154, Test: 2.4331\n",
      "Sun Jan  2 22:28:13 2022\tEpoch: 005, Loss: 1.8394, Val: 2.1290, Test: 2.2625\n",
      "Sun Jan  2 22:28:18 2022\tEpoch: 006, Loss: 1.6334, Val: 1.9508, Test: 2.0844\n",
      "Sun Jan  2 22:28:24 2022\tEpoch: 007, Loss: 1.4551, Val: 1.7890, Test: 1.9095\n",
      "Sun Jan  2 22:28:30 2022\tEpoch: 008, Loss: 1.3134, Val: 1.6506, Test: 1.7472\n",
      "Sun Jan  2 22:28:35 2022\tEpoch: 009, Loss: 1.2361, Val: 1.5426, Test: 1.6150\n",
      "Sun Jan  2 22:28:41 2022\tEpoch: 010, Loss: 1.2038, Val: 1.4537, Test: 1.5140\n",
      "Sun Jan  2 22:28:46 2022\tEpoch: 011, Loss: 1.1841, Val: 1.3729, Test: 1.4340\n",
      "Sun Jan  2 22:28:52 2022\tEpoch: 012, Loss: 1.1501, Val: 1.2956, Test: 1.3746\n",
      "Sun Jan  2 22:28:58 2022\tEpoch: 013, Loss: 1.1111, Val: 1.2411, Test: 1.3360\n",
      "Sun Jan  2 22:29:03 2022\tEpoch: 014, Loss: 1.0858, Val: 1.2096, Test: 1.3124\n",
      "Sun Jan  2 22:29:09 2022\tEpoch: 015, Loss: 1.0707, Val: 1.1861, Test: 1.2921\n",
      "Sun Jan  2 22:29:15 2022\tEpoch: 016, Loss: 1.0566, Val: 1.1680, Test: 1.2686\n",
      "Sun Jan  2 22:29:21 2022\tEpoch: 017, Loss: 1.0386, Val: 1.1543, Test: 1.2462\n",
      "Sun Jan  2 22:29:27 2022\tEpoch: 018, Loss: 1.0207, Val: 1.1536, Test: 1.2271\n",
      "Sun Jan  2 22:29:32 2022\tEpoch: 019, Loss: 1.0051, Val: 1.1541, Test: 1.2164\n",
      "Sun Jan  2 22:29:38 2022\tEpoch: 020, Loss: 0.9999, Val: 1.1529, Test: 1.2106\n",
      "Sun Jan  2 22:29:44 2022\tEpoch: 021, Loss: 0.9849, Val: 1.1536, Test: 1.2103\n",
      "Sun Jan  2 22:29:50 2022\tEpoch: 022, Loss: 0.9737, Val: 1.1550, Test: 1.2144\n",
      "Sun Jan  2 22:29:56 2022\tEpoch: 023, Loss: 0.9639, Val: 1.1560, Test: 1.2174\n",
      "Sun Jan  2 22:30:00 2022\tEpoch: 024, Loss: 0.9564, Val: 1.1579, Test: 1.2189\n",
      "Sun Jan  2 22:30:05 2022\tEpoch: 025, Loss: 0.9478, Val: 1.1508, Test: 1.2145\n",
      "Sun Jan  2 22:30:11 2022\tEpoch: 026, Loss: 0.9379, Val: 1.1503, Test: 1.2102\n",
      "Sun Jan  2 22:30:17 2022\tEpoch: 027, Loss: 0.9274, Val: 1.1534, Test: 1.2070\n",
      "Sun Jan  2 22:30:22 2022\tEpoch: 028, Loss: 0.9153, Val: 1.1553, Test: 1.2084\n",
      "Sun Jan  2 22:30:27 2022\tEpoch: 029, Loss: 0.9084, Val: 1.1509, Test: 1.2099\n",
      "Sun Jan  2 22:30:32 2022\tEpoch: 030, Loss: 0.9005, Val: 1.1510, Test: 1.2147\n",
      "Sun Jan  2 22:30:37 2022\tEpoch: 031, Loss: 0.8917, Val: 1.1562, Test: 1.2178\n",
      "Sun Jan  2 22:30:41 2022\tEpoch: 032, Loss: 0.8826, Val: 1.1604, Test: 1.2206\n",
      "Sun Jan  2 22:30:47 2022\tEpoch: 033, Loss: 0.8764, Val: 1.1636, Test: 1.2209\n",
      "Sun Jan  2 22:30:52 2022\tEpoch: 034, Loss: 0.8664, Val: 1.1705, Test: 1.2203\n",
      "Sun Jan  2 22:30:58 2022\tEpoch: 035, Loss: 0.8539, Val: 1.1647, Test: 1.2196\n",
      "Sun Jan  2 22:31:04 2022\tEpoch: 036, Loss: 0.8450, Val: 1.1704, Test: 1.2268\n",
      "Sun Jan  2 22:31:10 2022\tEpoch: 037, Loss: 0.8316, Val: 1.1720, Test: 1.2296\n",
      "Sun Jan  2 22:31:16 2022\tEpoch: 038, Loss: 0.8269, Val: 1.1665, Test: 1.2259\n",
      "Sun Jan  2 22:31:22 2022\tEpoch: 039, Loss: 0.8183, Val: 1.1705, Test: 1.2297\n",
      "Sun Jan  2 22:31:28 2022\tEpoch: 040, Loss: 0.8142, Val: 1.1769, Test: 1.2310\n",
      "Sun Jan  2 22:31:34 2022\tEpoch: 041, Loss: 0.7959, Val: 1.1746, Test: 1.2309\n",
      "Sun Jan  2 22:31:40 2022\tEpoch: 042, Loss: 0.7918, Val: 1.1706, Test: 1.2319\n",
      "Sun Jan  2 22:31:45 2022\tEpoch: 043, Loss: 0.7797, Val: 1.1788, Test: 1.2383\n",
      "Sun Jan  2 22:31:51 2022\tEpoch: 044, Loss: 0.7715, Val: 1.1959, Test: 1.2463\n",
      "Sun Jan  2 22:31:56 2022\tEpoch: 045, Loss: 0.7626, Val: 1.1913, Test: 1.2435\n",
      "Sun Jan  2 22:32:01 2022\tEpoch: 046, Loss: 0.7519, Val: 1.1832, Test: 1.2394\n",
      "Sun Jan  2 22:32:06 2022\tEpoch: 047, Loss: 0.7474, Val: 1.1834, Test: 1.2435\n",
      "Sun Jan  2 22:32:12 2022\tEpoch: 048, Loss: 0.7366, Val: 1.2065, Test: 1.2597\n",
      "Sun Jan  2 22:32:17 2022\tEpoch: 049, Loss: 0.7261, Val: 1.1951, Test: 1.2524\n",
      "Sun Jan  2 22:32:23 2022\tEpoch: 050, Loss: 0.7163, Val: 1.1781, Test: 1.2407\n",
      "Sun Jan  2 22:32:28 2022\tEpoch: 051, Loss: 0.7048, Val: 1.2180, Test: 1.2633\n",
      "Sun Jan  2 22:32:33 2022\tEpoch: 052, Loss: 0.6949, Val: 1.2243, Test: 1.2738\n",
      "Sun Jan  2 22:32:39 2022\tEpoch: 053, Loss: 0.6873, Val: 1.2169, Test: 1.2709\n",
      "Sun Jan  2 22:32:45 2022\tEpoch: 054, Loss: 0.6770, Val: 1.2099, Test: 1.2651\n",
      "Sun Jan  2 22:32:49 2022\tEpoch: 055, Loss: 0.6671, Val: 1.2239, Test: 1.2700\n",
      "Sun Jan  2 22:32:55 2022\tEpoch: 056, Loss: 0.6578, Val: 1.2247, Test: 1.2714\n",
      "Sun Jan  2 22:33:01 2022\tEpoch: 057, Loss: 0.6470, Val: 1.2271, Test: 1.2786\n",
      "Sun Jan  2 22:33:07 2022\tEpoch: 058, Loss: 0.6356, Val: 1.2114, Test: 1.2642\n",
      "Sun Jan  2 22:33:12 2022\tEpoch: 059, Loss: 0.6231, Val: 1.2280, Test: 1.2749\n",
      "Sun Jan  2 22:33:17 2022\tEpoch: 060, Loss: 0.6158, Val: 1.2407, Test: 1.2893\n",
      "Sun Jan  2 22:33:24 2022\tEpoch: 061, Loss: 0.6054, Val: 1.2234, Test: 1.2794\n",
      "Sun Jan  2 22:33:30 2022\tEpoch: 062, Loss: 0.5975, Val: 1.2076, Test: 1.2653\n",
      "Sun Jan  2 22:33:36 2022\tEpoch: 063, Loss: 0.5831, Val: 1.2091, Test: 1.2704\n",
      "Sun Jan  2 22:33:41 2022\tEpoch: 064, Loss: 0.5732, Val: 1.2063, Test: 1.2694\n",
      "Sun Jan  2 22:33:46 2022\tEpoch: 065, Loss: 0.5661, Val: 1.2049, Test: 1.2722\n",
      "Sun Jan  2 22:33:52 2022\tEpoch: 066, Loss: 0.5579, Val: 1.2100, Test: 1.2724\n",
      "Sun Jan  2 22:33:56 2022\tEpoch: 067, Loss: 0.5423, Val: 1.1965, Test: 1.2626\n",
      "Sun Jan  2 22:34:03 2022\tEpoch: 068, Loss: 0.5357, Val: 1.2050, Test: 1.2714\n",
      "Sun Jan  2 22:34:09 2022\tEpoch: 069, Loss: 0.5239, Val: 1.2234, Test: 1.2844\n",
      "Sun Jan  2 22:34:14 2022\tEpoch: 070, Loss: 0.5165, Val: 1.2277, Test: 1.2769\n",
      "Sun Jan  2 22:34:18 2022\tEpoch: 071, Loss: 0.5106, Val: 1.2210, Test: 1.2735\n",
      "Sun Jan  2 22:34:24 2022\tEpoch: 072, Loss: 0.4961, Val: 1.2273, Test: 1.2888\n",
      "Sun Jan  2 22:34:31 2022\tEpoch: 073, Loss: 0.4857, Val: 1.2157, Test: 1.2717\n",
      "Sun Jan  2 22:34:36 2022\tEpoch: 074, Loss: 0.4796, Val: 1.2194, Test: 1.2708\n",
      "Sun Jan  2 22:34:42 2022\tEpoch: 075, Loss: 0.4699, Val: 1.2180, Test: 1.2783\n",
      "Sun Jan  2 22:34:47 2022\tEpoch: 076, Loss: 0.4593, Val: 1.1954, Test: 1.2667\n",
      "Sun Jan  2 22:34:53 2022\tEpoch: 077, Loss: 0.4512, Val: 1.1721, Test: 1.2581\n",
      "Sun Jan  2 22:34:58 2022\tEpoch: 078, Loss: 0.4401, Val: 1.1761, Test: 1.2597\n",
      "Sun Jan  2 22:35:04 2022\tEpoch: 079, Loss: 0.4362, Val: 1.1805, Test: 1.2549\n",
      "Sun Jan  2 22:35:09 2022\tEpoch: 080, Loss: 0.4246, Val: 1.1738, Test: 1.2534\n",
      "Sun Jan  2 22:35:15 2022\tEpoch: 081, Loss: 0.4171, Val: 1.1745, Test: 1.2444\n",
      "Sun Jan  2 22:35:20 2022\tEpoch: 082, Loss: 0.4066, Val: 1.2126, Test: 1.2649\n",
      "Sun Jan  2 22:35:26 2022\tEpoch: 083, Loss: 0.3985, Val: 1.2052, Test: 1.2766\n",
      "Sun Jan  2 22:35:31 2022\tEpoch: 084, Loss: 0.3908, Val: 1.1864, Test: 1.2663\n",
      "Sun Jan  2 22:35:37 2022\tEpoch: 085, Loss: 0.3836, Val: 1.2011, Test: 1.2661\n",
      "Sun Jan  2 22:35:42 2022\tEpoch: 086, Loss: 0.3734, Val: 1.2078, Test: 1.2674\n",
      "Sun Jan  2 22:35:47 2022\tEpoch: 087, Loss: 0.3648, Val: 1.2258, Test: 1.2811\n",
      "Sun Jan  2 22:35:52 2022\tEpoch: 088, Loss: 0.3578, Val: 1.2313, Test: 1.2741\n",
      "Sun Jan  2 22:35:57 2022\tEpoch: 089, Loss: 0.3532, Val: 1.2213, Test: 1.2631\n",
      "Sun Jan  2 22:36:02 2022\tEpoch: 090, Loss: 0.3443, Val: 1.2166, Test: 1.2717\n",
      "Sun Jan  2 22:36:07 2022\tEpoch: 091, Loss: 0.3341, Val: 1.2174, Test: 1.2697\n",
      "Sun Jan  2 22:36:13 2022\tEpoch: 092, Loss: 0.3325, Val: 1.1870, Test: 1.2486\n",
      "Sun Jan  2 22:36:18 2022\tEpoch: 093, Loss: 0.3237, Val: 1.2056, Test: 1.2642\n",
      "Sun Jan  2 22:36:24 2022\tEpoch: 094, Loss: 0.3212, Val: 1.2473, Test: 1.3024\n",
      "Sun Jan  2 22:36:30 2022\tEpoch: 095, Loss: 0.3071, Val: 1.2245, Test: 1.2826\n",
      "Sun Jan  2 22:36:35 2022\tEpoch: 096, Loss: 0.3008, Val: 1.2475, Test: 1.2963\n",
      "Sun Jan  2 22:36:41 2022\tEpoch: 097, Loss: 0.2989, Val: 1.2717, Test: 1.3055\n",
      "Sun Jan  2 22:36:46 2022\tEpoch: 098, Loss: 0.2901, Val: 1.2623, Test: 1.2912\n",
      "Sun Jan  2 22:36:52 2022\tEpoch: 099, Loss: 0.2819, Val: 1.3291, Test: 1.3456\n",
      "Sun Jan  2 22:36:58 2022\tEpoch: 100, Loss: 0.2757, Val: 1.2682, Test: 1.3126\n",
      "Sun Jan  2 22:37:02 2022\tEpoch: 101, Loss: 0.2717, Val: 1.2782, Test: 1.3086\n",
      "Sun Jan  2 22:37:07 2022\tEpoch: 102, Loss: 0.2651, Val: 1.3348, Test: 1.3513\n",
      "Sun Jan  2 22:37:12 2022\tEpoch: 103, Loss: 0.2604, Val: 1.2875, Test: 1.3261\n",
      "Sun Jan  2 22:37:19 2022\tEpoch: 104, Loss: 0.2537, Val: 1.2956, Test: 1.3259\n",
      "Sun Jan  2 22:37:24 2022\tEpoch: 105, Loss: 0.2483, Val: 1.3757, Test: 1.3679\n",
      "Sun Jan  2 22:37:30 2022\tEpoch: 106, Loss: 0.2429, Val: 1.3841, Test: 1.3714\n",
      "Sun Jan  2 22:37:36 2022\tEpoch: 107, Loss: 0.2364, Val: 1.2755, Test: 1.3132\n",
      "Sun Jan  2 22:37:41 2022\tEpoch: 108, Loss: 0.2329, Val: 1.2897, Test: 1.3310\n",
      "Sun Jan  2 22:37:46 2022\tEpoch: 109, Loss: 0.2261, Val: 1.3064, Test: 1.3393\n",
      "Sun Jan  2 22:37:51 2022\tEpoch: 110, Loss: 0.2262, Val: 1.3015, Test: 1.3384\n",
      "Sun Jan  2 22:37:57 2022\tEpoch: 111, Loss: 0.2203, Val: 1.3177, Test: 1.3508\n",
      "Sun Jan  2 22:38:03 2022\tEpoch: 112, Loss: 0.2141, Val: 1.3272, Test: 1.3617\n",
      "Sun Jan  2 22:38:09 2022\tEpoch: 113, Loss: 0.2088, Val: 1.2448, Test: 1.3261\n",
      "Sun Jan  2 22:38:15 2022\tEpoch: 114, Loss: 0.2071, Val: 1.2994, Test: 1.3455\n",
      "Sun Jan  2 22:38:21 2022\tEpoch: 115, Loss: 0.1988, Val: 1.3227, Test: 1.3569\n",
      "Sun Jan  2 22:38:26 2022\tEpoch: 116, Loss: 0.1988, Val: 1.3855, Test: 1.3936\n",
      "Sun Jan  2 22:38:32 2022\tEpoch: 117, Loss: 0.1958, Val: 1.3148, Test: 1.3591\n",
      "Sun Jan  2 22:38:38 2022\tEpoch: 118, Loss: 0.1918, Val: 1.3233, Test: 1.3683\n",
      "Sun Jan  2 22:38:43 2022\tEpoch: 119, Loss: 0.1843, Val: 1.3979, Test: 1.4201\n",
      "Sun Jan  2 22:38:49 2022\tEpoch: 120, Loss: 0.1834, Val: 1.2796, Test: 1.3515\n",
      "Sun Jan  2 22:38:54 2022\tEpoch: 121, Loss: 0.1808, Val: 1.2970, Test: 1.3607\n",
      "Sun Jan  2 22:38:59 2022\tEpoch: 122, Loss: 0.1756, Val: 1.4741, Test: 1.4569\n",
      "Sun Jan  2 22:39:04 2022\tEpoch: 123, Loss: 0.1775, Val: 1.3004, Test: 1.3589\n",
      "Sun Jan  2 22:39:10 2022\tEpoch: 124, Loss: 0.1713, Val: 1.3382, Test: 1.3759\n",
      "Sun Jan  2 22:39:16 2022\tEpoch: 125, Loss: 0.1636, Val: 1.5286, Test: 1.4986\n",
      "Sun Jan  2 22:39:20 2022\tEpoch: 126, Loss: 0.1650, Val: 1.2943, Test: 1.3798\n",
      "Sun Jan  2 22:39:26 2022\tEpoch: 127, Loss: 0.1601, Val: 1.3823, Test: 1.4179\n",
      "Sun Jan  2 22:39:32 2022\tEpoch: 128, Loss: 0.1578, Val: 1.4117, Test: 1.4368\n",
      "Sun Jan  2 22:39:37 2022\tEpoch: 129, Loss: 0.1531, Val: 1.3096, Test: 1.3812\n",
      "Sun Jan  2 22:39:43 2022\tEpoch: 130, Loss: 0.1504, Val: 1.5143, Test: 1.5038\n",
      "Sun Jan  2 22:39:49 2022\tEpoch: 131, Loss: 0.1492, Val: 1.4768, Test: 1.4717\n",
      "Sun Jan  2 22:39:54 2022\tEpoch: 132, Loss: 0.1444, Val: 1.3871, Test: 1.4344\n",
      "Sun Jan  2 22:39:58 2022\tEpoch: 133, Loss: 0.1435, Val: 1.4289, Test: 1.4612\n",
      "Sun Jan  2 22:40:04 2022\tEpoch: 134, Loss: 0.1394, Val: 1.4310, Test: 1.4643\n",
      "Sun Jan  2 22:40:09 2022\tEpoch: 135, Loss: 0.1385, Val: 1.4120, Test: 1.4341\n",
      "Sun Jan  2 22:40:14 2022\tEpoch: 136, Loss: 0.1341, Val: 1.4858, Test: 1.4862\n",
      "Sun Jan  2 22:40:20 2022\tEpoch: 137, Loss: 0.1314, Val: 1.5536, Test: 1.5494\n",
      "Sun Jan  2 22:40:25 2022\tEpoch: 138, Loss: 0.1308, Val: 1.3893, Test: 1.4537\n",
      "Sun Jan  2 22:40:32 2022\tEpoch: 139, Loss: 0.1297, Val: 1.4732, Test: 1.4892\n",
      "Sun Jan  2 22:40:38 2022\tEpoch: 140, Loss: 0.1233, Val: 1.4900, Test: 1.5090\n",
      "Sun Jan  2 22:40:43 2022\tEpoch: 141, Loss: 0.1258, Val: 1.3584, Test: 1.4574\n",
      "Sun Jan  2 22:40:48 2022\tEpoch: 142, Loss: 0.1236, Val: 1.4999, Test: 1.5303\n",
      "Sun Jan  2 22:40:54 2022\tEpoch: 143, Loss: 0.1200, Val: 1.4912, Test: 1.5144\n",
      "Sun Jan  2 22:40:59 2022\tEpoch: 144, Loss: 0.1193, Val: 1.3746, Test: 1.4770\n",
      "Sun Jan  2 22:41:05 2022\tEpoch: 145, Loss: 0.1164, Val: 1.4671, Test: 1.5107\n",
      "Sun Jan  2 22:41:11 2022\tEpoch: 146, Loss: 0.1130, Val: 1.4376, Test: 1.4860\n",
      "Sun Jan  2 22:41:16 2022\tEpoch: 147, Loss: 0.1133, Val: 1.4531, Test: 1.5087\n",
      "Sun Jan  2 22:41:22 2022\tEpoch: 148, Loss: 0.1146, Val: 1.3216, Test: 1.4560\n",
      "Sun Jan  2 22:41:27 2022\tEpoch: 149, Loss: 0.1086, Val: 1.4076, Test: 1.4901\n",
      "Sun Jan  2 22:41:33 2022\tEpoch: 150, Loss: 0.1091, Val: 1.5883, Test: 1.5806\n",
      "Sun Jan  2 22:41:39 2022\tEpoch: 151, Loss: 0.1045, Val: 1.5820, Test: 1.5795\n",
      "Sun Jan  2 22:41:43 2022\tEpoch: 152, Loss: 0.1037, Val: 1.4229, Test: 1.5050\n",
      "Sun Jan  2 22:41:48 2022\tEpoch: 153, Loss: 0.1015, Val: 1.5577, Test: 1.5731\n",
      "Sun Jan  2 22:41:55 2022\tEpoch: 154, Loss: 0.0997, Val: 1.5911, Test: 1.5921\n",
      "Sun Jan  2 22:42:00 2022\tEpoch: 155, Loss: 0.0984, Val: 1.4933, Test: 1.5592\n",
      "Sun Jan  2 22:42:05 2022\tEpoch: 156, Loss: 0.0973, Val: 1.4378, Test: 1.5151\n",
      "Sun Jan  2 22:42:11 2022\tEpoch: 157, Loss: 0.0946, Val: 1.4516, Test: 1.5087\n",
      "Sun Jan  2 22:42:16 2022\tEpoch: 158, Loss: 0.0941, Val: 1.6122, Test: 1.6155\n",
      "Sun Jan  2 22:42:22 2022\tEpoch: 159, Loss: 0.0928, Val: 1.5705, Test: 1.6022\n",
      "Sun Jan  2 22:42:27 2022\tEpoch: 160, Loss: 0.0910, Val: 1.5172, Test: 1.5520\n",
      "Sun Jan  2 22:42:33 2022\tEpoch: 161, Loss: 0.0922, Val: 1.5136, Test: 1.5593\n",
      "Sun Jan  2 22:42:38 2022\tEpoch: 162, Loss: 0.0899, Val: 1.5298, Test: 1.5666\n",
      "Sun Jan  2 22:42:44 2022\tEpoch: 163, Loss: 0.0868, Val: 1.4828, Test: 1.5452\n",
      "Sun Jan  2 22:42:49 2022\tEpoch: 164, Loss: 0.0888, Val: 1.4275, Test: 1.5298\n",
      "Sun Jan  2 22:42:55 2022\tEpoch: 165, Loss: 0.0871, Val: 1.4407, Test: 1.5265\n",
      "Sun Jan  2 22:43:01 2022\tEpoch: 166, Loss: 0.0853, Val: 1.4355, Test: 1.5242\n",
      "Sun Jan  2 22:43:06 2022\tEpoch: 167, Loss: 0.0860, Val: 1.3681, Test: 1.5074\n",
      "Sun Jan  2 22:43:11 2022\tEpoch: 168, Loss: 0.0845, Val: 1.5931, Test: 1.6209\n",
      "Sun Jan  2 22:43:17 2022\tEpoch: 169, Loss: 0.0824, Val: 1.3616, Test: 1.5173\n",
      "Sun Jan  2 22:43:22 2022\tEpoch: 170, Loss: 0.0809, Val: 1.3858, Test: 1.5323\n",
      "Sun Jan  2 22:43:27 2022\tEpoch: 171, Loss: 0.0815, Val: 1.4346, Test: 1.5460\n",
      "Sun Jan  2 22:43:33 2022\tEpoch: 172, Loss: 0.0816, Val: 1.5404, Test: 1.5963\n",
      "Sun Jan  2 22:43:38 2022\tEpoch: 173, Loss: 0.0791, Val: 1.4097, Test: 1.5361\n",
      "Sun Jan  2 22:43:44 2022\tEpoch: 174, Loss: 0.0803, Val: 1.3197, Test: 1.5088\n",
      "Sun Jan  2 22:43:50 2022\tEpoch: 175, Loss: 0.0792, Val: 1.6047, Test: 1.6479\n",
      "Sun Jan  2 22:43:55 2022\tEpoch: 176, Loss: 0.0788, Val: 1.3666, Test: 1.5257\n",
      "Sun Jan  2 22:44:01 2022\tEpoch: 177, Loss: 0.0791, Val: 1.3986, Test: 1.5357\n",
      "Sun Jan  2 22:44:06 2022\tEpoch: 178, Loss: 0.0762, Val: 1.6319, Test: 1.6594\n",
      "Sun Jan  2 22:44:12 2022\tEpoch: 179, Loss: 0.0761, Val: 1.3296, Test: 1.5770\n",
      "Sun Jan  2 22:44:17 2022\tEpoch: 180, Loss: 0.0751, Val: 1.5648, Test: 1.6081\n",
      "Sun Jan  2 22:44:22 2022\tEpoch: 181, Loss: 0.0728, Val: 1.4367, Test: 1.5538\n",
      "Sun Jan  2 22:44:27 2022\tEpoch: 182, Loss: 0.0738, Val: 1.4208, Test: 1.5707\n",
      "Sun Jan  2 22:44:34 2022\tEpoch: 183, Loss: 0.0736, Val: 1.3739, Test: 1.5430\n",
      "Sun Jan  2 22:44:39 2022\tEpoch: 184, Loss: 0.0706, Val: 1.3262, Test: 1.5291\n",
      "Sun Jan  2 22:44:44 2022\tEpoch: 185, Loss: 0.0712, Val: 1.4159, Test: 1.5606\n",
      "Sun Jan  2 22:44:50 2022\tEpoch: 186, Loss: 0.0714, Val: 1.3720, Test: 1.5523\n",
      "Sun Jan  2 22:44:56 2022\tEpoch: 187, Loss: 0.0690, Val: 1.5060, Test: 1.6130\n",
      "Sun Jan  2 22:45:02 2022\tEpoch: 188, Loss: 0.0689, Val: 1.4553, Test: 1.5693\n",
      "Sun Jan  2 22:45:08 2022\tEpoch: 189, Loss: 0.0702, Val: 1.3948, Test: 1.5725\n",
      "Sun Jan  2 22:45:14 2022\tEpoch: 190, Loss: 0.0683, Val: 1.5273, Test: 1.6093\n",
      "Sun Jan  2 22:45:19 2022\tEpoch: 191, Loss: 0.0667, Val: 1.4563, Test: 1.5698\n",
      "Sun Jan  2 22:45:24 2022\tEpoch: 192, Loss: 0.0657, Val: 1.4273, Test: 1.6199\n",
      "Sun Jan  2 22:45:30 2022\tEpoch: 193, Loss: 0.0662, Val: 1.4881, Test: 1.5991\n",
      "Sun Jan  2 22:45:36 2022\tEpoch: 194, Loss: 0.0666, Val: 1.3496, Test: 1.5570\n",
      "Sun Jan  2 22:45:41 2022\tEpoch: 195, Loss: 0.0653, Val: 1.7030, Test: 1.7481\n",
      "Sun Jan  2 22:45:47 2022\tEpoch: 196, Loss: 0.0675, Val: 1.3705, Test: 1.5893\n",
      "Sun Jan  2 22:45:52 2022\tEpoch: 197, Loss: 0.0657, Val: 1.5363, Test: 1.6324\n",
      "Sun Jan  2 22:45:58 2022\tEpoch: 198, Loss: 0.0660, Val: 1.6762, Test: 1.6947\n",
      "Sun Jan  2 22:46:04 2022\tEpoch: 199, Loss: 0.0670, Val: 1.4143, Test: 1.5695\n",
      "Sun Jan  2 22:46:09 2022\tEpoch: 200, Loss: 0.0633, Val: 1.7009, Test: 1.7280\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for epoch in range(1, 201):\n",
    "    loss, train_counter = train(train_loader)\n",
    "    test_mae, test_counter = test(test_loader)\n",
    "    val_mae, _ = test(val_loader)\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "    writer.add_scalar('Loss/test', test_mae, epoch)\n",
    "    writer.add_scalar('Loss/val', val_mae, epoch)\n",
    "    writer.add_scalar('Counter/train', train_counter/len(train_loader.dataset), epoch)\n",
    "    writer.add_scalar('Counter/test', test_counter/len(test_loader.dataset), epoch)\n",
    "    \n",
    "    print(f'{time.ctime()}\\t'\n",
    "          f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n",
    "          f'Test: {test_mae:.4f}')\n",
    "    \n",
    "    # print(f'\\t\\t -- train_counter: {train_counter}, test_counter:{test_counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb52095-743c-4a75-947d-7e728e87c0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G2Dist_GCNConv_Global(\n",
       "  (node_emb): Embedding(10000, 2)\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(80, 80)\n",
       "    (1): GCNConv(80, 80)\n",
       "  )\n",
       "  (pools): ModuleList()\n",
       "  (batch_norms): ModuleList(\n",
       "    (0): BatchNorm(80)\n",
       "    (1): BatchNorm(80)\n",
       "  )\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=80, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3c2ebc-f8aa-4886-88c7-02bbc8b5188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G2Dist_GCNConv_Global(\n",
       "  (node_emb): Embedding(10000, 2)\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(80, 80)\n",
       "    (1): GCNConv(80, 80)\n",
       "  )\n",
       "  (pools): ModuleList()\n",
       "  (batch_norms): ModuleList(\n",
       "    (0): BatchNorm(80)\n",
       "    (1): BatchNorm(80)\n",
       "  )\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=80, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b771e75-9824-4e0b-9d67-b98b87acdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tld0 = list(train_loader)[0].to(device)\n",
    "tld1 = list(test_loader)[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb990c5f-3804-447f-9ec4-ff38f99732e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = model(tld0.x, tld0.edge_index, tld0.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f709262e-4b24-4720-98d5-d3d934d80962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 1, 2, 4, 3, 1, 3, 0, 3, 4, 2, 4, 3, 3, 3, 1, 3, 4, 2, 0, 4, 0, 1,\n",
       "        3, 0, 1, 0, 2, 2, 1, 0, 4, 4, 1, 0, 3, 1, 2, 2, 1, 1, 1, 4, 2, 1, 4, 3,\n",
       "        0, 4, 2, 1, 2, 2, 4, 2, 3, 2, 3, 3, 3, 0, 4, 0, 3, 2, 4, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 2, 3, 3, 4, 3, 3, 2, 0, 0, 4, 2, 3, 4, 1, 0, 2, 4, 2,\n",
       "        1, 4, 2, 4, 4, 1, 0, 2, 0, 4, 2, 2, 1, 0, 0, 2, 3, 4, 0, 2, 0, 0, 1, 3,\n",
       "        4, 4, 2, 4, 0, 2, 2, 2, 0, 1, 4, 2, 4, 2, 2, 2, 1, 1, 3, 0, 1, 4, 3, 2,\n",
       "        1, 0, 4, 2, 3, 0, 2, 0, 3, 4, 4, 2, 2, 4, 4, 2, 4, 1, 4, 1, 3, 3, 3, 3,\n",
       "        3, 0, 0, 3, 1, 3, 1, 4, 3, 3, 2, 2, 3, 3, 0, 4, 2, 4, 3, 2, 4, 4, 4, 2,\n",
       "        4, 0, 2, 2, 4, 3, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 3, 1, 2, 2, 0, 0, 1, 3,\n",
       "        4, 1, 2, 4, 0, 3, 3, 3, 2, 2, 0, 3, 1, 4, 3, 3, 3, 4, 0, 3, 4, 0, 3, 2,\n",
       "        3, 1, 2, 2, 0, 4, 3, 2, 4, 0, 1, 2, 0, 3, 1, 0, 2, 0, 4, 3, 1, 0, 0, 1,\n",
       "        4, 2, 1, 1, 0, 1, 4, 0, 1, 3, 3, 1, 1, 3, 2, 1, 4, 3, 3, 0, 4, 2, 0, 1,\n",
       "        0, 0, 0, 3, 4, 4, 3, 4, 4, 0, 4, 1, 2, 4, 2, 3, 4, 2, 1, 4, 3, 1, 1, 3,\n",
       "        4, 2, 0, 1, 2, 1, 1, 3, 4, 0, 0, 4, 4, 0, 2, 4, 1, 2, 0, 0, 4, 0, 0, 1,\n",
       "        2, 1, 1, 0, 0, 0, 2, 1, 3, 1, 3, 3, 1, 3, 1, 1, 2, 0, 3, 4, 0, 0, 0, 4,\n",
       "        0, 0, 4, 4, 3, 4, 0, 2, 4, 4, 0, 2, 2, 1, 4, 3, 4, 1, 2, 4, 4, 3, 4, 2,\n",
       "        1, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 3, 2, 4, 3, 4, 2, 3, 0, 3, 0, 1, 3, 2,\n",
       "        0, 1, 2, 4, 0, 1, 3, 4, 4, 2, 2, 0, 1, 3, 1, 3, 3, 4, 1, 2, 0, 1, 3, 0,\n",
       "        0, 2, 2, 2, 2, 3, 2, 0, 4, 0, 1, 0, 2, 1, 1, 2, 4, 1, 4, 4, 2, 3, 3, 4,\n",
       "        4, 2, 4, 3, 1, 3, 3, 1, 3, 1, 2, 3, 0, 0, 4, 1, 2, 0, 1, 4, 0, 4, 0, 3,\n",
       "        1, 0, 2, 2, 4, 0, 3, 1, 3, 4, 4, 4, 4, 1, 3, 0, 0, 1, 2, 3, 4, 4, 4, 2,\n",
       "        0, 0, 2, 0, 0, 4, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res0.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609f9b9c-5456-4492-90ed-cbe9c261d5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 1, 2, 4, 3, 1, 3, 0, 3, 4, 2, 4, 3, 3, 3, 1, 3, 4, 2, 0, 4, 0, 1,\n",
       "        3, 0, 1, 0, 2, 2, 1, 0, 4, 4, 1, 0, 3, 1, 2, 2, 1, 1, 1, 4, 2, 1, 4, 3,\n",
       "        0, 4, 2, 1, 2, 2, 4, 2, 3, 2, 3, 3, 3, 0, 4, 0, 3, 2, 4, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 2, 3, 3, 4, 3, 3, 2, 0, 0, 4, 2, 3, 4, 1, 0, 2, 4, 2,\n",
       "        1, 4, 2, 4, 4, 1, 0, 2, 0, 4, 2, 2, 1, 0, 0, 2, 3, 4, 0, 2, 0, 0, 1, 3,\n",
       "        4, 4, 2, 4, 0, 2, 2, 2, 0, 1, 4, 2, 4, 2, 2, 2, 1, 1, 3, 0, 1, 4, 3, 2,\n",
       "        1, 0, 4, 2, 3, 0, 2, 0, 3, 4, 4, 2, 2, 4, 4, 2, 4, 1, 4, 1, 3, 3, 3, 3,\n",
       "        3, 0, 0, 3, 1, 3, 1, 4, 3, 3, 2, 2, 3, 3, 0, 4, 2, 4, 3, 2, 4, 4, 4, 2,\n",
       "        4, 0, 2, 2, 4, 3, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 3, 1, 2, 2, 0, 0, 1, 3,\n",
       "        4, 1, 2, 4, 0, 3, 3, 3, 2, 2, 0, 3, 1, 4, 3, 3, 3, 4, 0, 3, 4, 0, 3, 2,\n",
       "        3, 1, 2, 2, 0, 4, 3, 2, 4, 0, 1, 2, 0, 3, 1, 0, 2, 0, 4, 3, 1, 0, 0, 1,\n",
       "        4, 2, 1, 1, 0, 1, 4, 0, 1, 3, 3, 1, 1, 3, 2, 1, 4, 3, 3, 0, 4, 2, 0, 1,\n",
       "        0, 0, 0, 3, 4, 4, 3, 4, 4, 0, 4, 1, 2, 4, 2, 3, 4, 2, 1, 4, 3, 1, 1, 3,\n",
       "        4, 2, 0, 1, 2, 1, 1, 3, 4, 0, 0, 4, 4, 0, 2, 4, 1, 2, 0, 0, 4, 0, 0, 1,\n",
       "        2, 1, 1, 0, 0, 0, 2, 1, 3, 1, 3, 3, 1, 3, 1, 1, 2, 0, 3, 4, 0, 0, 0, 4,\n",
       "        0, 0, 4, 4, 3, 4, 0, 2, 4, 4, 0, 2, 2, 1, 4, 3, 4, 1, 2, 4, 4, 3, 4, 2,\n",
       "        1, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 3, 2, 4, 3, 4, 2, 3, 0, 3, 0, 1, 3, 2,\n",
       "        0, 1, 2, 4, 0, 1, 3, 4, 4, 2, 2, 0, 1, 3, 1, 3, 3, 4, 1, 2, 0, 1, 3, 0,\n",
       "        0, 2, 2, 2, 2, 3, 2, 0, 4, 0, 1, 0, 2, 1, 1, 2, 4, 1, 4, 4, 2, 3, 3, 4,\n",
       "        4, 2, 4, 3, 1, 3, 3, 1, 3, 1, 2, 3, 0, 0, 4, 1, 2, 0, 1, 4, 0, 4, 0, 3,\n",
       "        1, 0, 2, 2, 4, 0, 3, 1, 3, 4, 4, 4, 4, 1, 3, 0, 0, 1, 2, 3, 4, 4, 4, 2,\n",
       "        0, 0, 2, 0, 0, 4, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tld0.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e86c48-0a60-48b8-ac35-8776deadb25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0643, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(res0, tld0.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a85b7691-9bec-4d6f-ba36-07213d45cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss()(res0.argmax(axis = 1).to(torch.float), tld0.y.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "340f9c83-9877-4df9-a4d4-235e1facaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model(tld1.x, tld1.edge_index, tld1.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "092b0b1f-3a5f-427e-abb4-3ef7723ef7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 3, 1, 4, 0, 2, 2, 0, 2, 2, 0, 2, 2, 3, 4, 4, 2, 4, 3, 4, 4, 3,\n",
       "        2, 2, 4, 3, 4, 4, 2, 2, 2, 1, 3, 0, 4, 2, 4, 4, 0, 3, 2, 2, 2, 1, 3, 3,\n",
       "        3, 0, 0, 2, 4, 3, 2, 4, 2, 4, 1, 1, 2, 0, 3, 1, 0, 2, 4, 3, 3, 3, 0, 3,\n",
       "        3, 2, 2, 2, 4, 4, 1, 3, 1, 1, 1, 0, 1, 0, 1, 4, 4, 1, 0, 0, 4, 2, 2, 1,\n",
       "        2, 4, 3, 3, 2, 2, 4, 3, 3, 2, 3, 4, 4, 2, 4, 4, 1, 0, 0, 4, 4, 2, 3, 4,\n",
       "        3, 4, 3, 2, 2, 1, 3, 2, 2, 0, 1, 1, 4, 3, 1, 1, 0, 3, 3, 2, 0, 1, 4, 4,\n",
       "        0, 0, 3, 2, 3, 0, 2, 2, 3, 1, 3, 3, 0, 4, 4, 1, 4, 4, 1, 2, 0, 0, 3, 4,\n",
       "        2, 4, 0, 3, 4, 1, 1, 0, 4, 3, 1, 2, 0, 0, 1, 4, 0, 2, 4, 0, 4, 2, 4, 2,\n",
       "        2, 2, 4, 3, 3, 3, 2, 3, 2, 2, 4, 0, 3, 2, 1, 3, 2, 1, 2, 2, 0, 2, 0, 2,\n",
       "        3, 3, 4, 1, 2, 4, 4, 0, 0, 2, 2, 2, 0, 4, 2, 4, 1, 2, 1, 3, 0, 3, 2, 4,\n",
       "        4, 3, 0, 4, 4, 4, 1, 0, 4, 3, 4, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f488421d-cdc8-4ea1-9617-b0fbedeab631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 3, 1, 2, 3, 0, 2, 4, 0, 2, 4, 0, 2, 4, 4, 3, 4, 1, 4, 4, 1, 2, 4,\n",
       "        3, 1, 4, 2, 3, 4, 3, 2, 1, 1, 2, 0, 2, 2, 3, 3, 0, 4, 1, 4, 2, 3, 2, 3,\n",
       "        2, 0, 0, 3, 4, 2, 4, 2, 1, 2, 1, 2, 4, 0, 3, 4, 0, 2, 2, 3, 1, 2, 0, 1,\n",
       "        2, 4, 1, 1, 4, 3, 1, 3, 4, 2, 1, 1, 1, 0, 2, 4, 2, 1, 0, 0, 4, 4, 2, 4,\n",
       "        2, 1, 3, 3, 3, 2, 4, 2, 4, 4, 4, 2, 4, 3, 4, 2, 1, 0, 0, 4, 3, 4, 4, 4,\n",
       "        2, 3, 4, 1, 1, 1, 3, 1, 4, 0, 1, 4, 2, 4, 1, 1, 0, 4, 2, 2, 0, 1, 4, 4,\n",
       "        0, 0, 3, 2, 3, 0, 1, 2, 4, 1, 2, 1, 0, 4, 1, 1, 4, 3, 2, 2, 1, 0, 4, 4,\n",
       "        2, 1, 0, 2, 4, 1, 4, 0, 2, 4, 2, 3, 0, 0, 2, 4, 0, 4, 1, 0, 4, 1, 4, 3,\n",
       "        1, 1, 2, 1, 2, 2, 2, 3, 1, 3, 2, 0, 2, 1, 1, 4, 3, 2, 2, 2, 0, 3, 0, 2,\n",
       "        4, 3, 4, 3, 4, 3, 3, 0, 0, 3, 2, 4, 0, 4, 2, 2, 1, 2, 1, 2, 0, 4, 2, 3,\n",
       "        2, 2, 0, 1, 4, 4, 2, 1, 4, 2, 1, 4, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tld1.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2105e71f-aae9-444b-a1dd-bcd3ce75870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 3, 1, 4, 0, 2, 2, 0, 2, 2, 0, 2, 2, 3, 4, 4, 2, 4, 3, 4, 4, 3,\n",
      "        2, 2, 4, 3, 4, 4, 2, 2, 2, 1, 3, 0, 4, 2, 4, 4, 0, 3, 2, 2, 2, 1, 3, 3,\n",
      "        3, 0, 0, 2, 4, 3, 2, 4, 2, 4, 1, 1, 2, 0, 3, 1, 0, 2, 4, 3, 3, 3, 0, 3,\n",
      "        3, 2, 2, 2, 4, 4, 1, 3, 1, 1, 1, 0, 1, 0, 1, 4, 4, 1, 0, 0, 4, 2, 2, 1,\n",
      "        2, 4, 3, 3, 2, 2, 4, 3, 3, 2, 3, 4, 4, 2, 4, 4, 1, 0, 0, 4, 4, 2, 3, 4,\n",
      "        3, 4, 3, 2, 2, 1, 3, 2, 2, 0, 1, 1, 4, 3, 1, 1, 0, 3, 3, 2, 0, 1, 4, 4,\n",
      "        0, 0, 3, 2, 3, 0, 2, 2, 3, 1, 3, 3, 0, 4, 4, 1, 4, 4, 1, 2, 0, 0, 3, 4,\n",
      "        2, 4, 0, 3, 4, 1, 1, 0, 4, 3, 1, 2, 0, 0, 1, 4, 0, 2, 4, 0, 4, 2, 4, 2,\n",
      "        2, 2, 4, 3, 3, 3, 2, 3, 2, 2, 4, 0, 3, 2, 1, 3, 2, 1, 2, 2, 0, 2, 0, 2,\n",
      "        3, 3, 4, 1, 2, 4, 4, 0, 0, 2, 2, 2, 0, 4, 2, 4, 1, 2, 1, 3, 0, 3, 2, 4,\n",
      "        4, 3, 0, 4, 4, 4, 1, 0, 4, 3, 4, 2, 0, 1, 0, 2])\n",
      "tensor([2, 0, 0, 3, 4, 3, 0, 4, 2, 4, 4, 4, 2, 2, 2, 2, 0, 2, 3, 4, 1, 0, 1, 2,\n",
      "        3, 0, 3, 3, 1, 3, 1, 0, 0, 4, 3, 0, 0, 3, 1, 2, 1, 1, 3, 0, 4, 0, 2, 3,\n",
      "        1, 4, 2, 1, 0, 3, 3, 2, 2, 2, 0, 1, 3, 4, 1, 2, 3, 1, 1, 4, 4, 2, 4, 0,\n",
      "        4, 1, 1, 4, 3, 0, 1, 0, 1, 4, 3, 1, 3, 1, 3, 4, 1, 4, 0, 4, 2, 4, 2, 4,\n",
      "        2, 1, 1, 2, 0, 3, 0, 4, 1, 2, 3, 1, 3, 1, 1, 2, 4, 2, 0, 2, 1, 2, 0, 0,\n",
      "        2, 0, 4, 3, 4, 4, 1, 4, 4, 2, 1, 1, 1, 0, 2, 4, 1, 0, 3, 4, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for tld in test_loader:\n",
    "    res = model(tld.x, tld.edge_index, tld.batch)\n",
    "    print(res.argmax(axis = 1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de62f1af-5842-4051-89a7-c33ce728c747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3df503c-618d-40c8-a040-a3cc36f23817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5402, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(res1, tld1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60e359cd-f57b-4c36-9854-e893f651c5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7773)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss()(res1.argmax(axis = 1).to(torch.float), tld1.y.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5ee4bdc-004c-4a80-ab9b-322a83e784f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [d.y.item() for d in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80c6323a-9b77-4f60-b075-c8dbfdf37c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f8702e1-17db-4b05-a5d9-9a02d86bd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [d.y.item() for d in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bbb9e24-7048-404c-9cff-01b3025ce878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "432e542f-d058-4e5c-9ccc-f2ce3828072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([d.y.item() for d in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ec70e5-62dc-4e3f-b3fa-aa666e6b3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a7adae8-7c3e-42fb-adc1-c0b3630041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abc36559-7631-46d6-adfb-8b5e7e83b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70a83aae-201f-41eb-ba8a-03ae1a00cbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10000, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.node_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f0c64e4-58d8-40b9-ac2b-1f1ec944eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.node_emb(data.x.squeeze()).view(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e50969d7-1fdd-41b1-8d8b-05e451b66511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0873,  0.1086,  0.9810,  ...,  0.1086,  1.0873,  0.1086],\n",
       "        [ 1.0873,  0.1086,  1.0873,  ...,  0.1086,  1.0873,  0.1086],\n",
       "        [ 1.0873,  0.1086,  1.0873,  ...,  1.1391,  1.0873,  0.1086],\n",
       "        ...,\n",
       "        [ 1.0873,  0.1086,  1.0873,  ...,  0.1086,  1.0873,  0.1086],\n",
       "        [ 1.0873,  0.1086,  1.0873,  ...,  0.1086, -1.0730,  1.1391],\n",
       "        [ 1.0873,  0.1086,  1.0873,  ...,  1.1391,  1.0873,  0.1086]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c33c9c64-c7e1-4e51-ab69-6f4dfe4d91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.convs[0](x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de5ca919-0a19-4418-a0b9-53dcb3b7a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5863, -0.4789,  0.1791,  ...,  0.1434, -0.2350, -0.2029],\n",
       "        [-0.5876, -0.4833,  0.1811,  ...,  0.1518, -0.2389, -0.2073],\n",
       "        [-0.5984, -0.5648,  0.0596,  ...,  0.1285, -0.2463, -0.1648],\n",
       "        ...,\n",
       "        [-0.5901, -0.4803,  0.1876,  ...,  0.1478, -0.2438, -0.2027],\n",
       "        [-0.5531, -0.4870,  0.1479,  ...,  0.2146, -0.1797, -0.2445],\n",
       "        [-0.5807, -0.5874,  0.1187,  ...,  0.1512, -0.2544, -0.1558]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "451ead6a-fc3f-404a-9d35-199b80ce8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2d276ee-3f46-4049-a24b-4a40118968f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [d.y.item() for d in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "124e4334-bf57-45d8-9d30-914eb84bee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [d.y.item() for d in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14c6dc80-2652-40e0-9686-6376e3299977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e87b13fd-beda-4c19-a008-c600ebc8fb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d85de6b7-d010-4cf4-a985-ef02ae432d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([d.y.item() for d in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba2ea5c4-1166-4ec2-9242-6eaaaa860569",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.histogram(train_y, np.arange(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ab40ab-7895-484b-879e-a061bfd7597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.histogram(test_y, np.arange(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99654bc3-cca0-45c9-9bb7-4c1c268f4d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [2, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 2, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "687ec21b-daff-4437-a7c5-f49380be7608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20480, 40])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tld0.x.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f797ae0-5b71-4a3d-88bc-77c9594b4a79",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'G2Dist_GCNConv_Global' object has no attribute 'pre'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_609117/1846061219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtld0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'G2Dist_GCNConv_Global' object has no attribute 'pre'"
     ]
    }
   ],
   "source": [
    "model.pre(tld0.x, tld0.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f09e2-65e5-4059-94d6-9b18e6de007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bed27-c684-4a99-9b2b-32e0061eaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61f51c-4a74-4408-81fd-2c5f2d6d3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73ed82-625c-441e-ad0c-251e2db7850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c552722-2930-4c6c-8235-10ba59906b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep AI",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
