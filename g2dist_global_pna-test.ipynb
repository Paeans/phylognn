{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aa328c-fbde-4c86-837d-b109eac25828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, Embedding\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, L1Loss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, PNAConv, BatchNorm, global_add_pool\n",
    "\n",
    "from phylognn_model import G2Dist_PNAConv\n",
    "\n",
    "from gene_graph_dataset import GeneGraphDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1afe07e-f45d-4435-9efd-f7be458f83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p, test_p = 0.7, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8f1633-bee2-464b-93e2-6fea1a471948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeneGraphDataset('dataset_adj1', 20, 20, graph_num = 100)\n",
    "data_size = len(dataset)\n",
    "train_size, test_size = (int)(data_size * train_p), (int)(data_size * test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2f694a-7ae1-455e-9582-8b7eb9ed67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95dcce3-4aaf-4d68-b153-a9581899a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:(train_size + test_size)]\n",
    "val_dataset = dataset[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f6283c-d51a-4747-8f1b-f437ca523abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbf1dce-6f12-4fdd-be53-37271e03d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c85b3a-1bdf-49db-8494-d04d29ba39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader), len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f5cbed-ec80-4a6f-8d23-d1f24482bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = torch.zeros(5, dtype=torch.long)\n",
    "for data in dataset:\n",
    "    d = degree(data.edge_index[1].type(torch.int64), \n",
    "               num_nodes=data.num_nodes, dtype=torch.long)\n",
    "    deg += torch.bincount(d, minlength=deg.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c79a8d-bb5d-4875-80ff-6c22ece243e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = G2Dist_PNAConv(deg).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e364bfa2-7153-493c-9d74-ba7b1ae117ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = MSELoss()\n",
    "# l1_fn = L1Loss()\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss, counter = 0, 0\n",
    "    size = len(train_loader)\n",
    "    for batch, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #loss = (out.squeeze() - data.y).abs().sum()\n",
    "        pred, y = out.softmax(axis = 1).argmax(axis = 1), data.y\n",
    "        counter += (pred == y).sum().item()\n",
    "        \n",
    "        loss = loss_fn(out, data.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / len(train_loader), counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1b9829-772b-4e9b-a75e-1e9904d80afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_error, counter = 0, 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        pred, y = out.softmax(axis = 1).argmax(axis = 1), data.y\n",
    "        counter += (pred == y).sum().item()\n",
    "        \n",
    "        # total_error += (out.squeeze() - data.y).abs().sum().item()\n",
    "        \n",
    "        total_error += loss_fn(out, data.y).item()\n",
    "        \n",
    "    return total_error / len(loader), counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fba2c20-6dee-4b91-acdb-8ee1fa2319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs_g2d_10/g2dist_adjone_02000-pna-global-run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23bb307-e484-493c-a60e-69911d93d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan  2 14:15:39 2022\tEpoch: 001, Loss: 3.1139, Val: 2.9204, Test: 2.9613\n",
      "\t\t -- train_counter: 117, test_counter:28\n",
      "Sun Jan  2 14:15:42 2022\tEpoch: 002, Loss: 2.7273, Val: 2.8902, Test: 2.9204\n",
      "\t\t -- train_counter: 181, test_counter:41\n",
      "Sun Jan  2 14:15:46 2022\tEpoch: 003, Loss: 2.6004, Val: 2.7530, Test: 2.8115\n",
      "\t\t -- train_counter: 263, test_counter:47\n",
      "Sun Jan  2 14:15:50 2022\tEpoch: 004, Loss: 2.4950, Val: 2.6956, Test: 2.7768\n",
      "\t\t -- train_counter: 293, test_counter:53\n",
      "Sun Jan  2 14:15:53 2022\tEpoch: 005, Loss: 2.4119, Val: 2.7598, Test: 2.8190\n",
      "\t\t -- train_counter: 356, test_counter:34\n",
      "Sun Jan  2 14:15:57 2022\tEpoch: 006, Loss: 2.3259, Val: 2.8666, Test: 2.7650\n",
      "\t\t -- train_counter: 429, test_counter:61\n",
      "Sun Jan  2 14:16:01 2022\tEpoch: 007, Loss: 2.2537, Val: 2.8493, Test: 2.7790\n",
      "\t\t -- train_counter: 489, test_counter:59\n",
      "Sun Jan  2 14:16:05 2022\tEpoch: 008, Loss: 2.1544, Val: 3.3997, Test: 3.3631\n",
      "\t\t -- train_counter: 568, test_counter:33\n",
      "Sun Jan  2 14:16:08 2022\tEpoch: 009, Loss: 2.0492, Val: 2.6519, Test: 2.6353\n",
      "\t\t -- train_counter: 643, test_counter:58\n",
      "Sun Jan  2 14:16:12 2022\tEpoch: 010, Loss: 1.9561, Val: 2.8832, Test: 2.8039\n",
      "\t\t -- train_counter: 680, test_counter:48\n",
      "Sun Jan  2 14:16:16 2022\tEpoch: 011, Loss: 1.8474, Val: 2.7059, Test: 2.6407\n",
      "\t\t -- train_counter: 764, test_counter:59\n",
      "Sun Jan  2 14:16:20 2022\tEpoch: 012, Loss: 1.7389, Val: 2.7982, Test: 2.7747\n",
      "\t\t -- train_counter: 859, test_counter:56\n",
      "Sun Jan  2 14:16:23 2022\tEpoch: 013, Loss: 1.6214, Val: 3.0413, Test: 3.0208\n",
      "\t\t -- train_counter: 969, test_counter:64\n",
      "Sun Jan  2 14:16:27 2022\tEpoch: 014, Loss: 1.5159, Val: 2.8599, Test: 2.8434\n",
      "\t\t -- train_counter: 1029, test_counter:43\n",
      "Sun Jan  2 14:16:31 2022\tEpoch: 015, Loss: 1.3921, Val: 2.7073, Test: 2.7088\n",
      "\t\t -- train_counter: 1096, test_counter:52\n",
      "Sun Jan  2 14:16:35 2022\tEpoch: 016, Loss: 1.2583, Val: 2.9003, Test: 2.8039\n",
      "\t\t -- train_counter: 1167, test_counter:62\n",
      "Sun Jan  2 14:16:39 2022\tEpoch: 017, Loss: 1.1576, Val: 2.8658, Test: 2.9079\n",
      "\t\t -- train_counter: 1220, test_counter:56\n",
      "Sun Jan  2 14:16:42 2022\tEpoch: 018, Loss: 1.0234, Val: 2.8176, Test: 2.6986\n",
      "\t\t -- train_counter: 1295, test_counter:63\n",
      "Sun Jan  2 14:16:46 2022\tEpoch: 019, Loss: 0.9091, Val: 2.7374, Test: 2.7596\n",
      "\t\t -- train_counter: 1317, test_counter:63\n",
      "Sun Jan  2 14:16:50 2022\tEpoch: 020, Loss: 0.7933, Val: 2.7472, Test: 2.7798\n",
      "\t\t -- train_counter: 1344, test_counter:50\n",
      "Sun Jan  2 14:16:53 2022\tEpoch: 021, Loss: 0.6791, Val: 2.8580, Test: 2.8180\n",
      "\t\t -- train_counter: 1373, test_counter:61\n",
      "Sun Jan  2 14:16:57 2022\tEpoch: 022, Loss: 0.5756, Val: 2.8144, Test: 2.7407\n",
      "\t\t -- train_counter: 1383, test_counter:66\n",
      "Sun Jan  2 14:17:01 2022\tEpoch: 023, Loss: 0.4795, Val: 2.8017, Test: 2.7642\n",
      "\t\t -- train_counter: 1391, test_counter:62\n",
      "Sun Jan  2 14:17:05 2022\tEpoch: 024, Loss: 0.3959, Val: 2.8307, Test: 2.7190\n",
      "\t\t -- train_counter: 1398, test_counter:62\n",
      "Sun Jan  2 14:17:09 2022\tEpoch: 025, Loss: 0.3204, Val: 2.7680, Test: 2.7586\n",
      "\t\t -- train_counter: 1399, test_counter:60\n",
      "Sun Jan  2 14:17:13 2022\tEpoch: 026, Loss: 0.2558, Val: 2.8387, Test: 2.7908\n",
      "\t\t -- train_counter: 1399, test_counter:59\n",
      "Sun Jan  2 14:17:16 2022\tEpoch: 027, Loss: 0.2130, Val: 2.9020, Test: 2.8862\n",
      "\t\t -- train_counter: 1400, test_counter:61\n",
      "Sun Jan  2 14:17:20 2022\tEpoch: 028, Loss: 0.1708, Val: 2.8656, Test: 2.8370\n",
      "\t\t -- train_counter: 1400, test_counter:69\n",
      "Sun Jan  2 14:17:24 2022\tEpoch: 029, Loss: 0.1387, Val: 2.9369, Test: 2.8971\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:17:27 2022\tEpoch: 030, Loss: 0.1148, Val: 2.9080, Test: 2.8441\n",
      "\t\t -- train_counter: 1400, test_counter:64\n",
      "Sun Jan  2 14:17:31 2022\tEpoch: 031, Loss: 0.0965, Val: 2.9860, Test: 2.8986\n",
      "\t\t -- train_counter: 1400, test_counter:64\n",
      "Sun Jan  2 14:17:35 2022\tEpoch: 032, Loss: 0.0843, Val: 2.9017, Test: 2.8597\n",
      "\t\t -- train_counter: 1400, test_counter:60\n",
      "Sun Jan  2 14:17:38 2022\tEpoch: 033, Loss: 0.0734, Val: 2.8785, Test: 2.8404\n",
      "\t\t -- train_counter: 1400, test_counter:59\n",
      "Sun Jan  2 14:17:42 2022\tEpoch: 034, Loss: 0.0650, Val: 2.9337, Test: 2.8827\n",
      "\t\t -- train_counter: 1400, test_counter:62\n",
      "Sun Jan  2 14:17:46 2022\tEpoch: 035, Loss: 0.0591, Val: 2.9170, Test: 2.8772\n",
      "\t\t -- train_counter: 1400, test_counter:60\n",
      "Sun Jan  2 14:17:50 2022\tEpoch: 036, Loss: 0.0530, Val: 2.9525, Test: 2.8919\n",
      "\t\t -- train_counter: 1400, test_counter:65\n",
      "Sun Jan  2 14:17:53 2022\tEpoch: 037, Loss: 0.0483, Val: 2.9818, Test: 2.9025\n",
      "\t\t -- train_counter: 1400, test_counter:59\n",
      "Sun Jan  2 14:17:57 2022\tEpoch: 038, Loss: 0.0438, Val: 2.9380, Test: 2.8833\n",
      "\t\t -- train_counter: 1400, test_counter:60\n",
      "Sun Jan  2 14:18:01 2022\tEpoch: 039, Loss: 0.0409, Val: 2.9320, Test: 2.9069\n",
      "\t\t -- train_counter: 1400, test_counter:59\n",
      "Sun Jan  2 14:18:04 2022\tEpoch: 040, Loss: 0.0373, Val: 2.9855, Test: 2.9148\n",
      "\t\t -- train_counter: 1400, test_counter:57\n",
      "Sun Jan  2 14:18:08 2022\tEpoch: 041, Loss: 0.0352, Val: 2.9856, Test: 2.9154\n",
      "\t\t -- train_counter: 1400, test_counter:65\n",
      "Sun Jan  2 14:18:12 2022\tEpoch: 042, Loss: 0.0327, Val: 3.0052, Test: 2.9292\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:18:16 2022\tEpoch: 043, Loss: 0.0307, Val: 2.9617, Test: 2.9240\n",
      "\t\t -- train_counter: 1400, test_counter:57\n",
      "Sun Jan  2 14:18:19 2022\tEpoch: 044, Loss: 0.0286, Val: 3.0063, Test: 2.9313\n",
      "\t\t -- train_counter: 1400, test_counter:54\n",
      "Sun Jan  2 14:18:23 2022\tEpoch: 045, Loss: 0.0269, Val: 3.0059, Test: 2.9502\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:18:27 2022\tEpoch: 046, Loss: 0.0253, Val: 3.0088, Test: 2.9459\n",
      "\t\t -- train_counter: 1400, test_counter:59\n",
      "Sun Jan  2 14:18:31 2022\tEpoch: 047, Loss: 0.0242, Val: 3.0180, Test: 2.9537\n",
      "\t\t -- train_counter: 1400, test_counter:58\n",
      "Sun Jan  2 14:18:35 2022\tEpoch: 048, Loss: 0.0228, Val: 3.0070, Test: 2.9584\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:18:38 2022\tEpoch: 049, Loss: 0.0215, Val: 3.0474, Test: 2.9718\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:18:42 2022\tEpoch: 050, Loss: 0.0205, Val: 3.0334, Test: 2.9641\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:18:46 2022\tEpoch: 051, Loss: 0.0196, Val: 3.0281, Test: 2.9685\n",
      "\t\t -- train_counter: 1400, test_counter:57\n",
      "Sun Jan  2 14:18:50 2022\tEpoch: 052, Loss: 0.0189, Val: 3.0723, Test: 2.9917\n",
      "\t\t -- train_counter: 1400, test_counter:61\n",
      "Sun Jan  2 14:18:53 2022\tEpoch: 053, Loss: 0.0177, Val: 3.0335, Test: 2.9933\n",
      "\t\t -- train_counter: 1400, test_counter:53\n",
      "Sun Jan  2 14:18:57 2022\tEpoch: 054, Loss: 0.0170, Val: 3.0706, Test: 2.9966\n",
      "\t\t -- train_counter: 1400, test_counter:57\n",
      "Sun Jan  2 14:19:00 2022\tEpoch: 055, Loss: 0.0164, Val: 3.0534, Test: 3.0027\n",
      "\t\t -- train_counter: 1400, test_counter:53\n",
      "Sun Jan  2 14:19:04 2022\tEpoch: 056, Loss: 0.0155, Val: 3.0638, Test: 3.0075\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:19:08 2022\tEpoch: 057, Loss: 0.0153, Val: 3.0543, Test: 3.0080\n",
      "\t\t -- train_counter: 1400, test_counter:50\n",
      "Sun Jan  2 14:19:12 2022\tEpoch: 058, Loss: 0.0145, Val: 3.0887, Test: 3.0279\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:19:15 2022\tEpoch: 059, Loss: 0.0138, Val: 3.0578, Test: 3.0098\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:19:19 2022\tEpoch: 060, Loss: 0.0134, Val: 3.1057, Test: 3.0254\n",
      "\t\t -- train_counter: 1400, test_counter:52\n",
      "Sun Jan  2 14:19:22 2022\tEpoch: 061, Loss: 0.0131, Val: 3.1073, Test: 3.0322\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:19:26 2022\tEpoch: 062, Loss: 0.0126, Val: 3.0867, Test: 3.0300\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:19:30 2022\tEpoch: 063, Loss: 0.0121, Val: 3.0788, Test: 3.0246\n",
      "\t\t -- train_counter: 1400, test_counter:54\n",
      "Sun Jan  2 14:19:34 2022\tEpoch: 064, Loss: 0.0118, Val: 3.1042, Test: 3.0424\n",
      "\t\t -- train_counter: 1400, test_counter:53\n",
      "Sun Jan  2 14:19:37 2022\tEpoch: 065, Loss: 0.0113, Val: 3.1105, Test: 3.0337\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:19:41 2022\tEpoch: 066, Loss: 0.0109, Val: 3.1250, Test: 3.0519\n",
      "\t\t -- train_counter: 1400, test_counter:51\n",
      "Sun Jan  2 14:19:44 2022\tEpoch: 067, Loss: 0.0106, Val: 3.1089, Test: 3.0496\n",
      "\t\t -- train_counter: 1400, test_counter:55\n",
      "Sun Jan  2 14:19:48 2022\tEpoch: 068, Loss: 0.0101, Val: 3.1340, Test: 3.0621\n",
      "\t\t -- train_counter: 1400, test_counter:56\n",
      "Sun Jan  2 14:19:51 2022\tEpoch: 069, Loss: 0.0099, Val: 3.1177, Test: 3.0584\n",
      "\t\t -- train_counter: 1400, test_counter:53\n",
      "Sun Jan  2 14:19:55 2022\tEpoch: 070, Loss: 0.0097, Val: 3.1214, Test: 3.0604\n",
      "\t\t -- train_counter: 1400, test_counter:54\n",
      "Sun Jan  2 14:19:59 2022\tEpoch: 071, Loss: 0.0093, Val: 3.1384, Test: 3.0711\n",
      "\t\t -- train_counter: 1400, test_counter:52\n",
      "Sun Jan  2 14:20:03 2022\tEpoch: 072, Loss: 0.0091, Val: 3.1320, Test: 3.0791\n",
      "\t\t -- train_counter: 1400, test_counter:53\n",
      "Sun Jan  2 14:20:06 2022\tEpoch: 073, Loss: 0.0088, Val: 3.1471, Test: 3.0790\n",
      "\t\t -- train_counter: 1400, test_counter:54\n",
      "Sun Jan  2 14:20:10 2022\tEpoch: 074, Loss: 0.0085, Val: 3.1296, Test: 3.0784\n",
      "\t\t -- train_counter: 1400, test_counter:52\n",
      "Sun Jan  2 14:20:14 2022\tEpoch: 075, Loss: 0.0083, Val: 3.1486, Test: 3.0928\n",
      "\t\t -- train_counter: 1400, test_counter:52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_605902/3516486598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mval_mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# scheduler.step(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_605902/2264621115.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/phylognn/phylognn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_max_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/nn/conv/pna_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_attr: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snowflake/lib/python3.7/site-packages/torch_geometric/nn/conv/pna_conv.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, dim_size)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'amplification'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_deg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'attenuation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_deg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for epoch in range(1, 1001):\n",
    "    loss, train_counter = train(train_loader)\n",
    "    test_mae, test_counter = test(test_loader)\n",
    "    val_mae, _ = test(val_loader)\n",
    "    \n",
    "    # scheduler.step(loss)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "    writer.add_scalar('Loss/test', test_mae, epoch)\n",
    "    writer.add_scalar('Loss/val', val_mae, epoch)\n",
    "    writer.add_scalar('Counter/train', train_counter/len(train_loader.dataset), epoch)\n",
    "    writer.add_scalar('Counter/test', test_counter/len(test_loader.dataset), epoch)\n",
    "    \n",
    "    print(f'{time.ctime()}\\t'\n",
    "          f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n",
    "          f'Test: {test_mae:.4f}')\n",
    "    \n",
    "    print(f'\\t\\t -- train_counter: {train_counter}, test_counter:{test_counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb52095-743c-4a75-947d-7e728e87c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c2ebc-f8aa-4886-88c7-02bbc8b5188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b771e75-9824-4e0b-9d67-b98b87acdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tld0 = list(train_loader)[0].to(device)\n",
    "tld1 = list(test_loader)[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb990c5f-3804-447f-9ec4-ff38f99732e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = model(tld0.x, tld0.edge_index, tld0.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709262e-4b24-4720-98d5-d3d934d80962",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f9b9c-5456-4492-90ed-cbe9c261d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tld0.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e86c48-0a60-48b8-ac35-8776deadb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(res0, tld0.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b7691-9bec-4d6f-ba36-07213d45cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1Loss()(res0.argmax(axis = 1).to(torch.float), tld0.y.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a3380-01eb-4ff9-9485-ca018689bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(res0.argmax(axis = 1) == tld0.y).abs().sum().item()/len(tld0.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f9c83-9877-4df9-a4d4-235e1facaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model(tld1.x, tld1.edge_index, tld1.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b0b1f-3a5f-427e-abb4-3ef7723ef7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488421d-cdc8-4ea1-9617-b0fbedeab631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tld1.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df503c-618d-40c8-a040-a3cc36f23817",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(res1, tld1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e359cd-f57b-4c36-9854-e893f651c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1Loss()(res1.argmax(axis = 1).to(torch.float), tld1.y.to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee4bdc-004c-4a80-ab9b-322a83e784f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [d.y.item() for d in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6323a-9b77-4f60-b075-c8dbfdf37c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8702e1-17db-4b05-a5d9-9a02d86bd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [d.y.item() for d in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb9e24-7048-404c-9cff-01b3025ce878",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e542f-d058-4e5c-9ccc-f2ce3828072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([d.y.item() for d in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec70e5-62dc-4e3f-b3fa-aa666e6b3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7adae8-7c3e-42fb-adc1-c0b3630041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc36559-7631-46d6-adfb-8b5e7e83b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a83aae-201f-41eb-ba8a-03ae1a00cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.node_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c64e4-58d8-40b9-ac2b-1f1ec944eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.node_emb(data.x.squeeze()).view(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50969d7-1fdd-41b1-8d8b-05e451b66511",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c9c64-c7e1-4e51-ab69-6f4dfe4d91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.convs[0](x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ca919-0a19-4418-a0b9-53dcb3b7a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ead6a-fc3f-404a-9d35-199b80ce8483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep AI",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
